{"version":3,"file":"312.7fd0a6dd.chunk.js","mappings":"gBAAIA,ECCAC,EADAC,ECAAC,E,sFCEG,MAAMC,EAAeC,GAAc,WAAUA,GACvCC,EAAoBD,GAAc,SAASA,ICDjD,MAAME,EACX,iDAEWC,EAA2B,+CAA+CD,IAC1EE,EAA2B,mCAAmCF,IAI9DG,EAAoB,oC,eCwGjC,MAnGA,oBACE,KAASC,SAAyB,WAIlC,KAAQC,QAA6B,CAAC,EAMtC,KAAQC,YAAsB,EAJ1BC,aACF,OAAOC,KAAKH,OACd,CAIII,gBACF,OAAOD,KAAKF,UACd,CAEA,mBACE,MAAMI,QAAiBF,KAAKG,KAAMJ,OAAOK,IAAI,qBAC7C,IAAKF,EACH,MAAO,CAAEG,WAAYV,GAEvB,MAAMW,GAAU,QAAUJ,GAAoBK,cAE9C,MAAO,CAAEF,WAAY,UAAUC,EAAQA,WAAWA,EAAQE,OAC5D,CAEAC,WAAWC,GACTV,KAAKG,MAAO,QAAiBO,GAC7BV,KAAKH,cAAgBG,KAAKW,aAEJ,oBAAXC,SACTA,OAAOT,KAAOH,KAAKG,KACnBS,OAAOC,MAAQxB,GAEjByB,EAAQC,IACN,2BACOf,KAAKG,KAAKa,MAAMC,cAAcC,KAAKC,GAAMA,EAAEC,cAEpDpB,KAAKF,YAAa,CACpB,CAEAW,WAAWY,EAAaX,EAAwB,CAAC,GAC/C,OAAOV,KAAKG,KAAMmB,MAAMC,KAAKhC,EAAiB8B,GAAM,IAC/CX,EACHc,WAAW,EACXC,MAAM,IACLC,MAAMC,IACP,MAAM,KAAEC,EAAI,KAAEH,EAAI,UAAEI,EAAS,MAAEC,EAAK,OAAEC,GAAWJ,EACjD,MAAO,CACLC,OACAH,KAAMA,IAAS,EACfI,UAAWA,IAAc,EACzBE,SACD,GAEL,CAEAC,IAAIX,EAAaX,EAAsB,CAAC,GACtC,OAAOV,KAAKG,KAAM6B,IAAI3C,EAAYgC,GAAMX,EAC1C,CAEAD,UAAUwB,EAAwBvB,EAAwB,CAAC,GACzD,aAAcV,KAAKG,KAAM+B,IAAID,EAASvB,IAAUW,IAAID,UACtD,CAEAX,UAAUY,EAAaX,EAAwB,CAAC,GAC9C,aAAcV,KAAKG,KAAMgC,IAAID,IAAI7C,EAAYgC,GAAMX,IAAUU,UAC/D,CAEAX,iBACE,aAAcT,KAAKG,KAAMa,MAAMoB,SAASlB,KAAKmB,GAAMA,EAAEC,KAAKlB,YAC5D,CAEAX,aAAc,CACdA,cAAe,CAEfA,kBAAkBH,GAChB,MAAMiC,GAAO,QAAUjC,GAIvB,aAHMN,KAAKG,KAAMqC,UAAUN,IAAIK,SAEzBvC,KAAKG,KAAMa,MAAMyB,QAAQF,IACxB,CACT,CAEAG,KACE,OAAO1C,KAAKG,KAAMgC,IAAIO,IACxB,CAEAjC,aACE,MAAM,SAAEkC,SAAmB3C,KAAKG,KAAMyC,MAAMC,OAEtCC,QAAmB9C,KAAKG,KAAM4C,MAC9B,aAAEC,EAAY,GAAED,GAAOD,EAC7B,MAAO,CAAEC,GAAIA,EAAG3B,WAAY4B,eAAcL,WAC5C,G,0JCvEF,MA+DMM,EAAoC,CACxCC,WAAY,EACZC,WAAW,GAiLb,MA9KA,oBACE,KAASvD,SAAyB,QAMlC,KAAQE,YAAa,EAJjBC,aACF,MAAO,CAAEM,WAAYV,EACvB,CAIIM,gBACF,OAAOD,KAAKF,UACd,CAMAW,aACE,MAAM2C,EAAa,IAAI,IAAc,kBAC/BA,EAAWC,OAEjB,MAAMC,EAAY,IAAI,IAAa,kBAC7BA,EAAUD,OAEhB,MAOME,OAnGY9C,OACpB6C,EACAE,EAA0B,WAEL,OAAa,CAChCF,YAOAG,WAAY,EACV,UACA,UACA,OAAO,CACLC,iBAAkB,CAChBC,WAAY,CACV,CACEC,KAAM,CACJ,+BACA,mCACA,yBACA,wCACA,6BAGJ,CACEC,WAAY,OACZC,SAAU,OACVF,KAAM,CAAC,yBAA0B,iCAKzC,UACA,OAAsB,CACpBG,eAAgB,KAGpBC,qBAAsB,EAAC,UACvBC,aAAc,EAAC,UACfC,gBAAiB,CACfC,kBAAmB,KACV,GAOXC,cAAe,EACb,OAAU,CACRC,KAAMb,KAGVc,SAAU,CACRC,UAAU,EAAAA,EAAA,SA0CSC,CAAclB,EAPb,CACpB,kFACA,kFACA,kFACA,kFACA,+FAIFtD,KAAKG,WAAa,OAAY,CAAEiD,aAAYE,YAAWC,WAEvDvD,KAAKyE,IAAK,QAAOzE,KAAKG,MAEA,oBAAXS,SACTA,OAAO2C,OAASA,EAChB3C,OAAOT,KAAOH,KAAKG,KACnBS,OAAO6D,GAAKzE,KAAKyE,GACjB7D,OAAOC,MAAQxB,GAIjBkE,EAAOmB,iBAAiB,gBAAiBC,IACvC,MAAMC,EAASD,EAAIE,OAAOzD,WACpB0D,EAAOvB,EAAOwB,eAAeH,IAAW,GACxCI,EAAmBC,OAAOC,YAC9BJ,EAAK5D,KAAKmB,GAAM,CACdA,EAAE8C,WAAW/D,WACbiB,EAAE8C,WAAWC,aAAalE,KAAKmE,IAAM,QAAUA,IAAIC,WAGvD,EAAQC,MAAM,gBAAgBX,IAAUI,EAAiB,IAe3DzB,EAAOmB,iBAAiB,mBAAoBC,IAC1C,EAAQY,MAAM,qBAAqBZ,EAAIE,OAAOzD,aAAa,IAE7D,EAAQL,IACN,qBACAwC,EAAOiC,gBAAgBtE,KAAKC,GAAMA,EAAEC,cAStCpB,KAAKF,YAAa,CACpB,CAEAW,WAAWY,EAAaX,EAAwB,CAAC,GAC/C,OAAOV,KAAKyE,GAAIlD,KAAKlC,EAAYgC,GAAMX,GAASgB,MAAMC,IACpD,MAAM,KAAEC,EAAI,SAAE6D,EAAQ,cAAEC,EAAa,OAAE3D,EAAM,QAAE4D,EAAO,MAAEC,GAAUjE,EAClE,MAAO,CACLC,OACAH,KAAMgE,IAAa,EACnB5D,UAAW6D,IAAkB,EAC7B3D,SACD,GAEL,CAEAC,IAAIX,EAAaX,EAAsB,CAAC,GACtC,OAAOV,KAAKyE,GAAIzC,IAAI3C,EAAYgC,GAAMX,EACxC,CAEAD,UAAUwB,EAAwBvB,EAAwB,CAAC,GAEzD,MAAMmF,EAAY,IACbnF,KACAuC,GAGL,IAAI5B,EAEJ,GAAIY,aAAmB6D,KAAM,CAC3B,MAAMC,EAAW9D,EAAQqD,KACnBU,QAAoB/D,EAAQ+D,cAC5BC,EAAO,IAAIC,WAAWF,GAC5B3E,QAAYrB,KAAKyE,GAAI0B,QACnB,CAAEC,KAAML,EAAU9D,QAASgE,GAC3BJ,EAEJ,KAAO,CACL,MAAMI,GAAO,IAAII,aAAcC,OAAOrE,GACtCZ,QAAYrB,KAAKyE,GAAI8B,SAASN,EAAMJ,EACtC,CAGA,OADA7F,KAAKmC,IAAId,EAAID,WAAYV,GAClBW,EAAID,UACb,CAEAX,UAAUY,EAAaX,EAAwB,CAAC,GAC9C,MAAM8F,EAAOnH,EAAYgC,GAEzB,UADuBrB,KAAKG,MAAMsG,KAAKC,SAASF,EAAM9F,IACvC,QAELV,KAAKG,MAAMsG,KAAKvE,IAAIsE,EAAM9F,MAC/BW,IAAID,UAET,CAGF,CAEAX,iBACE,OAAOT,KAAKG,KAAMoD,OAAQwB,iBAAiB7D,KAAKmB,GAC9CA,EAAEsE,WAAWvF,YAEjB,CAEAX,mBACQT,KAAKG,MAAMyG,OACnB,CAEAnG,oBACQT,KAAKG,MAAM0G,QACnB,CAEApG,kBAAkBH,SACGN,KAAKG,KAAMoD,OAAQuD,MAAK,QAAUxG,IACrD,OAAO,CACT,CAEAoC,KACE,MAAMf,EA/OVlB,gBACEsG,GAGA,gBAAiBC,KAAQD,EAAU,CACjC,MAAM,IAAE1F,EAAG,SAAE4F,GAAaD,OACpB,CAAE3F,IAAKA,EAAI6F,OAAQD,WAAUrF,KAAM,YAC3C,CACF,CAuOmBuF,CAAcnH,KAAKG,KAAMsG,KAAK/D,MAC7C,OAAOf,CACT,CAEAlB,aAIE,MAAO,CAAEsC,GAHE/C,KAAKG,KAAMoD,OAAOqB,OAAOxD,WAGvB4B,aAFQhD,KAAKG,KAAMoD,OAAQe,SAAUC,SAAU6C,KACzDpE,aACwBL,UAAW,EACxC,G,sBC1LF,MAtFmB,MACjBkE,OAAO,EACPhE,KAAM,qBACNwE,MAAO,CACLC,SAAS,EACTC,IAAK,CACHD,SAAS,IAGbE,QAAS,CACPF,SAAS,GAEXvH,OAAQ,CACN0H,IAAK,CACHC,YAAa,CACX,+BAAgC,CAAC,MAAO,QACxC,8BAA+B,CAC7B,wBACA,wBACA,wBACA,2BAINC,UAAW,CACTC,QAAS,0BACTC,MAAO,GAKPC,UAAW,IAMbC,UAAW,CACTC,KAAM,CACJC,SAAS,EACTC,SAAU,IAEZC,WAAY,CACVF,SAAS,IAGbG,UAAW,GAQXC,OAAQ,CACNJ,SAAS,GAEXJ,MAAO,CACLS,QAAS,CACPC,UAAW,IACXC,SAAU,IAEZC,mBAAmB,GAErBC,QAAS,CACPC,KAAM,cAGVpF,OAAQ,CACNE,WAAY,EAIV,OAAW,CACTmF,OAAQC,EAAA,MAGZC,IAAK,CACHxB,SAAS,IAGbyB,aAAc,CACZC,YAAY,KCWhB,MAnFA,oBACE,KAASpJ,SAAyB,WAMlC,KAAQE,YAAsB,EAJ1BC,aACF,MAAO,CAAEM,WAAYV,EACvB,CAIIM,gBACF,OAAOD,KAAKF,UACd,CAIAW,aACET,KAAKG,WAAa,QAAmB,KACf,oBAAXS,SACTA,OAAOT,KAAOH,KAAKG,KACnBS,OAAOC,MAAQxB,GAGjBW,KAAKF,YAAa,CACpB,CAEAW,WAAWY,EAAaX,EAAwB,CAAC,GAC/C,OAAOV,KAAKG,KAAMmB,MAAMC,KAAKhC,EAAiB8B,GAAM,IAC/CX,EACHc,WAAW,EACXC,MAAM,IACLC,MAAMC,IACP,MAAM,KAAEC,EAAI,KAAEH,EAAI,UAAEI,EAAS,MAAEC,EAAK,OAAEC,GAAWJ,EACjD,MAAO,CACLC,OACAH,KAAMA,IAAS,EACfI,UAAWA,IAAc,EACzBE,SACD,GAEL,CAEAC,IAAIX,EAAaX,EAAsB,CAAC,GACtC,OAAOV,KAAKG,KAAM6B,IAAI3C,EAAYgC,GAAMX,EAC1C,CAEAD,UAAUwB,EAAwBvB,EAAwB,CAAC,GACzD,aAAcV,KAAKG,KAAM+B,IAAID,EAASvB,IAAUW,IAAID,UACtD,CAEAX,UAAUY,EAAaX,EAAwB,CAAC,GAC9C,aAAcV,KAAKG,KAAMgC,IAAID,IAAI7C,EAAYgC,GAAMX,IAAUU,UAC/D,CAEAX,iBACE,aAAcT,KAAKG,KAAMa,MAAMoB,SAASlB,KAAKmB,GAAMA,EAAEC,KAAKlB,YAC5D,CAEAX,aAAc,CACdA,cAAe,CAEfA,kBAAkBH,GAChB,MAAMiC,GAAO,QAAUjC,GAIvB,aAHMN,KAAKG,KAAMqC,UAAUN,IAAIK,SAEzBvC,KAAKG,KAAMa,MAAMyB,QAAQF,IACxB,CACT,CAEAG,KACE,OAAO1C,KAAKG,KAAMgC,IAAIO,IACxB,CAEAjC,aACE,MAAMP,QAAiBF,KAAKG,KAAMyC,MAAMC,OAClCF,EAAWsG,OAAO/I,EAASyC,UAE3BG,QAAmB9C,KAAKG,KAAM4C,MAC9B,aAAEC,EAAY,GAAED,GAAOD,EAC7B,MAAO,CAAEC,GAAIA,EAAG3B,WAAY4B,eAAcL,WAC5C,G,+BC9FgBuG,EAAX,CAAWA,IAChBA,EAAA,QAAU,UACVA,EAAA,YAAc,cACdA,EAAA,IAAM,MACNA,EAAA,KAAO,OACPA,EAAA,MAAQ,QACRA,EAAA,OAAS,cANOA,GAAX,CAAWA,GAAA,ICiClB,MA3BsC,CACpCC,QAAS,CACPC,SAAUF,EAASG,QACnBC,WAAY,OACZC,aAAc,WACdC,QAAS,mCACTC,QAAS,mCACTC,cAAe,2CACfC,YAAa,gDACbC,gBAAiB,8CACjBC,cAAe,UACfC,WAAY,iCAEd,cAAe,CACbV,SAAUF,EAASa,YACnBT,WAAY,QACZC,aAAc,cACdC,QAAS,wCACTC,QAAS,uCACTC,cAAe,+CACfC,YAAa,oDACbC,gBAAiB,kDACjBC,cAAe,QACfC,WAAY,sCC1BhB,MAAME,EACJd,EAASG,QAIEI,EACY,EAAgBO,GAAkBP,QAK9CC,GAFY,EAAgBM,GAAkBR,QAG5B,EAAgBQ,GAAkBN,eAEpDC,EACgB,EAAgBK,GAAkBL,YAElDC,EAEX,EAAgBI,GAAkBJ,gBAEvBC,EACkB,EAAgBG,GAAkBH,cAE3DI,EAAoB,GAAGJ,OAEhBK,EAAwB,GAAGD,SAmB3B,WAAEH,IAda,EAAgBE,GAAkBV,WAGhC,EAAgBU,GAAkBT,aAWlC,EAAgBS,IC9CjC,EAAgB,IAAIG,OAC/B,IAAIN,oBACJ,KAGW,EAAoB,uBAwBpBO,GAtByB,IAAID,OACxC,IAAIN,oBACJ,KAGmC,IAAIM,OACvC,IAAID,2BACJ,KAe0B,2B,sCCVrB,MAAMG,GAAwB5J,MACnC6J,IAEA,IAAKA,EACH,MAAO,UAGT,MAAMC,QAAiB,QAAmBD,GAE1C,OAAOC,GAAUC,MAAQ,c,+BCf3B,SAASC,GAAcC,EAAqB9I,GAG1C,MADa,QAAQA,aADH,OAAwB8I,EAAS,WAGrD,CAGO,MAoBDC,GAAQ,+DAYP,MAMMC,GAA0BnK,MACrCwB,EACAZ,EACAwJ,KAEA,IACE,MAAML,EAAOvI,GAAS6I,MAAMN,KACtBtK,EAA+B,CACnC6K,KAAM,SAAS1J,IACf2J,SAAS,EACT3J,OAEI4J,EAlDuB,CAC/BT,IAEA,GAAIA,EAAM,CACR,GAAIA,EAAKU,SAAS,SAChB,MAAO,QAGT,GAAIV,EAAKU,SAAS,SAChB,MAAO,QAGT,GAAIV,EAAKU,SAAS,QAChB,MAAO,MAEX,CAEA,MAAO,SAiCeC,CAAkBX,GACtC,GAAI,CAAC,QAAS,QAAS,QAAQY,QAAQH,IAAgB,EACrD,MAAO,IAAK/K,EAAU0B,KAAMqJ,EAAaD,SAAS,GAGpD,MAAMN,EAAUzI,GAASN,YDuBIlB,OAC/BP,EACA2K,KAEA,IAAIQ,EAAkB,EACtB,IACE,GAAInL,aAAoBgG,WAEtB,OADA2E,GAAcA,EAAW3K,EAASoL,YAC3BpL,EAET,MAAMqL,EAA4B,GAElC,GAAIrL,aAAoBsL,eAAgB,CACtC,MAAMC,EAASvL,EAASwL,YAElBC,EAAalL,OACjBmL,OACAC,WAEID,GACK,OAAiBL,IAG1BA,EAAOO,KAAKD,GACZR,GAAmBQ,EAAOP,WAC1BT,GAAcA,EAAWQ,GAClBI,EAAOM,OAAOrK,KAAKiK,IAK5B,aAFoCF,EAAOM,OAAOrK,KAAKiK,EAGzD,CAEA,MAAMF,EAASvL,EAAS8L,OAAOC,iBAM/B,gBAAiBC,KAAST,EACpBS,aAAiBhG,aACnBqF,EAAOO,KAAKI,GACZb,GAAmBa,EAAMZ,WACzBT,GAAcA,EAAWQ,IAI7B,OADe,OAAiBE,EAElC,CAAE,MAAOY,GAMP,YALA,GAAQA,MACN,gEACAA,EAIJ,GC9EYC,CAAkBnK,EAAQN,OAAQkJ,QACxC,EAEJ,GAAKL,EAGE,IAC2B,IAAhCA,EAAKY,QAAQ,gBACwB,IAArCZ,EAAKY,QAAQ,mBAEb,GAAI,IAAMiB,GAAOC,KAAK5B,IACpBxK,EAAS0B,KAAO,QAChB1B,EAAS+B,QAAUwI,GAAcC,EAAS,qBACrC,CACL,MAAM6B,GAAa,OAAwB7B,GAG3CxK,EAAS6K,KACPwB,EAAWC,OAAS,GAAK,SAASnL,IAAQ,WAAWkL,IAEnDA,EAAWE,MAAM,IACnBvM,EAAS8K,SAAU,EACnB9K,EAAS0B,KAAO,QAChB1B,EAAS+B,QAAUsK,EACnBrM,EAAS6K,KAAO,SAAS1J,KAChBkL,EAAWE,MAAMrC,IAC1BlK,EAAS0B,KAAO,OAChB1B,EAAS8K,SAAU,EACnB9K,EAAS+B,QAAUsK,EACnBrM,EAAS6K,KAAO,SAAS1J,MA/DnC,SAAgBqL,GACd,MAAMC,EAAYD,EAAOE,OAAOC,MAAM,EAAG,KACzC,OAAOlC,GAAMmC,KAAKH,EACpB,CA6DmBI,CAAOR,IAKhBrM,EAAS0B,KAAO,OAChB1B,EAAS+B,QAAUsK,EACnBrM,EAAS8M,KAlEnB,SAAuBN,EAAgBF,EAAS,KAC9C,OAAOE,EAAOF,OAASA,EAAS,GAAGE,EAAOG,MAAM,EAAGL,QAAeE,CACpE,CAgE0BO,CAAcV,KAN9BrM,EAAS0B,KAAO,QAChB1B,EAAS8K,SAAU,EACnB9K,EAAS+B,QAAUZ,EAAID,WAM3B,MACoC,IAA3BoJ,EAAKY,QAAQ,UACtBlL,EAAS+B,QAAUwI,GAAcC,EAASF,GAC1CtK,EAAS0B,KAAO,QAChB1B,EAAS8K,SAAU,IAC2B,IAArCR,EAAKY,QAAQ,qBACtBlL,EAAS0B,KAAO,MAChB1B,EAAS+B,QAlHf,SAAyByI,EAAqB9I,GAC5C,MAAMsL,EAAO,IAAIC,KAAK,CAACzC,GAAU,CAAE9I,SACnC,OAAOwL,IAAIC,gBAAgBH,EAC7B,CA+GyBG,CAAgB3C,EAASF,GAC5CtK,EAAS8K,SAAU,QA3CnB9K,EAAS8M,KAAO,yBAAyB3L,EAAID,aAC7ClB,EAAS8K,SAAU,EA6CrB,OAAO9K,CACT,CAAE,MAAOoN,GAEP,YADA,GAAQvM,IAAI,uBAAwBuM,EAAGjM,EAEzC,GAaWkM,GAAoB,CAC/BC,EACAhD,EACAiD,EAAgB,MAETD,GAAShD,GAAiB,eAATA,GACpB,OAAwBgD,GAAOX,MAAM,EAAGY,QACxC,ECtJN,MAAMC,GAAK,I,SAAI,IAAM,mBACrBA,GAAGC,QAAQ,GAAGC,OAAO,CACnBvM,IAAK,MACLwM,UAAW,QAGb,UCkBA,OAHS,CAAE3L,IApBGzB,MAAOY,EAAaiJ,KAG9B,UAFsB,SAAS,OAAOlK,IAAI,CAAEiB,QAE9B,CACZ,MAAMyM,EAA6B,CACjCzM,MACA4E,KAAMqE,GAER,SAAS,OAAOpI,IAAI4L,EACtB,GAWY1N,IARFK,MAAOY,IAEjB,MAAM0M,QAAgB,SAAS,OAAO3N,IAAI,CAAEiB,QAG5C,OAAO0M,GAAS9H,MAAQ8H,GAAS9L,OAAO,G,YCG5C,OAfqB,MACnB,MAAM+L,EAAU,IAAI,MbDU,2BaY9B,MAAO,CAAE9L,IATGzB,MACVwN,IAEA,MAAMC,EACY,iBAATD,EAAoB,IAAInI,KAAK,CAACmI,GAAO,YAAcA,EAC5D,OAAOD,EAAQ9L,IAAIgM,EAAU,CAAEhL,WAAY,EAAGC,WAAW,GAAQ,EAIrDgL,OADC1N,MAAOY,GAAgB2M,EAAQG,OAAO9M,GAC/B,EAGxB,G,YCAA,MAAM+M,GAAwB3N,MAC5BY,IAKA,MAAM4E,QAAa,OAAgB5E,GACnC,GAAI4E,GAAQA,EAAKuG,OAAQ,CAEvB,MAAMhC,QAAaH,GAAsBpE,GACnCoI,EAAcd,GAAkBtH,EAAMuE,GAQ5C,MAAO,CAAE7I,OAAQsE,EAAM5E,MAAKyJ,KANE,CAC5BlJ,KAAM,OACNH,KAAMwE,EAAKuG,OACX3K,UAAWoE,EAAKuG,OAChBhC,QAEgC8D,OAAQ,KAAMD,cAClD,CAEO,EAGHE,GAA6B,CACjC3M,KAAM,OACNH,UAAM,EACNK,WAAO,EACPD,eAAW,GAGP2M,GAAuB/N,MAC3BY,EACAlB,EACAsO,KAEA,GAAItO,EAAM,CAER,aADmBA,EAAKoB,KAAKF,EAAK,CAAEoN,UAEtC,CACA,OAAOF,EAAS,EAGZG,GAA2BjO,MAC/BY,EACAlB,EACAwO,KAEA,MAAMC,EAAmBD,GAAc,IAAIE,iBACrC,OAAEJ,GAAWG,EACnB,IAAIE,EAEJ,GAAK3O,EAAL,CAKKwO,IACHG,EAAQC,YAAW,KACjBH,EAAiBI,OAAO,GACvB,MAIL,IAEE,MAAMC,EAAYC,KAAKC,MACjBrE,QAAa0D,GAAqBnN,EAAKlB,EAAMsO,GAC7CW,EAAgBF,KAAKC,MAC3BrE,EAAKuE,UAAYD,EAAgBH,EACjC,MAAMK,IAAcxE,EAAKrJ,MAAOqJ,EAAKrJ,KdjFP,IcoF9B,GAFAqN,GAASS,aAAaT,GAGf,cADChE,EAAKlJ,KAGT,MAAO,CAAEP,MAAKmO,mBAAmB,EAAMlB,OAAQ,OAAQxD,QAEhD,CAEP,MAAQe,MAAO4D,SAAqBtP,EACjC6B,IAAIX,EAAK,CAAEoN,SAAQjC,OAAQ,KAAMkD,OAAQ,IACzC1D,OAAOC,iBACP7M,OAEGoL,QAAaH,GAAsBoF,GACnCE,EACJ7E,EAAKrJ,MAAQqJ,EAAKrJ,MAAQ,GAAKgO,EAAWjD,QAAU1B,EAAKrJ,KAErD4M,EAAcd,GAAkBkC,EAAYjF,GAE9CmF,SACI,OAAgBtO,GAAK,OAAiB,CAACoO,KAI/C,MAAMG,EAASD,EACXF,EACAH,EACAnP,EAAK6B,IAAIX,EAAK,CAAEoN,gBAChB,EAcJ,OAZA3D,EAAK+E,QAAUX,KAAKC,MAAQC,GAIvBtE,EAAKhJ,OAASwN,GACjBnP,EAAKgC,IAAId,GAETyJ,EAAKgF,QAAUZ,KAAKC,MAAQrE,EAAK+E,SAEjC/E,EAAKgF,SAAW,EAGX,CACLnO,OAAQiO,EACRvB,cACAhN,MACAyJ,KAAM,IAAKA,EAAMN,QACjB8D,OAAQ,OAGZ,CAEJ,CAAE,MAAOnC,GAEP,OADA,GAAQ5G,MAAM,iCAAkC4G,GACzC,CAAE9K,MAAKmO,mBAAmB,EAAMlB,OAAQ,OAAQxD,KAAMyD,GAC/D,CAxEA,MAFE,GAAQxN,IAAI,8DA0Ed,EAGIgP,GAA8BtP,MAClCY,EACAlB,EACAwO,EACAqB,KAGA,MAAMC,EAAoC,aAAnB9P,GAAMP,SACvBkL,EAAOmF,QACHzB,GAAqBnN,EAAKlB,EAAMwO,GAAYF,QAClDF,GAEE2B,EAAa,GAAGvQ,UAA0B0B,IAC1CnB,QAAiBiQ,MAAMD,EAAY,CACvCE,OAAQ,MACR3B,OAAQE,GAAYF,OACpBuB,YAGF,GAAI9P,GAAYA,EAASmQ,KAAM,CAe7B,MAAMC,EAAgB/E,GACnB0E,EAEGM,QAAQC,UADR,OAAgBnP,GAAK,OAAiBkK,KAGtC,KAAEf,EAAI,OAAE7I,EAAM,WAAE8N,SL/JnBhP,eACLmP,EACAa,GAEA,MAAOC,EAAkBC,GAAcf,EAAOgB,MACxCrF,EAA4B,GAG5BsF,EAAcH,EAAiBhF,aAC/B,MAAEG,SAAgBgF,EAAY9E,OAC9BvB,EAAOqB,QAAcxB,GAAsBwB,QAAS,EAEpDiF,EAAaH,EAAWjF,YAExBqF,EAA2C,CAC/CtQ,OAAQuL,OAAOC,iBACb,OAAa,CACX,MAAM,KAAEL,EAAMC,MAAAA,SAAgBiF,EAAW/E,OACzC,GAAIH,EAEF,YADA6E,GAASA,EAAMlF,EAAQf,IAGzBiG,GAASlF,EAAOO,KAAKD,SACfA,CACR,CACF,GAGF,MAAO,CAAErB,OAAM7I,OAAQoP,EAAetB,WAAY5D,EACpD,CKkI+CmF,CACzC9Q,EAASmQ,KACTC,GAGIjC,EAAcd,GAAkBkC,EAAYjF,GAClD,MAAO,CACLnJ,MACAgN,cACAvD,KAAM,IAAKA,EAAMN,QACjB7I,SACA2M,OAAQ,UACR4B,aAEJ,CAEO,EAiCT,MAAMe,GAAiBxQ,MACrBY,EACAlB,EACAwO,EACAuC,KAEA,MAAMC,QAAsB/C,GAAsB/M,GAClD,QAAsB,IAAlB8P,EACF,OAAOA,EAGT,GAAIhR,EAAM,CACR+Q,GAAsBA,EAAmB,6BAIzC,aAF0BxC,GAAyBrN,EAAKlB,EAAMwO,EAGhE,CAEAuC,GAAsBA,EAAmB,+BAQzC,aAN6BnB,GAC3B1O,EACAlB,EACAwO,EAGmB,EAqDjByC,GAAkB3Q,MACtBN,EACA8B,KAEA,IAAIZ,EAQJ,OAPIlB,IACFkB,QAAYlB,EAAK+B,IAAID,IAGvB,OAAiBA,GAEjBZ,SAAc,OAAgBA,OJrMGZ,OACjCwB,GAEO,IAAIiE,WACU,iBAAZjE,EACHoK,GAAOC,KAAKrK,SACNA,EAAQ+D,eI+LqBqL,CAAoBpP,IACtDZ,CAAG,E,gCChUZ,MAAMiQ,GAAyD,CAC7DC,MAAO,EACPC,SAAU,EACVC,SAAU,GAILhR,eAAeiR,GACpBhR,GAEA,MAAM,aAAEiR,KAAiBC,GAAgBlR,EASnCmR,ECvBR,SACEC,EACApR,GAEA,OAAO,cAA+BoR,EACpCrR,uBAAuBY,EAAa0Q,GAClC,MAAM7R,QAAiB+Q,GAAe5P,EAAKrB,MACrCgS,QAAgBpH,GAAwB1K,EAAUmB,GAExD,OAAQ0Q,EAEJC,GAASpQ,OAASmQ,EAClBC,OACA,EAHAA,CAIN,CAEAvR,iBAAiBwB,GACf,OAAOmP,GAAgBpR,KAAMiC,EAC/B,CAEAxB,2BACE,eAAgBwR,MAAMC,YAAYC,MAC/BvN,GAAWA,IAAWlE,EAAQ0R,aAEnC,CAEA3R,uBAAuB4R,SACTrS,KAAKsS,sBAMfL,MACGM,YAAY7R,EAAQ8R,kBACpB9Q,MAAK,KACJ,GAAQX,IAAI,2BAA2BL,EAAQ8R,qBACxC,KAERC,OAAOC,IACN,GAAQ3R,IACN,0BAA0BL,EAAQ8R,qBAAqBE,EAAIC,YAEtD,IAGf,EAEJ,CDzBwBC,CAAgBtB,GAAaK,GAAe,CAChES,YARkB5S,EASlBgT,iBANiB,aAAjBb,EACIjS,EACAD,IAOAoT,EAAW,IAAIhB,EAUrB,aARMgB,EAASC,KAAK,CAAEC,IAAKnB,EAAYoB,UAKvC,GAAQjS,IAAI,WAAY4Q,SAElBkB,EAASI,mBACRJ,CACT,C,uLE9CO,MAAMK,GAKXC,YAAYC,EAAyBC,GACnCrT,KAAKoT,SAAWA,EAChBpT,KAAKqT,MAAQA,CACf,CAEAC,cAAchF,GACZ,MAAMiF,EAAQvT,KAAKqT,MAAMjI,QAAQkD,GACjC,OAAOiF,EAAQvT,KAAKqT,MAAM7G,OAASxM,KAAKqT,MAAME,EAAQ,QAAK,CAC7D,E,4BCfK,SAASC,GAAW3H,GAGzB,OAAO4H,QAAQ5H,EAAMY,MAAM,wBAC7B,CCkBO,IAAKiH,GAAL,CAAKA,IACVA,EAAAA,EAAA,aAAe,GAAf,eACAA,EAAAA,EAAA,SAAW,GAAX,WACAA,EAAAA,EAAA,KAAO,GAAP,OAHUA,GAAL,CAAKA,IAAA,IAiEAC,GAAL,CAAKA,IACVA,EAAAA,EAAA,QAAU,GAAV,UACAA,EAAAA,EAAA,UAAY,GAAZ,YACAA,EAAAA,EAAA,KAAO,GAAP,OACAA,EAAAA,EAAA,OAAS,GAAT,QAJUA,GAAL,CAAKA,IAAA,I,YCrBZ,MAAMC,GAA2B,CAC/BvP,KAAM,CACJwP,WAAW,EACX5N,KAAM,GACNkG,WAAO,GAET2H,MAAO,CAAC,EACRC,QAAS,CACPC,YAAa,CACXC,MAAO,EACPC,UAAW,EACXC,QAAS,KAKf,SAASC,GAAcpN,GACjBA,EAAKqN,YAAcX,GAAUY,MAAQtN,EAAK8D,KAAKyJ,KACjDvN,EAAKqN,UAAYX,GAAUc,UAG7B,MAAM,KAAE1J,GAAS9D,EAEXyN,EAAuB,CAC3BC,UAAW,IAAIxF,KAAKpE,EAAK4J,WAAWC,cAGpCC,gBACE5N,EAAK4N,iBACL5N,EAAK6N,MACL7N,EAAK8D,KAAKgK,kBACV9N,EAAK8D,KAAK+J,MACV7N,EAAK8D,KAAK8J,gBAEZG,KAAM/N,EAAK+N,MAAQjK,EAAKiK,KAExBC,YAAahO,EAAKjE,GAElBiR,YAAahN,EAAKgN,aAAe,GAGnC,OAAQhN,EAAKqN,WACX,KAAKX,GAAUY,KACf,KAAKZ,GAAUuB,aAAc,CAC3B,MAAMnK,EAAO9D,EAAK8D,MACZ,KAAElJ,GAASkJ,EAEjB,IAAIwB,EAAOtF,EAAKkO,QAEhB,GAAa,gCAATtT,EAAwC,CAE1C0K,EADcxB,EAAKe,MACNsJ,WACf,MAAO,GAAa,qCAATvT,EAA6C,CAGtD0K,EAFcxB,EAAKe,MAENuJ,OAAO,GAAG9U,OACzB,CAEA2E,OAAOoQ,OAAOZ,EAAW,CACvB7S,OACA0K,OACAxB,KAAM9D,EAAK8D,KAAKe,QAGlB,KACF,CAEA,KAAK6H,GAAUc,SAAU,CACvB,MAAM1J,EAAO9D,EAAK8D,KAElB7F,OAAOoQ,OAAOZ,EAAW,CACvB7S,KAAM,mCACN0K,KAAMxB,EAAKwK,OACXxK,KAAMA,EACNyK,SAAS,IAGX,KACF,CAEA,QAGE,MAAO,CAAC,EAGZ,OAAOd,CACT,CAEA,MAAMe,IAAe,SACnB,sBACA/U,MAAOgV,UACcA,EAAUC,WACjBxU,IAAIkT,MAIduB,IAAe,SACnB,sBACAlV,OAASsC,KAAI0S,eAGX,GAFiBjC,GAAWzQ,GAEd,CAeZ,aAdoB0S,EAAUG,SAAS7S,IACV7B,KAAK8F,IAChC,GAAuB,IAAnBA,EAAK0N,UAIT,OAAON,GAAc,IAChBpN,EACHjE,KACAsR,UAAWX,GAAUc,SACrB1J,KAAM9D,GACN,IAGkB4B,OAAO6K,QAC/B,CAaA,aAXmBgC,EAAUI,eAAe9S,IACjB7B,KAAK8F,IAC9B,MAAMqN,EAAYrN,EAAKuN,GAAKb,GAAUc,SAAWd,GAAUY,KAC3D,OAAOF,GAAc,IAChBpN,EACHqN,YACAtR,KACA+H,KAAM9D,GACN,GAGgB,IAIlB8O,IAAa,SACjB,oBACArV,OAASsC,KAAI0S,cACJA,EAAUK,WAAW/S,KAI1BgT,GAAyB,CAC7BhT,GAAI,GACJ8Q,WAAW,EACX5N,KAAM,GACNkG,WAAO,EACP6H,YAAa,GAGf,SAASgC,GAAqB1B,EAAY2B,GAOxC,OANqB3B,EAAKrO,KAAK4G,OAAO,GAEDqJ,MAAMC,GAClCA,EAAIvB,kBAAoBqB,EAAWrB,iBAI9C,CAEA,MAAM/H,IAAQ,SAAY,CACxBvH,KAAM,QACNsO,gBACAwC,SAAU,CAERC,gBAAiB,CACfC,QAAS,CAACC,EAAOC,KACFA,EAAOC,QAEfC,SAAS/D,IACZ,MAAQqC,YAAajS,GAAO4P,EAEvB4D,EAAMzC,MAAM/Q,KACfwT,EAAMzC,MAAM/Q,GAAM,IAAKgT,KAGzB,MAAMzB,EAAOiC,EAAMzC,MAAM/Q,GAEzBkC,OAAOoQ,OAAOf,EAAM,CAClBvR,KAEAiR,YAAarB,EAAQqB,aAAe,IAGjCgC,GAAqB1B,EAAM3B,KAC9B2B,EAAKrO,KAAOqO,EAAKrO,KAAK0Q,OAAOhE,GAC/B,IAGF9F,GAAM+J,aAAaC,eAAeN,EAAM,EAE1CO,QAAU7Q,IACD,CACLwQ,QAASxQ,EAAK/E,IAAIkT,OAKxB2C,aACER,EACAC,GAEA,MAAM,GAAEzT,EAAE,KAAEiE,GAASwP,EAAOC,QACfF,EAAMzC,MAAM/Q,GAEpBkD,KAAK6F,KAAK,IACV9E,EACH8D,KAAM9D,EAAK8D,KACXqD,OAAQ,YAGV,MAAM6I,EAAUT,EAAMlS,KAAK4B,KAAK2C,QAAQ5B,GAASA,IAASjE,IAC1DiU,EAAQC,QAAQlU,GAChBwT,EAAMlS,KAAK4B,KAAO+Q,CACpB,EAEAE,gBACEX,EACAC,GAMA,MAAM,OAAEW,EAAM,OAAEC,EAAM,UAAEC,GAAcb,EAAOC,QAGvCzP,EAFOuP,EAAMzC,MAAMqD,GAEPlR,KAAKkM,MAAMnL,GAASA,EAAK4N,kBAAoBwC,IAE3DpQ,IACEqQ,SACKrQ,EAAKmH,OAEZnH,EAAKmH,OAAS,QAGpB,EACA0I,eAAeN,GACb,MAmBMe,EAnBmBrS,OAAOsS,KAAKhB,EAAMzC,OAAO0D,QAKhD,CAACC,EAAK1U,KACN,MAAMuR,EAAOiC,EAAMzC,MAAM/Q,GAGzB,IAAKuR,EAAKrO,KAAKuG,OACb,OAAOiL,EAGT,MAAMC,EAAUpD,EAAKrO,KAAKqO,EAAKrO,KAAKuG,OAAS,GAG7C,OAFAiL,EAAI3L,KAAK,CAAE/I,KAAI2U,YAERD,CAAG,GACT,IAE6BE,MAAK,CAACxW,EAAGyW,IAErC1I,KAAK2I,MAAMD,EAAEF,QAAQhD,WAAaxF,KAAK2I,MAAM1W,EAAEuW,QAAQhD,aAI3D6B,EAAMlS,KAAK4B,KAAOqR,EAAOpW,KAAK4W,GAAMA,EAAE/U,IACxC,EACAgV,MAAK,IACInE,IAIXoE,cAAgBC,IACdA,EAAQC,QAAQ1C,GAAa2C,SAAU5B,IACrCA,EAAMlS,KAAKwP,WAAY,CAAI,IAG7BoE,EAAQC,QAAQ1C,GAAa4C,WAAW,CAAC7B,EAAOC,KAC9CD,EAAMlS,KAAKwP,WAAY,EAEvB,MAAMmD,EAAsC,GAE5CR,EAAOC,QAAQC,SAAS/D,IACtB,MAAQqC,YAAajS,GAAO4P,EAEvB4D,EAAMzC,MAAM/Q,KACfwT,EAAMzC,MAAM/Q,GAAM,IAAKgT,KAGzB,MAAMzB,EAAOiC,EAAMzC,MAAM/Q,GAEzBkC,OAAOoQ,OAAOf,EAAM,CAClBvR,KAEAiR,YAAarB,EAAQqB,aAAe,IAGjCgC,GAAqB1B,EAAM3B,KAC9B2B,EAAKrO,KAAOqO,EAAKrO,KAAK0Q,OAAOhE,IAG/BqE,EAAQlL,KAAK/I,EAAG,IAGlBwT,EAAMlS,KAAK4B,KAAO+Q,CAAO,IAE3BiB,EAAQC,QAAQ1C,GAAa6C,UAAU,CAAC9B,EAAOC,KAC7C,GAAQrK,MAAMqK,GAEdD,EAAMlS,KAAKwP,WAAY,EACvB0C,EAAMlS,KAAK8H,MAAQqK,EAAOrK,MAAMwG,OAAO,IAGzCsF,EAAQC,QAAQvC,GAAawC,SAAS,CAAC5B,EAAOC,KAC5C,MAAM,GAAEzT,GAAOyT,EAAO1L,KAAKwN,IAEtB/B,EAAMzC,MAAM/Q,KACfwT,EAAMzC,MAAM/Q,GAAM,IAAKgT,KAIzBQ,EAAMzC,MAAM/Q,GAAI8Q,WAAY,CAAI,IAGlCoE,EAAQC,QAAQvC,GAAayC,WAAW,CAAC7B,EAAOC,KAC9C,MAAM,GAAEzT,GAAOyT,EAAO1L,KAAKwN,IACrBhE,EAAOiC,EAAMzC,MAAM/Q,GACzBuR,EAAKT,WAAY,EAEjBS,EAAKvR,GAAKA,EAEVuR,EAAKrO,KAAOuQ,EAAOC,OAAO,IAE5BwB,EAAQC,QAAQvC,GAAa0C,UAAU,CAAC9B,EAAOC,KAC7C,GAAQrK,MAAMqK,GAEd,MAAMlC,EAAOiC,EAAMzC,MAAM0C,EAAO1L,KAAKwN,IAAIvV,IACzCuR,EAAKT,WAAY,EACjBS,EAAKnI,MAAQqK,EAAOrK,MAAMwG,OAAO,IAKnCsF,EAAQC,QAAQpC,GAAWsC,WAAW,CAAC7B,EAAOC,KAC5C,MAAM,GAAEzT,GAAOyT,EAAO1L,KAAKwN,IACrBhE,EAAOiC,EAAMzC,MAAM/Q,GAEnByR,EAAWhB,GAAWzQ,IAEtB,YAAEiR,GAAgBM,EAExBiC,EAAMxC,QAAQC,YAAYC,OAASD,EAC/BQ,EACF+B,EAAMxC,QAAQC,YAAYE,WAAaF,EAEvCuC,EAAMxC,QAAQC,YAAYG,SAAWH,EAGvCM,EAAKN,YAAc,CAAC,GACpB,KA8BO,aAAE+C,GAAY,gBAAEG,GAAe,gBAAEb,GAAiB0B,MAAK,MA1BzC,UACxBxB,GAAqBA,EAAMgC,MAAMzE,QACjCA,IACC,IAAI0E,EAAsB,EACtBC,EAAoB,EAExBxT,OAAOyT,OAAO5E,GAAO4C,SAAQ,EAAG3T,KAAIiR,kBACjBR,GAAWzQ,GAG1ByV,GAAuBxE,EAEvByE,GAAqBzE,CACvB,IAKF,MAAO,CACLC,MAHYuE,EAAsBC,EAIlCvE,UAAWsE,EACXrE,QAASsE,EACV,IAKH5L,GAAM8L,SAOO9L,GAAa,QC7crB,MAAM,GACH,CACN+L,OAAQ,SACRC,eAAgB,iBCkBd,GAA2B,CAC/BC,UAAW,CACTC,MCFO,SDITC,eAAgB,CACd1T,KAAM,KACN2T,QAAS,MAEXC,SAAU,MAUZ,SAASC,GAAmB5C,GAC1B,MAAM,eAAEyC,EAAc,SAAEE,GAAa3C,EAErCyC,GACEI,aAAaC,QACX,UACAC,KAAKC,UAAU,CACb,CAACP,EAAe1T,MAAO0T,EAAeC,WAG5CC,GACEE,aAAaC,QACX,kBACAC,KAAKC,UAAUL,GAErB,CAEA,MAAM,IAAQ,SAAY,CACxB5T,KAAM,SACNsO,aAAY,GACZwC,SAAU,CACRoD,kBAAmB,CACjBjD,GAEEE,SAAWnR,OAAM2T,eAGnB1C,EAAMyC,eAAiB,CACrB1T,OACA2T,QAASA,GAAW1C,EAAM2C,WAAW5T,IAAS,MAGhD6T,GAAmB5C,EAAM,EAE3BkD,YAAa,CAAClD,GAASE,cACrBF,EAAM2C,SAAWzC,EAEjB0C,GAAmB5C,EAAM,EAE3BmD,uBAAwB,CAACnD,GAASE,cAChCF,EAAMuC,UAAUC,MAAQtC,CAAO,EAIjCkD,cAAe,CAACpD,GAASE,cACnBF,EAAM2C,UACRjU,OAAOsS,KAAKhB,EAAM2C,UAAUxC,SAASkD,IACnC3U,OAAOsS,KAAKhB,EAAM2C,SAASU,IAAalD,SAASmD,IAC/C,GAAItD,EAAM2C,SAASU,GAAYC,GAAYC,SAAWrD,EAAS,CAO7D,UANOF,EAAM2C,SAASU,GAAYC,GAEqB,IAAnD5U,OAAOsS,KAAKhB,EAAM2C,SAASU,IAAapN,eACnC+J,EAAM2C,SAASU,GAGpBrD,EAAMyC,gBAAgBC,SAASc,OAAOD,SAAWrD,EAAS,CAC5D,MAEMuD,EAFU/U,OAAOgV,QAAQ1D,EAAM2C,UAEV/G,MACzB,EAAE,CAAEtG,KAAWA,EAAMkO,OAAOD,SAI5BvD,EAAMyC,eADJgB,EACqB,CACrB1U,KAAM0U,EAAW,GACjBf,QAASe,EAAW,IAGC,CACrB1U,KAAM,KACN2T,QAAS,KAGf,CAEAE,GAAmB5C,EACrB,IACA,GAEN,MAQO,kBACXiD,GAAiB,YACjBC,GAAW,uBACXC,GAAsB,cACtBC,IACE,GAAMhB,QAEK,GAAa,QE5E5B,OA5CA,MAGExF,cACEnT,KAAKka,QAAU,IAAIC,iBCjBc,wBDkBnC,CAEOC,kBACL9U,EACA6I,EACAwE,GAEA3S,KAAKka,QAAQG,YAAY,CACvBzY,KAAM,iBACNiK,MAAO,CAAEvG,OAAM6I,SAAQwE,YAE3B,CAEO2H,sBAAsBC,EAAsBhE,GAEjDvW,KAAKka,QAAQG,YAAY,CAAEzY,KAAM,aAAciK,MAAO,CAAE0O,QAAOhE,UACjE,CAEOiE,gBAAgBC,GAEjBA,EAAUjO,OAAS,GACrBxM,KAAKka,QAAQG,YAAYhE,GAAgBoE,GAE7C,CAEOC,sBAAsBpV,EAAc2T,GACzCjZ,KAAKka,QAAQG,YACXb,GAAkB,CAChBlU,OACA2T,YAGN,CAEA0B,KAAKxE,GACHnW,KAAKka,QAAQG,YAAYlE,EAC3B,GEtDK,MAAMyE,WAA8BC,MACzC1H,YAAY2H,GACV7I,MAAM,iBAAiB6I,KACvB7V,OAAO8V,eAAe/a,KAAM4a,GAAsBI,UACpD,ECHK,MAAMC,GACC,eAGP,IAAKC,GAAL,CAAKA,IACVA,EAAA,aAAe,gBADLA,GAAL,CAAKA,IAAA,I,YCuCZ,SAASC,GAA0BnU,GACjC,OAAQA,EAAKoU,UAAY,IAAMpU,EAAKqU,kBAAoB,EAC1D,CAEA,MAIMC,GAAa,CACjB7J,SAAU,IAAIyB,GACZ,CACExF,GAAI,CAAE6N,QAAS,IAAMC,wBAAyB,KAC9Crb,KAAM,CAAEob,QAAS,IAAWC,wBAAyB,IACrDxQ,QAAS,CAAEuQ,QAAS,KAAOC,wBAAyB,KAEtD,CAAC,KAAM,OAAQ,YAEjBhK,SAAU,IAAI0B,GACZ,CACExF,GAAI,CAAE6N,QAAS,IAAMC,wBAAyB,KAC9Crb,KAAM,CAAEob,QAAS,IAAWC,wBAAyB,IACrDxQ,QAAS,CAAEuQ,QAAS,KAAOC,wBAAyB,KAEtD,CAAC,KAAM,UAAW,SAEpBjK,MAAO,IAAI2B,GACT,CACExF,GAAI,CAAE6N,QAAS,IAAMC,wBAAyB,KAC9Crb,KAAM,CAAEob,QAAS,IAAUC,wBAAyB,IACpDxQ,QAAS,CAAEuQ,QAAS,IAAUC,wBAAyB,KAEzD,CAAC,KAAM,OAAQ,aAsZnB,OAhZA,MAmMErI,YACEsI,GACA,SACEC,EAAQ,gBACRC,EAAe,gBACfC,IAvMJ,KAAQC,OAAS,IAAIC,GAAA,EAA0B,IAAIC,KAEnD,KAAQ5b,UAAgC,EAQxC,KAAQ6b,iBAA2B9M,KAAKC,MAExC,KAAQ+K,QAAU,IAAI,GAEtB,KAAQ+B,UAAmD,CACzDvO,GAAI,IAAIwO,IACR/b,KAAM,IAAI+b,IACVlR,QAAS,IAAIkR,KA6LbT,EAAcU,WAAWhc,IACnBA,GACFH,KAAKoc,QAAQjc,EACf,IAGFH,KAAK0b,SAAWA,GAAYJ,GAAW9J,SACvCxR,KAAK2b,gBAAkBA,GA9PD,GA+PtB3b,KAAK4b,gBAAkBA,GAIvB,EAAAS,GAAA,GAlQ+B,KAmQ5BC,MAAK,EAAA1T,GAAA,IAAO,IAAM5I,KAAK6b,OAAOhQ,MAAMpK,KAAO,KAAOzB,KAAKG,QACvDgc,WAAU,IAAMnc,KAAKG,KAAM8S,iBAAiBjT,KAAKgc,oBAEpDhc,KAAK6b,OACFS,MAEC,EAAAC,GAAA,GAAavc,KAAK2b,kBAClB,EAAAza,GAAA,IAAKsb,GAAUxc,KAAKyc,yBAAyBD,MAC7C,EAAAE,GAAA,IAAUF,IACR,MAAMG,EAAY3c,KAAK4c,2BAA2BJ,GAElD,OAAIG,EAAUnQ,OAAS,GAErBxM,KAAKG,MAAM8S,iBAAiBjT,KAAKgc,mBAE1B,EAAAa,GAAA,MAASF,EAAUzb,KAAK8F,GAAShH,KAAK8c,WAAW9V,OAEnD,GAAA+V,CAAK,KAGfZ,WAAU,EAAGnV,OAAMmH,SAAQG,SAAQ3M,aAClC,MAAM,IAAEN,GAAQ2F,EACVgW,EAAYhd,KAAK6b,OAAOhQ,MAAMzL,IAAIiB,IAAM2b,WAAa,GAc3D,GAVAA,EAAU9b,KAAK+b,GAAaA,EAAS5b,EAAK8M,EAAQG,EAAQ3M,KAG3C,SAAX2M,IACFtO,KAAKgc,iBAAmB9M,KAAKC,OAG/BnP,KAAKic,UAAU3N,GAAQ4O,OAAO7b,GAGf,cAAX8M,GAAqC,cAAXA,EAE5BnO,KAAKmd,cAAc9b,OACd,CAIL,MAAM+b,EAAapd,KAAK0b,SAASpI,cAAchF,GAE3C8O,EACFpd,KAAKqd,oBAAoBrW,EAAMoW,IAE/Bpd,KAAKmd,cAAc9b,GAEnB2b,EAAU9b,KAAK+b,GACbA,EAAS5b,EAAK,YAAaiN,EAAQ3M,KAGzC,CAEA3B,KAAKsd,aAAa,GAExB,CAjQQC,eAAe7B,GACrB1b,KAAK0b,SAAWA,CAClB,CAEA,cAAqBvb,EAAmBqd,GACtC,GAAQzc,IAAI,oBAAoBf,KAAKG,MAAMP,eAAeO,EAAKP,YAC/DI,KAAKG,KAAOA,EACZH,KAAKud,eAAeC,GAAkBlC,GAAWnb,EAAKP,UACxD,CAEQgd,2BAA2BJ,GACjC,MAAMiB,EAAe,IAAIjB,EAAM9D,UAAU9P,QACtCkP,GAAmB,YAAbA,EAAE3J,SAGLuP,EAAkB,QAAW5F,GAAMA,EAAExJ,QAAQmP,GAE7CE,EAA8B,GAEpC,UAAYC,EAAaC,KAAU5Y,OAAOgV,QAAQyD,GAAkB,CAClE,MAEMI,EAFW9d,KAAK0b,SAAStI,SAASwK,GAG7BpC,wBACTxb,KAAKic,UAAU2B,GAAkCnc,KAE7Csc,EAAkBF,EACrBlG,MACC,CAACxW,EAAGyW,IAAMuD,GAA0BvD,GAAKuD,GAA0Bha,KAEpE0L,MAAM,EAAGiR,GAIZH,EAAe7R,QAAQiS,EACzB,CAEA,OAAOJ,CACT,CAEQL,cACN,MAAMvJ,EAAU,WAAW/T,KAAK6b,OAAOhQ,MAAMpK,gBAAgBzB,KAAKic,UAAUvO,GAAGjM,eAAezB,KAAKic,UAAU9b,KAAKsB,kBAAkBzB,KAAKic,UAAUjR,QAAQvJ,QAE3JzB,KAAKka,QAAQE,kBAAkB,OAAQ,UAAWrG,EACpD,CAEQ+I,WAAW9V,GACjB,MAAM,IAAE3F,EAAG,OAAEiN,EAAM,UAAE0O,EAAS,WAAErO,GAAe3H,EAEzCoM,EAAWpT,KAAK0b,SAAStI,SAAS9E,GACxCtO,KAAKic,UAAU3N,GAAQpM,IAAIb,GAC3BrB,KAAKsd,cACL,MAAMU,EAAYhe,KAAK6b,OAAOhQ,MAAMzL,IAAIiB,GAWxC,OATArB,KAAK6b,OAAOhQ,MAAMoS,IAAI5c,EAAK,IACtB2c,EACH7P,OAAQ,YACR+P,cAAehP,KAAKC,MACpBR,WAAY,IAAIE,kBAGlBmO,EAAU9b,KAAK+b,GAAaA,EAAS5b,EAAK,YAAaiN,MC5JpB6P,ED8JR1d,UACzB,IACE,MAAM2d,QdkDd3d,eACEY,EACAiN,EACA5N,GAEA,MAAM,KAAEP,EAAI,WAAEwO,EAAU,QAAEqB,GAAYtP,EAEtC,IACE,OAAQ4N,GACN,IAAK,KACH,OAAOF,GAAsB/M,GAC/B,IAAK,OACH,OAAOqN,GAAyBrN,EAAKlB,EAAMwO,GAC7C,IAAK,UACH,OAAOoB,GAA4B1O,EAAKlB,EAAMwO,EAAYqB,GAC5D,QACE,OAEN,CAAE,MAAO1C,GAEP,YADA,GAAQvM,IAAI,6BAA8BuM,EAE5C,CACF,CcxE0B+Q,CAAiBhd,EAAKiN,EAAQ,CAC9CK,aACAxO,KAAMH,KAAKG,KACX6P,QAAS,CACP,CAACiL,IAA2BC,GAAiBoD,gBAE9C5c,MAAMO,IACPjC,KAAK4b,iBAAiB2C,mBAAmBtc,GAElCA,KAET,OAAOmc,CACT,CAAE,MAAO9Q,GAEP,MAAMA,CACR,GC9KG,IAAIkR,GAAA,GAAeC,IACxBN,IACGzc,MAAMxB,IACLue,EAASrf,KAAKc,GACdue,EAASC,UAAU,IAEpBjM,OAAOtG,IACN,GAAQ5G,MAAM,gCAAiC4G,GAC/CsS,EAAStS,MAAMA,EAAM,GACrB,KDsKDmQ,MACD,EAAAf,GAAA,GAAQ,CACNoD,KAAMvL,EAASmI,QACfqD,KAAM,KACJ,EAAAC,GAAA,IAAW,KACTlQ,GAAYK,MAAM,WACX,IAAI4L,GAAsBxH,EAASmI,eAGhD,EAAAra,GAAA,IAAKS,IACI,CACLqF,OACAmH,OAAQxM,EAAS,YAAc,QAC/B2M,SACA3M,cAGJ,EAAAmd,GAAA,IAAY3S,GAENA,aAAiByO,IACZ,EAAAmE,GAAAA,IAAG,CACR/X,OACAmH,OAAQ,UACRG,WAIgB,eAAhBnC,GAAO7G,MACF,EAAAyZ,GAAAA,IAAG,CAAE/X,OAAMmH,OAAQ,YAAaG,YAElC,EAAAyQ,GAAAA,IAAG,CAAE/X,OAAMmH,OAAQ,QAASG,cC9MpC,IAAgC6P,CDiNrC,CAQQa,gBAAgB3d,EAAa4d,GACnC,MAAMzC,EAAQxc,KAAK6b,OAAOhQ,MACpB7E,EAAOwV,EAAMpc,IAAIiB,GAKvB,OAJI2F,GACFwV,EAAMyB,IAAI5c,EAAK,IAAK2F,KAASiY,IAGxBjf,KAAK6b,OAAOzc,KAAKod,EAC1B,CAEQW,cAAc9b,GACpB,MAAMmb,EAAQxc,KAAK6b,OAAOhQ,MAC1B2Q,EAAMU,OAAO7b,GACbrB,KAAK6b,OAAOzc,KAAKod,EACnB,CAGQa,oBAAoBrW,EAAiBoW,GAC3CpW,EAAKgW,UAAU9b,KAAK+b,GAAaA,EAASjW,EAAK3F,IAAK,UAAW+b,KAE/Dpd,KAAKgf,gBAAgBhY,EAAK3F,IAAK,CAAE8M,OAAQ,UAAWG,OAAQ8O,GAC9D,CAEQX,yBAAyBD,GAmB/B,MAlBC,CAAC,OAAQ,WAAmC9F,SAASpI,IACpD4Q,MAAM5S,KAAKtM,KAAKic,UAAU3N,IAASoI,SAASrV,IAC1C,MAAM2F,EAAOwV,EAAMpc,IAAIiB,GACnB2F,GAAQmU,GAA0BnU,GAAQ,GAAKA,EAAK2H,aAEtD3H,EAAK2H,WAAWK,MAAM,aACtBhI,EAAKgW,UAAU9b,KAAK+b,GAClBA,EAASjW,EAAK3F,IAAK,UAAW2F,EAAKsH,UAGrCkO,EAAMyB,IAAI5c,EAAK,IAAK2F,EAAMmH,OAAQ,YAGlCnO,KAAKic,UAAU3N,GAAQ4O,OAAO7b,GAChC,GACA,IAGGmb,CACT,CAEQ2C,iBAAiB9d,GAEvB4D,OAAOsS,KAAKvX,KAAKic,WAAWvF,SAAS0I,GACnCpf,KAAKic,UAAUmD,GAA0BlC,OAAO7b,IAEpD,CAuFOge,QACLhe,EACA4b,EACAvc,EAA4B,CAAC,GAE7B,MAAM8b,EAAQxc,KAAK6b,OAAOhQ,MACpByT,EAAe9C,EAAMpc,IAAIiB,GAK/B,GAAIie,EACFtf,KAAKgf,gBAAgB3d,EAAK,CACxB2b,UAAW,IAAIsC,EAAatC,UAAWC,SAEpC,CACL,MAAM3O,EAAS5N,EAAQ6e,eAAiBvf,KAAK0b,SAASrI,MAAM,GACtDrM,EAAkB,CACtB3F,MACA2b,UAAW,CAACC,GACZ3O,SACAH,OAAQ,UACRqR,gBAAgB,KACb9e,GAGLuc,EAAS5b,EAAK,UAAWiN,GAEzBkO,EAAMyB,IAAI5c,EAAK2F,GACfhH,KAAK6b,OAAOzc,KAAKod,EACnB,CACF,CAEOiD,eACLpe,EACAX,EAA4B,CAAC,GAE7B,OAAO,IAAI6P,SAASC,IAOlBxQ,KAAKqf,QAAQhe,GANK,CAACA,EAAK8M,EAAQG,EAAQ3M,KACvB,cAAXwM,GAAqC,cAAXA,GAC5BqC,EAAQ,CAAErC,SAAQG,SAAQ3M,UAC5B,GAG0BjB,EAAQ,GAExC,CAEOgf,uBAAuBre,EAAaga,GACzCrb,KAAKgf,gBAAgB3d,EAAK,CAAEga,oBAC9B,CAEOsE,OAAOte,GACZ,MACM2F,EADQhH,KAAK6b,OAAOhQ,MACPzL,IAAIiB,GAEnB2F,IAGGA,EAAK2H,WAGR3H,EAAK2H,WAAWK,MAAM,aAFtBhP,KAAKmd,cAAc9b,GAKzB,CAEOue,eAAeC,GACpB,MAAMrD,EAAQxc,KAAK6b,OAAOhQ,MAE1B2Q,EAAM9F,SAAQ,CAAC1P,EAAM3F,KACf2F,EAAK6Y,SAAWA,IAClB7f,KAAKmf,iBAAiB9d,GACtB2F,EAAK2H,YAAYK,MAAM,aACvBwN,EAAMU,OAAO7b,GACf,IAGFrB,KAAK6b,OAAOzc,KAAKod,EACnB,CAEOsD,QACL,MAAMtD,EAAQxc,KAAK6b,OAAOhQ,MAE1B2Q,EAAM9F,SAAQ,CAAC1P,EAAM3F,KACnBrB,KAAKmf,iBAAiB9d,GACtB2F,EAAK2H,YAAYK,MAAM,aACvBwN,EAAMU,OAAO7b,EAAI,IAGnBrB,KAAK6b,OAAOzc,KAAK,IAAI2c,IACvB,CAEOgE,cACL,OAAO/f,KAAK6b,OAAOhQ,KACrB,CAEOmU,eACL,OAAOd,MAAM5S,KAAKtM,KAAK6b,OAAOhQ,MAAM6M,SACtC,CAEOuH,WAOL,OANW,OACT,OAAqB,OAAO,WAC5B,OACA,OAAM,OAAS,CAAC,SAAU,WAGrBC,CAAGlgB,KAAKggB,eACjB,GEpbUG,GAAL,CAAKA,IACVA,EAAAA,EAAA,KAAO,GAAP,OACAA,EAAAA,EAAA,IAAM,IAAN,MACAA,EAAAA,EAAA,OAAS,IAAT,SACAA,EAAAA,EAAA,KAAO,IAAP,OACAA,EAAAA,EAAA,OAAS,GAAT,SALUA,GAAL,CAAKA,IAAA,I,YC3BZ,SAASC,GAAoB5f,GAC3B,MAAO,CACLC,OAAQuL,OAAOC,iBAKb,IAAIL,GAAO,EACX,MAAQA,GAAM,CAEZ,MAAMyU,EAAU,IAAI9P,SAA4BC,IAE9ChQ,EAAK8f,UAAaC,IACG,OAAfA,EAAMta,MACR2F,GAAO,EACP4E,EAAQ,OAERA,EAAQ+P,EAAMta,KAChB,CACD,IAGG4F,QAAcwU,EAEN,OAAVxU,UACIA,EAEV,CACF,EAEJ,CAEA,MAAM2U,GAGF,CACFC,UAAYC,GACVA,GAAOA,EAAI/e,QAAsD,mBAArC+e,EAAI/e,OAAOqK,OAAOC,eAChD0U,UAAUD,GACR,QAAY,IAARA,EACF,MAAO,CAAC,KAAM,IAEhB,MAAM,OAAE/e,KAAWif,GAASF,GACtB,MAAEG,EAAK,MAAEC,GAAU,IAAIC,eAY7B,OAXIpf,GACF,WAEE,gBAAiBkK,KAASlK,EACxBkf,EAAMxG,YAAYxO,GAEpBgV,EAAMxG,YAAY,MAElBwG,EAAMG,OACP,EARD,GAUK,CAAC,IAAKJ,EAAMpgB,KAAMsgB,GAAS,CAACA,GACrC,EACAG,YAAYC,GACV,IAAKA,EACH,OAEF,MAAM,KAAE1gB,KAASogB,GAASM,EAE1B,MAAO,IACFN,EACHjf,OAAQye,GAAoB5f,GAEhC,G,4BCrEuD,oBAAjB2gB,cAEgBC,GAAQC,IAAIC,OAGpE,SAASC,KACP,SAAqB,cAAef,GACtC,CAWA,SAASgB,GAAgBC,GACvB,MAAMC,EAAgB,CACpB3gB,IAAK,CAAE4gB,SAAU,GAAQ5gB,KACzBoL,MAAO,CAAEwV,SAAU,GAAQxV,OAC3ByV,KAAM,CAAED,SAAU,GAAQC,OAEtBC,EAAqBzR,IACzB,MAAM,SAAEuR,GAAaD,EAActR,GAEnCsR,EAActR,GAAQuR,SAAW,GAAQvR,GAEzC,GAAQA,GAAU,IAAI0R,KACpBH,EAASI,MAAM,GAASD,GACxB,MAAME,EAAmBF,EAAK5gB,KAAKoX,GAtBzC,SAAuBoI,GACrB,IACE,OAAOpH,KAAKC,UAAUmH,EACxB,CAAE,MAAOvU,GACP,OAAO8V,OAAOvB,EAChB,CACF,CAgBiDwB,CAAc5J,KAEzDmJ,EAAOpH,YAAY,CAAEzY,KAAM,UAAWwO,SAAQ0R,KAAME,GAAmB,CACxE,EAGH/c,OAAOsS,KAAKmK,GAAehL,SAAStG,GAClCyR,EAAkBzR,IAEtB,C,wCCrCO,MAAM+R,GAAkB,CAC7B7c,EACA8c,KAGO,CACLC,WAAY,CACVlU,EACAwE,EACA2P,KAGAF,EAAW9H,sBAAsBhV,EAAM,CACrC6I,SACAwE,UACA2P,WACA1W,KAAM,CAAC,SAAU,QAAS,UAAUsK,MAAM5W,GAAMA,IAAM6O,KACtD,IClBR1N,eAAe8hB,GACb1E,EACA2E,EACAC,EAAY,IAEZ,IAAIC,EAAQ,GAEZ,gBAAiB1b,KAAQ6W,EACvB6E,EAAM5W,KAAK9E,GACP0b,EAAMlW,SAAWiW,UACbD,EAAaE,GACnBA,EAAQ,IAIRA,EAAMlW,OAAS,SACXgW,EAAaE,EAEvB,CA4BOjiB,eAAgBkiB,GACrBC,EACAC,GAEA,IAAInT,EAAS,EACb,OAAa,CAEX,MAAMmO,QAAc+E,EAAc,IAAKC,EAAQnT,WAE/C,GAAqB,IAAjBmO,EAAMrR,OACR,YAGIqR,EAENnO,GAAUmO,EAAMrR,MAClB,CACF,CCrEO,MAAMsW,GAAY,iDAEZC,GAAa,iDCUbC,GAAyB,CAACF,GAAWC,I,gBCmMlD,OArLA,MAuBE5P,YAAY8P,GACV,GAjBF,KAAQC,UAAYf,GAAgB,WAAY,IAAI,IAEpD,KAAQgB,YAAc,IAAIrH,GAAA,EACxB,IAAIC,MAcCkH,EAAKG,uBACR,MAAM,IAAIvI,MAAM,yCAGlB7a,KAAKojB,uBAAyBH,EAAKG,uBAEnCH,EAAKI,YAAYlH,WAAU1b,MAAOiN,IAChC1N,KAAK0N,GAAKA,QACJ1N,KAAKsjB,eAAe,IAG5BtjB,KAAKujB,gBAAiB,EAAAC,GAAA,GAAc,CAClCP,EAAKI,YACLJ,EAAKxH,gBACJa,MACD,EAAApb,GAAA,IAAI,EAAEuiB,EAAYC,OAAoBA,KAAkBD,IAE5D,CA5BWjH,YACT,OAAOxc,KAAKmjB,YAAYQ,UAC1B,CAIWC,YACT,OAAO5jB,KAAK6jB,MACd,CAsBA,uBAA+BpG,GAG7B,MAAMgF,EAAYhF,EAAajR,OAE/BxM,KAAKkjB,UAAUb,WACb,cACA,oBAAoBI,KAAaA,YAAoBziB,KAAKwc,MAAM/a,mBAGlE,IAAIqW,EAAI2K,QACFlS,QAAQuT,IACZrG,EAAavc,KAAIT,MAAOuG,IACtB,MAAM,GAAEjE,GAAOiE,EAEf,OAAOhH,KAAKojB,uBAAuBrgB,EAAIod,GAAc4D,QAAQriB,MAC3DjB,MAAOkB,IACiB,cAAlBA,EAAOwM,aACHnO,KAAK0N,GAAIsW,gBAAgB,CAC7BjhB,KACAoL,OAAQwF,GAAgBxH,cAGpBnM,KAAK0N,GAAIuW,gBAAgBlhB,GAGjC,MAAMyZ,EAAQxc,KAAKmjB,YAAYtX,MAC/B2Q,EAAMU,OAAOna,GACb+U,IACA9X,KAAKmjB,YAAY/jB,KAAKod,GAEtBxc,KAAKkjB,UAAUb,WACb,cACA,oBAAoBI,EAAY3K,KAAK2K,YACnCziB,KAAKwc,MAAM/a,kBAEd,GAEJ,IAGP,CAEAoF,QACE,MAAMqd,EAAUlkB,KAAKujB,eAAejH,MAClC,EAAA6H,GAAA,IAAKC,GAAM,GAAQrjB,IAAI,8BAA8BqjB,QACrD,EAAAxb,GAAA,IAAQyb,IAAoC,IAAlBA,KAC1B,EAAA3H,GAAA,IAAS,IAAM1c,KAAKmjB,eAEpB,EAAAva,GAAA,IAAQwb,GAAMA,EAAE3iB,KAAO,KACvB,EAAAib,GAAA,IAAUF,IACR,MAAMnY,EAAO,IAAImY,EAAM9D,UAMjB+J,EAtGW,IAkGMpe,EAAKuE,QACzBkP,GAAMA,EAAE3J,SAAWwF,GAAgBsI,YACpCzP,OAIF,GAAIiW,EAAY,EAAG,CACjB,MAAMhF,EAAepZ,EAClBuE,QAAQkP,GAAMA,EAAE3J,SAAWwF,GAAgBwE,UAC3CR,MAAK,CAACxW,EAAGyW,IACDzW,EAAEia,SAAWxD,EAAEwD,WAEvBvO,MAAM,EAAG4V,GAEZ,GAAIhF,EAAajR,OAAS,EAWxB,OAVAiR,EAAa/G,SAASoB,IACpB0E,EAAMyB,IAAInG,EAAE/U,GAAI,IACX+U,EACH3J,OAAQwF,GAAgBsI,WACxB,IAGJjc,KAAKmjB,YAAY/jB,KAAKod,GAEtBxc,KAAKkjB,UAAUb,WAAW,cAAe,eAClCriB,KAAKskB,iBAAiB7G,EAEjC,CAEA,OAAO,GAAAV,CAAK,KAahB,OATA/c,KAAK6jB,OAASK,EAAQ5H,MAAK,EAAAiI,GAAA,MAE3BvkB,KAAK6jB,OAAO1H,UAAU,CACpB/c,KAAOuC,IACL3B,KAAKkjB,UAAUb,WAAW,SAAS,EAErClW,MAAQuG,GAAQ1S,KAAKkjB,UAAUb,WAAW,QAAS3P,EAAItR,cAGlDpB,IACT,CAEA,kBAAyBqB,GACvB,OAAOrB,KAAKojB,uBAAuB/hB,EAAK8e,GAAcqE,OACxD,CAEA,mBAA0BC,EAAqBrJ,GAC7C,OAAOmH,GACLkC,GACCA,GACCzkB,KAAKqf,QACHoF,EAAKvjB,KAAKG,IAAQ,CAChB0B,GAAI1B,EACJ+Z,iBD5KyB,ICiLnC,CAEA,cAAqByC,GACnB,GAAqB,IAAjBA,EAAMrR,OACR,aAEIxM,KAAK0N,GAAIgX,aAAa7G,GAC5B,MAAMrB,EAAQxc,KAAKmjB,YAAYtX,MAE/BgS,EAAMnH,SAAS1P,GACbwV,EAAMyB,IAAIjX,EAAKjE,GAAI,IAAKiE,EAAMmH,OAAQwF,GAAgBwE,YAExDnY,KAAKmjB,YAAY/jB,KAAKod,EACxB,CAEA,sBACE,MAAMA,QAAcxc,KAAK0N,GAAIiX,aAAa,CACxCC,SAAU,CAACjR,GAAgBwE,WAC1BzW,MAAMmc,GAAU,IAAI9B,IAAI8B,EAAM3c,KAAK8F,GAAS,CAACA,EAAKjE,GAAIiE,QAEzDhH,KAAKmjB,YAAY/jB,KAAK,IAAI2c,IAAI,IAAIS,KAAUxc,KAAKwc,QACnD,G,uEC3MK,MAAMqI,GAAmBnQ,GAC9B,KAAW,IAAIxF,KAAKwF,GAAY,2BAA2B,GAEhDoQ,GAAmBC,GAC9B7V,KAAK2I,MAAMkN,EAAUC,SAAS,KAAOD,EAAY,GAAGA,MCG/C,MAsBME,GAAgC,CAC3C3P,EACA4P,KAEA,MAAM,iBACJpQ,EAAgB,MAChBvB,EACA4R,aAAa,KACXpQ,EACAqQ,OAAO,UAAE1Q,EAAS,OAAE2Q,GAAQ,QAC5BC,GACD,KACD1jB,EAAI,MACJiK,GACEqZ,EACJ,MAAO,CACLrQ,KAAMC,EACNvB,QACA3R,OACA8S,UAAWoQ,GAAgBpQ,GAE3BK,OACAlJ,QACAyZ,UACAhQ,SACAiQ,YAAaF,EACd,EAoCUG,GAA0B,EACrClZ,OACAiI,KACAe,SACAZ,YACAI,uBACF,CACExI,OACAiI,KACAe,SACAZ,UAAWoQ,GAAgBpQ,GAC3BE,gBAAiBE,ICnDZ,SAAS2Q,GACdC,EACAjX,GAEA,OAAOhO,SAAUqhB,KACf,GAAIrT,EAAOkX,QACT,MAAM,IAAIC,aAAa,6BAA8B,cAEvD,OAAOF,KAAQ5D,EAAK,CAExB,C,gBC4NO,IAusHK+D,GAAL,CAAKA,IAEVA,EAAA,IAAM,MAENA,EAAA,cAAgB,kBAEhBA,EAAA,aAAe,iBAEfA,EAAA,KAAO,OAEPA,EAAA,eAAiB,mBAEjBA,EAAA,cAAgB,kBAZNA,GAAL,CAAKA,IAAA,IAorLwB,KAAG;;;;;;;;;MAgCH,KAAG;;;;;;;;MAyCF,KAAG;;;;;;;;;;;;;;;MAiDV,KAAG;;;;;;;;;;;;;;MAkDK,KAAG;;;;;;;;MAyClC,MAAMC,GAA+B,KAAG;;;;;;;;;;MA+CxC,MAAMC,GAAkC,KAAG;;;;;;;;;;MA8CD,KAAG;;;;;;;;MA2C7C,MAAMC,GAAiC,KAAG;;;;;;;;;;;MA8C1C,MAAMC,GAAiC,KAAG;;;;;;;;;;;;;;;;;;;;;MA4D1C,MAAMC,GAAmC,KAAG;;;;;;;;;;;;;;;;;;;;;MAkDX,KAAG;;;;;;;;MAyCJ,KAAG;;;;;;MAwCD,KAAG;;;;;;;;;;;;;;;;;;;;;;;MA0DH,KAAG;;;;;;;;;;;;;;;;;;;;8CC1wUrC,MAAMC,GAA4B,8BAE5BC,GACX,mCCeWC,GAA+B,CAC1C/Q,EACA3T,KAEA,MAAM,KAAEsE,EAAI,OAAEqgB,GAAW3kB,EAEnBkT,EAAOyR,EAAO,WAAW,GACzBC,EAAkBD,EAAO,kBAAkB,GAAGzZ,MAAM,GACpD6H,ELlC6BxF,KAAKC,MKmClCoW,EAAce,EAAO,aAAa,IAElC,KAAEvR,EAAO,YAAIyR,GAhCQ,CAACvgB,IAC5B,MAAMtE,EAAS,GAAA8kB,GAAA,QAAU,SAAWxgB,IAC9B8O,EAAOpT,EAAO0O,MAAM0E,KACpByR,EAAW7kB,EAAO0O,MAAMmW,SAC3BtlB,KAAKyR,IACJ,MAAM+T,EAAU/T,EAAQgU,QAAQ9Z,MAAM,GACtC,OAAI6Z,IAAYP,GACP,GAAAS,QAAA,OAAejU,EAAQ9G,OAG5B6a,IAAYN,GACP,GAAAS,aAAA,OAAoBlU,EAAQ9G,YADrC,CAGO,IAERjD,QAAQ+J,QAAwB,IAAZA,IAEvB,MAAO,CAAEoC,OAAMyR,WAAU,EAeOM,CAAc7gB,EAAK4F,MAAMkb,SAAS7B,IAE5DjQ,EAAiC,GAevC,OAdAuR,EAAU9P,SAAQ,CAAC/D,EAASY,KAC1B0B,EAAanJ,KAAK,CAChB+I,OACAtB,QACA3R,KAAM2kB,EACN7R,YACA4Q,SAAS,EACTzZ,MAAO8G,EACPoC,OACAO,SACAiQ,eACA,IAGGtQ,CAAY,E,gECtDrB,MAAM+R,GAAqB,IAAI,MAC7B,SAAa,CACXjU,IAAKnJ,EACLqd,YAAcC,IAA6B,EAC3CC,cAAe,GACfC,UAAW3mB,MAAO4mB,IAChBtY,YAAW,IAAMwB,QAAQC,WAAW8W,KAAKC,IAAI,IAAO,GAAKF,EAAS,KAAO,KAqBlEG,GAAuBC,GAClC,IAAI,MAAc9d,EAAa,CAC7B8E,OAAQgZ,ICnBZ,MAAMC,GAAkBjnB,OACtBknB,cACAC,gBACAlY,SAAS,EACT+X,wBAOkBD,GAAoBC,GAAaI,QAGjD/B,GAA8B,CAC9BgC,MChC2B,IDiC3BpY,SACAqY,QAAS,CAAC,CAAErT,UAAWmR,GAASmC,MAChCC,MAAO,CACLC,IAAK,CACH,CAAEC,YAAa,CAAEC,IAAKT,IACtB,CAAEU,cAAe,CAAED,IAAKT,KAE1BjT,UAAW,CAAE4T,IAAKzD,GAAgB+C,QAI3BW,WAqBPC,GAA0B/nB,OAC9B6U,SACAmT,gBACAb,gBACAnF,YACA/S,SAAS,EACT+X,kBASA,MAAMQ,EAAQ,CACZS,KAAM,CACJ,CACEhU,UAAW,CACT4T,IAAKzD,GAAgB+C,KAGzB,CACEtS,OAAQ,CACN8S,IAAK9S,IAGT,CAAE+S,cAAe,CAAEM,IAAKF,MAkB5B,aAdkBjB,GAAoBC,GAAaI,QAGjD/B,GAA8B,CAC9BgC,MAAOrF,EACP/S,SACAqY,QAAS,CACP,CACErT,UAAWmR,GAASmC,MAGxBC,WAGSM,UAAU,EAGVK,GAAkCnoB,MAC7C6U,EACAmT,EACAb,EACAnF,EACAgF,IAEA9E,GAAsB6F,GAAyB,CAC7ClT,SACAmT,gBACAb,gBACAnF,YACAgF,gBEhHEoB,GAA+BC,GACnC,IACK,IAAI5M,IAAI,IACN4M,EAAM5nB,KAAK6J,GAASA,EAAKwJ,QACzBuU,EAAM5nB,KAAK6J,GAASA,EAAKuB,UAKrByc,GAAqCtoB,MAChDY,EACA2nB,EACAC,EACAC,EACAzB,KAEA,MAAM0B,EFmGwB,EAC9BxB,EACAC,EACAH,IAEA9E,GAAsB+E,GAAiB,CACrCC,cACAC,gBACAH,gBE3GyB2B,CACzB/nB,EACA2nB,EACAvB,GAEIqB,EAAQ,GAEd,gBAAiBpG,KAASyG,EAAoB,CAC5CL,EAAMhd,QAAQ4W,GACd,MAAMxO,EAAY2U,GAA4BnG,GAC1CxO,EAAU1H,OAAS,SACf+V,GACJrO,GACCuQ,GACCwE,EAAmBI,aAAa5E,EAAMyE,IXnCT,GWuCrC,CAEA,OAAOJ,CAAK,ECvBP,MAAMQ,GAAgC,EAC3ChU,SACAsS,gBACAlY,SAAS,EACT6Z,QAAQ,GACRC,iBAAiB,OACjB1B,YACF,CACExnB,QAAS,IAAIgV,KACbwS,QACA2B,eAAgB5E,GAAgB+C,GAChClY,SACA6Z,MAAO,IAAIA,EAAMroB,KAAKwoB,GAAM,IAAIA,OAAMC,KAAK,SAC3CC,gBAAiBJ,IAGbK,GAAoBppB,OACxB6U,SACAsS,gBACAlY,SAAS,EACT6Z,QAAQ,GACRC,iBAAiB,OACjB1B,QACAL,kBAEA,MAAMrJ,QAAYoJ,GAAoBC,GAAaI,QAIjD5B,GACAqD,GAA8B,CAC5BhU,SACAsS,gBACAlY,SACA6Z,QACAC,iBACA1B,QACAL,iBAIJ,OAAOrJ,GAAK0L,mBAAmB,ECrB3BC,GAAkB,CACtBjW,EACAvR,EACAmnB,EACAM,EACAC,KAEA,MAAM3V,EAAOR,EAAM1T,IAAImC,GACjB0S,EAAeX,GAAMW,cAAgB,GAS3C,OAPAA,EAAanJ,KAAK4d,GAClB5V,EAAMmK,IAAI1b,EAAM,CACd2nB,YAAa3nB,EACb4nB,kBAAmBF,EAAWP,EAAEhV,UAAYJ,GAAM6V,mBAAqB,EACvEC,KAAM,CAAEJ,SAAQjV,KAAM2U,EAAE3U,KAAMsV,UAAWJ,EAAW,KAAO,QAC3DhV,iBAEKnB,CAAK,ECrDDwW,GAAc7pB,MACzBiN,EACA6c,EACA3C,EACAnZ,EACA+b,GAAwB,KAExB,MAAMC,QAAkB/c,EAAGgd,eAAe,CACxCxV,QAASqV,EACTlW,UAAWX,GAAUY,OAGjBqW,EAAe,IAAI5O,IAAI0O,GAAWvpB,KAAK4W,GAAM,CAACA,EAAE/U,GAAI+U,MAOpD8S,EDnByB,EAC/BL,EACAtV,KASA,GAAgC,KAN9BA,EAAcrM,QACX8gB,GACCA,EAAE9nB,OAASukB,IACXuD,EAAE9nB,OAASwkB,MACV,IAEc5Z,OACnB,MAAO,GAET,MAAMsH,EAAQ,IAAIiI,IAmBlB,OAlBA9G,EAAayB,SAASgT,IACpB,IAAIQ,EAAc,GAClB,GAAIR,EAAE9nB,OAASwkB,GAAiC,CAC9C,MAAM,OAAEhR,EAAM,QAAEyV,GAAYnB,EAAE7d,MACxBoe,EAAW7U,EAAOjD,MAAM2F,GAAMA,EAAExX,UAAYiqB,KAC7BN,EAAWY,EAAUzV,GAC7BsB,SAASP,GACpB4T,GAAgBjW,EAAOqC,EAAI7V,QAASopB,EAAGvT,EAAI2U,MAAOb,IAEtD,MAAO,GAAIP,EAAE9nB,OAASukB,GAA2B,CAC/C,MAAM,YAAEhR,EAAW,UAAE4V,EAAS,OAAEf,GAC9BN,EAAE7d,MACEoe,EAAW9U,IAAgBoV,EACjCL,EAAcD,EAAWc,EAAY5V,EACrC4U,GAAgBjW,EAAOoW,EAAaR,EAAGM,EAAQC,EACjD,KAGKnW,CAAK,ECdIkX,CAAkBT,QALL7c,EAAGud,gBAAgBV,EAAW,CACzDlX,MAAO,MACPuU,mBAKIsD,EAA2B,GAGjC,UAAW5W,KAAQsW,EAAQlS,SAAU,CACnC,MAAMyS,EAAWR,EAAavqB,IAAIkU,EAAK4V,aACjCkB,EAAkB9W,EAAKW,aAAaoW,IAAI,IAEtC3W,UAAW4W,EAAoB,KAAEzW,EAAI,MAAEtB,GAAU6X,EACnDG,EAAiB,CACrBlX,UAAWX,GAAUY,KACrBY,QAASqV,EACTzf,KAAM,CACJ8J,gBAAiBC,EACjBtB,UAKJ,GAAK4X,EAmBE,CACL,MAAM,GACJpoB,EAAE,cACFyoB,EAAa,gBACbxC,EAAe,KACfle,EACAkJ,YAAayX,GACXN,EAEEO,EAAoBpE,KAAKqE,IAC7BH,EACAlX,EAAK6V,oBAED,uBAAEyB,EAAyB,EAAC,oBAAEC,EAAsB,GAAM/gB,EAC1DghB,EAAsBxE,KAAKqE,IAC/BrX,EAAK6V,kBACL0B,GAEI7X,EACJyX,EACAnX,EAAKW,aAAarM,QAAQ8gB,GAAMA,EAAEhV,UAAYoX,IAC3Ctf,OAEL,GAAIwc,EAAkBsC,EAAsB,CAE1C,MAAMS,EAAyBvB,EAC3Bc,EACAO,EAEEG,EAAoB,IACrBT,EACHxoB,KACAiR,cACAwX,cAAeE,EAGf1C,gBAAiB1B,KAAKqE,IACpBL,EACAM,EACAG,GAGFjhB,KAAM,IACDygB,EAAezgB,KAClB+gB,oBAAqBE,EACrBH,iCAKEnG,GACJ/X,EAAGue,iBAAiBC,KAAKxe,GACzBe,EAFIgX,CAGJuG,GAEFd,EAAQpf,KAAK,IACRqf,KACAa,EACHlhB,KAAMsgB,GAEV,CACF,KAhFe,CACb,MAAMpX,EAAcM,EAAKW,aAAarM,QACnC8gB,GAAMA,EAAEhV,UAAYJ,EAAK6V,oBAC1B3d,OAEI2f,EAAU,IACXZ,EACHxoB,GAAIuR,EAAK4V,YACTlW,cAEAgV,gBAAiBwB,EAAwBc,EAAuB,EAChEE,cAAelX,EAAK6V,kBACpBiC,UAAU,SAIN3G,GAAe/X,EAAG2e,cAAcH,KAAKxe,GAAKe,EAA1CgX,CAAkD0G,GAExDjB,EAAQpf,KAAK,IAAKqgB,EAASrhB,KAAMsgB,GACnC,CA8DF,CACA,OAAOF,CAAO,E,wCCxHT,MAAMoB,GAqBXnZ,YAAYoZ,GApBZ,KAAQC,eAAkC,GAE1C,KAAQC,cAAgB,EAExB,KAAQC,kBAAoB,EAE5B,KAAQC,eAAiB,EAEzB,KAAQlK,UAAY,EAalBziB,KAAKusB,iBAAmBA,CAC1B,CAVWjK,eACT,MAAO,CACLsK,WAAY5sB,KAAKysB,cACjBI,cAAe7sB,KAAK0sB,kBACpBC,cAAe3sB,KAAK2sB,cAExB,CAMO9lB,MAAM4lB,EAAuBhK,EAAY,GAO9C,OANAziB,KAAKysB,cAAgBA,EACrBzsB,KAAKwsB,eAAiB,GACtBxsB,KAAK0sB,kBAAoB,EACzB1sB,KAAK2sB,eAAiB,EACtB3sB,KAAKyiB,UAAYA,EAEVziB,KAAKsiB,QACd,CAEOpgB,IAAI4qB,GAGT,OAFA9sB,KAAKysB,eAAiBK,EAEf9sB,KAAKsiB,QACd,CAEOyK,cAAcC,GAOnB,GANAhtB,KAAKitB,iBAAiBD,GAElBhtB,KAAKwsB,eAAehgB,OAtDL,IAuDjBxM,KAAKwsB,eAAeU,QAGlBltB,KAAKwsB,eAAehgB,OAAS,EAAG,CAClC,MAGM2gB,EAHqBntB,KAAKotB,gCACNptB,KAAKysB,cAAgBzsB,KAAK0sB,mBACAM,GAIpDhtB,KAAK0sB,mBAAqBM,EAC1BhtB,KAAK2sB,cAAgBrF,KAAK+F,MAAMF,GAChCntB,KAAKusB,kBAAoBvsB,KAAKusB,iBAAiBvsB,KAAKsiB,SACtD,CAEA,OAAOtiB,KAAKsiB,QACd,CAEQ2K,iBAAiBK,GACvBttB,KAAKwsB,eAAe1gB,KAAK,CAAE4I,UAAWxF,KAAKC,MAAOme,aACpD,CAEQF,8BACN,IAAIG,EAAY,EACZC,EAAa,EAEjB,QAAS1V,EAAI,EAAGA,EAAI9X,KAAKwsB,eAAehgB,OAAQsL,IAAK,CACnD,MAAM2V,EACJztB,KAAKwsB,eAAe1U,GAAGpD,UAAY1U,KAAKwsB,eAAe1U,EAAI,GAAGpD,WAC1D,UAAE4Y,GAActtB,KAAKwsB,eAAe1U,GAE1CyV,GAAaE,EAAWH,EACxBE,GAAcF,CAChB,CAEA,OAAsB,IAAfE,EAAmB,EAAID,EAAYC,CAC5C,ECyBF,OAjGA,MAuBEra,YACE7N,EACA2d,EACAgG,GASA,GA5BF,KAAUyE,gBAAkB,IAAIpB,GAEhC,KAAUlK,WAAa,IAAI,GAM3B,KAAUS,OAA4B,CACpC0H,UAAW,MAYXvqB,KAAKsF,KAAOA,EAEZtF,KAAK2tB,gBAAkB,IAAI9e,gBAE3B7O,KAAKkjB,UAAYf,GAAgB7c,EAAMtF,KAAKoiB,YAC5CpiB,KAAKipB,kBAAoBA,EACzBjpB,KAAK4tB,UAAW,QAAoB,CAAEC,OAAQ,OAAQC,OAAQxoB,KACzD2d,EAAK8K,QACR,MAAM,IAAIlT,MAAM,0BAGlBoI,EAAKI,YAAYlH,WAAWzO,IAC1B1N,KAAK0N,GAAKA,CAAE,IAGd1N,KAAKipB,kBAAoBA,EAEzBjpB,KAAKujB,eAAiBvjB,KAAKguB,4BAA4B/K,GAEvDjjB,KAAKujB,eAAepH,WAAWkI,IAC7BrkB,KAAK4tB,SAASK,KACZ,OAAOjuB,KAAKsF,UAAU+e,EAAgB,cAAgB,cAExDrkB,KAAKkjB,UAAUb,WAAWgC,EAAgB,cAAgB,WAAW,IAGvErkB,KAAKujB,eACFjH,MAAK,EAAA4R,GAAA,IAAU,IAAMjL,EAAK8K,WAC1B5R,WAAW0G,IACV7iB,KAAK6iB,OAASA,EACd7iB,KAAK4tB,SAASK,KAAK,OAAOjuB,KAAKsF,wBAAyB,CACtDW,KAAM4c,GACN,IAIN7iB,KAAKujB,eACFjH,MACC,EAAA1T,GAAA,IAAQyb,KAAoBA,KAC5B,EAAA6J,GAAA,IAAU,IAAMluB,KAAKmuB,sBAAsBlL,EAAK8K,YAEjD5R,WAAU,KACTnc,KAAKouB,SAAS,GAEpB,CAEUC,sBACRruB,KAAK2tB,gBAAkB,IAAI9e,eAC7B,CAOUsf,sBAAsBJ,GAC9B,OAAOA,EAAQzR,MACb,EAAApb,GAAA,IAAK2hB,GAAWA,EAAO0H,aACvB,EAAA+D,GAAA,IAAqB,CAACC,EAAYC,IAAcD,IAAeC,KAC/D,EAAAttB,GAAA,IAAKmE,KAAQA,KACb,EAAAuD,GAAA,IAAQvD,KAAQA,IAEpB,GCrGK,MAAMopB,GAAwB,CACnClL,EACAmL,EACAC,IAEApL,EAAejH,MACb,EAAAgS,GAAA,MACA,EAAAnK,GAAA,IAAKE,GAAkBsK,IAAWtK,MAClC,EAAAzb,GAAA,IAAQgmB,GAAgBA,KACxB,EAAAV,GAAA,IAAU,IAAMQ,KAChB,EAAAnK,GAAA,M,gBC+DJ,OAzEA,cAAsC,GAKpCpR,YACE7N,EACA2d,EACAgG,GAEAhX,MAAM3M,EAAM2d,EAAMgG,GAPpB,KAAmB4F,eAAiB,IAAIC,GAAA,EAStC,MAAM5K,EAAUuK,GACdzuB,KAAKujB,eACLvjB,KAAK6uB,eAAevS,MAClB,EAAAyS,GAAA,GAAU,OACV,EAAA5K,GAAA,IAAI,KAEFnkB,KAAKquB,qBAAqB,KAE5B,EAAAH,GAAA,IAAU,IACRluB,KAAKgvB,uBAAuB1S,MAC1B,EAAA4R,GAAA,IAAWtG,GACT5nB,KAAKivB,uBAAuBrH,GAAetL,MACzC,EAAA6H,GAAA,IAAI,IAAMnkB,KAAKkjB,UAAUb,WAAW,aACpC,EAAA6L,GAAA,IAAWjoB,IAAS,EAAAqG,GAAA,GAAKtM,KAAKkvB,SAASjpB,EAAMjG,KAAK6iB,mBAM3DwB,IACC,GAAQtjB,IAAI,OAAOuE,kBAAsB+e,GACzCrkB,KAAKkjB,UAAUb,WAAWgC,EAAgB,cAAgB,WAAW,IAIzEH,EAAQ/H,UAAU,CAChB/c,KAAM,KACJY,KAAKkjB,UAAUb,WAAW,SAAS,EAErClW,MAAQuG,IACN1S,KAAKkjB,UAAUb,WAAW,QAAS3P,EAAI,IAG3C1S,KAAKkkB,QAAUA,CACjB,CAQOkK,UACLpuB,KAAK2tB,iBAAiB3e,QACtBhP,KAAK6uB,eAAezvB,OACpB,GAAQ2B,IAAI,OAAOf,KAAKsF,sBAC1B,CAOOuB,QAIL,OAHA7G,KAAKkkB,QAAQ/H,WAAU,SAGhBnc,IACT,GCiRF,OA5SA,cAAmC,GACvBguB,4BAA4B/K,GAepC,OAduB,EAAAO,GAAA,GAAc,CACnCP,EAAKI,YACLJ,EAAK8K,QAASzR,MACZ,EAAApb,GAAA,IAAK2hB,GAAWA,EAAO0H,aACvB,EAAA+D,GAAA,MAEFtuB,KAAKipB,kBAAmB1F,iBACvBjH,MACD,EAAApb,GAAA,IACE,EAAEuiB,EAAY8G,EAAW4E,OACrB1L,KAAgB0L,KAA0B5E,IAKpD,CAGU0E,uBACRrH,GAEA,MAAM,UAAE2C,GAAcvqB,KAAK6iB,OAC3B7iB,KAAK4tB,SAASK,KACZ,OAAOjuB,KAAKsF,kBAAkBilB,UAAkB1F,GAC9C+C,MAIJ,MAAMwH,EAAY9F,GAA8B,CAC9ChU,OAAQiV,EACR3C,gBACA2B,MAAO,GACPC,eAAgB,OAChB1B,MAAO,MAGHuH,EXlDH,SACLC,EACAF,GAEA,MAKMG,EALS,IAAIC,GAAA,EAAa,CAC9BzkB,KAAMic,GACNyI,MAAO,IAAI,OAGmBtT,UAAU,CAAEmT,QAAOF,cACnD,OAAO,IAAI5Q,GAAA,GAAYkR,IACrB,MAAMC,EAAeJ,EAAiBpT,UAAU,CAC9C/c,KAAKuC,GACH+tB,EAAWtwB,KAAKuC,EAAOsE,KACzB,EACAkG,MAAMuG,GACJgd,EAAWvjB,MAAMuG,EACnB,EACAgM,WACEgR,EAAWhR,UACb,IAIF,MAAO,IAAMiR,EAAaC,aAAa,GAE3C,CWyBMC,CACE3J,GACAkJ,GACA9S,MACA,EAAApb,GAAA,IAAKhB,IACI,CACLoO,OAAQ,UACR2G,aAAc/U,EAAS4pB,oBAAoB5oB,KAAK4W,GAC9CmN,GAA8BsF,EAAYzS,UAM9CgY,ECjGH,SACLxvB,EACAgvB,EACAvuB,GAEA,OAAO,IAAIyd,GAAA,GAAYkR,IACrB,MAAMK,EAAK,IAAIC,UAAUtmB,GA8BzB,OA5BAqmB,EAAGE,OAAS,KACVlvB,EAAI,wBAAwB2I,UAAsB4lB,KAClDS,EAAGG,KACD5W,KAAKC,UAAU,CACb4W,QAAS,MACT/f,OAAQ,YACRrN,GAAI,IACJ8f,OAAQ,CAAEyM,WAEb,EAGHS,EAAGzP,UAAaC,IACd,MAAM5N,EAAU2G,KAAKzB,MAAM0I,EAAMta,MACjClF,EAAI,WAAWT,cAAqBqS,GACpC+c,EAAWtwB,KAAKuT,EAAQhR,OAAO,EAGjCouB,EAAGK,QAAW7P,IACZxf,EAAI,WAAWT,UAAiB,CAAE6L,MAAOoU,IACzCmP,EAAWvjB,MAAMoU,EAAM,EAGzBwP,EAAGM,QAAU,KACXtvB,EAAI,WAAWT,YACfovB,EAAWhR,UAAU,EAGhB,KACLqR,EAAG/O,OAAO,CACX,GAEL,CDyD6BsP,CACvB/F,GCtGoCjqB,EDuGViqB,ECtG9B,yCAAyCjqB,ODuGrC,CAACqS,EAAS4d,IAAQvwB,KAAK4tB,SAASK,KAAKtb,EAAS,CAAE6d,KAAM,aAAcD,MACpEjU,MACA,EAAA1T,GAAA,IAAQ3C,KAAU,KAAAwqB,SAAQxqB,MAC1B,EAAA/E,GAAA,IAAK+E,IACI,CACLqI,OAAQ,OACR2G,aAAcoR,GAA6BkE,EAAYtkB,QC9GxB,IAAC3F,EDmHtC,OAAO,EAAAuc,GAAA,GACLwS,EACAS,EAEJ,CAEUd,uBACR,OAAO,EAAA0B,GAAA,IAAM,KAAM,EAAApkB,GAAA,GAAKtM,KAAK2wB,aAE/B,CAEA,iBACE,MAAM,UAAEpG,GAAcvqB,KAAK6iB,QACrB,OAAEpU,GAAWzO,KAAK2tB,gBAClBxC,QAAiBnrB,KAAK0N,GAAIkjB,cAAcrG,EAAYA,GAEpDsG,QAAiC7wB,KAAK8wB,iBAC1CvG,EACAA,EACAY,GAGFnrB,KAAKkjB,UAAUb,WAAW,cAAe,iBACzC,MAAM0O,QAAwBzG,GAC5BtqB,KAAK0N,GACL6c,EACAY,EAASnC,gBACTva,GAMF,OAHAzO,KAAKoiB,WAAW5H,gBAAgBuW,GAChC/wB,KAAKkjB,UAAUb,WAAW,UAEnBwO,CACT,CAEA,gBACE,OAAEviB,EAAM,aAAE2G,GACV4N,GAEA,MAAM,UAAE0H,GAAc1H,GAChB,OAAEpU,GAAWzO,KAAK2tB,gBACxB,GAA4B,IAAxB1Y,EAAazI,OAEf,YADAxM,KAAK4tB,SAASK,KAAK,OAAOjuB,KAAKsF,QAAQilB,wBAGzC,MAAMY,QAAiBnrB,KAAK0N,GAAIkjB,cAAcrG,EAAYA,SAEpDvqB,KAAKgxB,yBACTzG,EACAA,EACAtV,EACAkW,EACA7c,GAGFtO,KAAKkjB,UAAUb,WAAW,cAAe,iBACzC,MAAM0O,QAAwBzG,GAC5BtqB,KAAK0N,GACL6c,EACAY,EAASnC,gBACTva,EACW,SAAXH,GAGFtO,KAAKoiB,WAAW5H,gBAAgBuW,GAChC/wB,KAAKkjB,UAAUb,WAAW,SAC5B,CAEA,+BACEkI,EACAjqB,EACA2U,GACA,cAAEuW,EAAa,YAAExX,EAAW,gBAAEgV,GAC9B1a,GAEA,MAAM,OAAEG,GAAWzO,KAAK2tB,gBAIlBnD,EAAmC,SAAXlc,EAE9BtO,KAAK4tB,SAASK,KACZ,iCAAiC3tB,KAAWgO,eAC1C2G,EAAazI,iBACJyI,EAAaoW,GAAG,IAAI3W,kBAC7BO,EAAaoW,IAAI,IAAI3W,mBAKnB+Q,GAAezlB,KAAK0N,GAAIujB,gBAAiBxiB,EAAzCgX,CAAiDxQ,GAGvDjV,KAAKkxB,UAAUjc,EAAcxG,GAE7B,MAAM,KACJoG,EAAI,MACJtB,EAAK,UAELmB,GACEO,EAAaoW,IAAI,GAEf8F,EAAoBzc,EAGpB0c,EAAc,CAClBlc,QAASqV,EACTlW,UAAWX,GAAUuB,aACrBlS,GAAIzC,EACJ0oB,gBAAiBwB,EACb2G,EACAnI,EACJhV,YAAaA,EAAeiB,EAAazI,OACzCgf,cAAeA,GAAiB,EAChCY,UAAU,EACVthB,KAAM,CACJ8J,gBAAiBC,EACjBtB,UAMJ,aAFMkS,GAAezlB,KAAK0N,GAAI2e,cAAe5d,EAAvCgX,CAA+C2L,GAE9CD,CACT,CAEA,uBACE5G,EACAjqB,EACA6qB,GAEA,MAAM,YAAEnX,EAAW,gBAAEgV,GAAoBmC,EACnCvD,EAAgBoB,EAAkB,EAExChpB,KAAKkjB,UAAUb,WAAW,cAE1B,MAAMgP,OP1LmC5wB,OAC3CH,EACAsnB,EACAH,KAEA,MAAMrJ,QAAYoJ,GAAoBC,GAAaI,QAGjD7B,GAAgC,CAChC1lB,QAAS,IAAIA,KACboU,UAAWmQ,GAAgB+C,KAG7B,OAAOxJ,GAAKkT,8BAA8BC,WAAWC,KAAK,EO6KxBC,CAC9BnxB,EACAsnB,EACA5nB,KAAK2tB,gBAAiBlf,QAOxB,GAJAzO,KAAK4tB,SAASK,KACZ,gCAAgC3tB,cAAoB+wB,YAA4BzJ,KAGxD,IAAtByJ,EACF,OAAOzJ,EAGT5nB,KAAKkjB,UAAUb,WACb,cACA,QAAQ/hB,OACRN,KAAK0tB,gBAAgB7mB,MACnBygB,KAAKoK,KAAKL,ETnRe,OSuR7B,MAAMM,EPhM+B,GACvCrc,SACAsS,gBACA2B,QACAC,iBACA1B,QACAL,iBAEA9E,GAAsBkH,GAAmB,CACvCvU,SACAsS,gBACA2B,QACAC,iBACA1B,QACAL,gBOkLkCmK,CAA0B,CAC1Dtc,OAAQhV,EACRsnB,gBACA2B,MAAO,GACPC,eAAgB,MAChB1B,MT5R2B,IS6R3BL,YAAaznB,KAAK2tB,iBAAiBlf,SAGrC,IAAIojB,EAAmB,EACnBV,EAAoBvJ,EAGxB,gBAAiBlF,KAASiP,EAA2B,CACnD3xB,KAAKkjB,UAAUb,WACb,cACA,QAAQ/hB,OACRN,KAAK0tB,gBAAgBX,cAAc,IAGrC8E,GAAoBnP,EAAMlW,OAE1B,MAAMyI,EAAeyN,EAAMxhB,KAAK4W,GAC9BmN,GAA8B3kB,EAASwX,KAGzCqZ,QAA0BnxB,KAAKgxB,yBAC7BzG,EACAjqB,EACA2U,EACA,IACKkW,EACHnX,YAAaA,EAAc6d,GAE7B,UAEJ,CAEA,OAAOV,CACT,CAEA,gBAAwBzO,EAAyBjU,GAC/C,MAAM,OAAEqjB,EAAM,eAAEC,EAAc,MAAEjJ,GR5Q7B,SAAyCpG,GAC9C,MAAM6F,EAAa7F,EAAM9Z,QACtBopB,GLlCsC,qCKkChCA,EAAEpwB,OAELmwB,EAAiB,IAAI7V,IACrB4M,EAAmB,GAuBzB,MAAO,CACLgJ,OAtB2CvJ,EAAW/Q,QAEtD,CAACC,GAAO5L,QAAOgJ,OAAMH,gBACpB7I,EAAyBid,MAAMpS,SAAS3L,IACvCgnB,EAAe7vB,IAAI6I,EAAKwJ,IACxBwd,EAAe7vB,IAAI6I,EAAKuB,MACxB,MAAM2lB,EAAS,IACVlnB,EACH2J,YACAY,OAASzJ,EAAyByJ,OAClCV,gBAAiBC,GAEnBiU,EAAMhd,KAAKmmB,GAEPlnB,EAAKuB,OAASwW,KAChBrL,EAAIwa,EAAO1d,IAAM0d,EACnB,IAEKxa,IACN,CAAC,GAIFsa,eAAgB,IAAIA,GACpBjJ,QAEJ,CQ4OMoJ,CAAgCxP,GAC9BoG,EAAMtc,OAAS,SACX+V,GACJuG,GACCA,GAAUrD,GAAezlB,KAAK0N,GAAIykB,cAAe1jB,EAAvCgX,CAA+CqD,InB/T7B,KmBoUjC,MAAMsJ,EAAiBntB,OAAOsS,KAAKua,GAE7BO,EAAoBN,EAAenpB,QACtCvH,IAAS+wB,EAAelnB,SAAS7J,WAI9BrB,KAAKipB,kBAAmBI,aAC5B+I,EACAjS,GAAcmS,MAIZD,EAAkB7lB,OAAS,SACvBxM,KAAKipB,kBAAmBI,aAC5BgJ,EACAlS,GAAcoS,IAGpB,GE5VK,MAAMC,GAAgBC,GAC3BA,EAAIC,QAAQ,gBAAiBC,GAC3BA,EAAMC,cAAcF,QAAQ,IAAK,IAAIA,QAAQ,IAAK,MAQ/C,SAASG,GACdC,GAEA,IAAKA,GAAgC,iBAAbA,EACtB,OAAOA,EAET,MAAMC,EAA2B,CAAC,EAalC,OAZA9tB,OAAOsS,KAAKub,GAAUpc,SAAS0I,IAC7B,GAAIna,OAAO+V,UAAUgY,eAAeC,KAAKH,EAAU1T,GAAM,CACvD,MAAM8T,EAAeV,GAAapT,GAClC,IAAIvT,EAAQinB,EAAS1T,GACjBF,MAAMiU,QAAQL,EAAS1T,IACzBvT,EAAQinB,EAAS1T,GAAKle,KAAK8F,GAAS6rB,GAAY7rB,KACd,iBAAlB8rB,EAAS1T,KACzBvT,EAAQgnB,GAAYC,EAAS1T,KAE/B2T,EAAIG,GAAgBrnB,CACtB,KAEKknB,CACT,CCtBO,SAASK,GACdtK,EACA5T,EACAme,EAAoB,EACpB5H,EAAkB,GAElB,MAAM6H,EAAkBxK,EAAMlgB,QAC3BmC,GAASA,EAAK2J,UAAY2e,IAEvBE,GAAkB,KAAAC,eACtBF,GACCvoB,GAASA,EAAKuK,SAAWJ,IAGtBlB,EACJuf,EAAkB,EACd9H,EAAkB6H,EAAgB9mB,OAClC8mB,EAAgB9mB,OAAS+mB,EAAkB,EAKjD,MAAO,CACL/H,cAHA+H,EAAkB,EAAIF,EAAoBvK,EAAMyK,GAAiB7e,UAIjEV,cAEJ,CAEO,SAASyf,GACdC,EACA5K,EACA5T,EACAsV,GAAwB,GAExB,MAAM,cAAEgB,EAAa,YAAExX,GAAgBof,GACrCtK,EACA5T,EACAwe,EAAWlI,cACXkI,EAAW1f,aAGP2f,EAAWd,GAAY/J,EAAMA,EAAMtc,OAAS,IAC5Cwc,EAAkB2K,EAASjf,UACjC,MAAO,IACFgf,EACHxe,UACAb,UAAWX,GAAUc,SACrB4X,UAAU,EACVpY,cACAlJ,KAAM,IACD6oB,EACHjf,UAAWsU,GAEbwC,gBACAxC,gBAAiBwB,EACbxB,EACA0K,EAAW1K,gBAEnB,CAEA,MCtEa4K,GAAoBtmB,GAC/BA,aAAasY,cAA2B,eAAXtY,EAAEhI,K,oDCsFjC,OA3EA,cAAoC,GAKlC6N,YACE7N,EACAuuB,EACA5Q,EACAgG,GACA,SACE6K,GAGE,CAAEA,SAAU,IAEhB7hB,MAAM3M,EAAM2d,EAAMgG,GAElB,MAAM,MAAErF,EAAK,YAAEmQ,GCPiB,EAClCxQ,EACAmL,EACAhuB,EAAiC,CAAC,KAElC,MAAM,WACJmzB,EAAU,SACVC,EAAW,EAAC,gBACZE,EAAe,QACfC,EAAO,aACPC,EAAe,EAAC,SAChBvF,GACEjuB,EAEEyzB,EAAkB,IAAIrF,GAAA,EAEtBsF,EAAqBD,EAAgB7X,MACzC,EAAAyS,GAAA,GAAU,OACV,EAAAb,GAAA,IAAU,KAAM,EAAA7R,GAAA,GAASwX,GAAYvX,MAAK,EAAAyS,GAAA,GAAU,IAAI,EAAAsF,GAAA,GAAMP,OAsBhE,MAAO,CACLlQ,MApBc6K,GACdlL,EACA6Q,EAAmB9X,MACjB,EAAA6H,GAAA,IAAI,IAAM6P,GAAmBA,OAC7B,EAAAM,GAAA,IAAW,IACT5F,EAAkBpS,MAChB,EAAAiY,GAAA,GAAM,CACJF,MAAQloB,IACN,GAAQpL,IAAI,QAASoL,GACrB8nB,GAAWA,EAAQ9nB,IACZ,EAAAkQ,GAAA,GAAS6X,WAMzB7P,GAAkBsK,IAAWtK,KAK9B0P,YAAa,KAGXI,EAAgB/0B,MAAM,EAEzB,EDxCgCo1B,CAC7Bx0B,KAAKujB,gBAEL,EAAAmN,GAAA,IAAM,KAAM,EAAApkB,GAAA,GAAKtM,KAAKy0B,YACtB,CACEZ,aACAC,WAEAG,QAAU9nB,IACRnM,KAAK4tB,SAASK,KAAK,OAAO3oB,UAAc6G,EAAM/K,YAC9CpB,KAAKkjB,UAAUb,WAAW,QAASlW,EAAM/K,WAAW,EAEtDutB,SAAWtK,IACTrkB,KAAK4tB,SAASK,KAAK,OAAO3oB,kBAAqB+e,KAC/CrkB,KAAKkjB,UAAUb,WAAWgC,EAAgB,cAAgB,WAAW,IAK3ErkB,KAAK4jB,MAAQA,EACb5jB,KAAK+zB,YAAcA,CACrB,CAEO3F,UACLpuB,KAAK2tB,iBAAiB3e,QACtBhP,KAAK+zB,gBACL/zB,KAAK4tB,SAASK,KAAK,OAAOjuB,KAAKsF,oBACjC,CAEOuB,QAEL,OADA7G,KAAK4jB,MAAMzH,WAAU,IAAMnc,KAAKkjB,UAAUb,WAAW,YAC9CriB,IACT,CAEA,eACE,MAAM6iB,GAAS,UAAM7iB,KAAK6iB,QAC1B7iB,KAAKquB,sBACL,UACQruB,KAAK00B,KAAK7R,EAClB,CAAE,MAAOvV,GACP,MAAMqnB,EAAYf,GAAiBtmB,GAQnC,GAPAtN,KAAK4tB,SAASK,KACZ,OAAOjuB,KAAKsF,QAAQud,EAAO0H,8BAA8BoK,MACzD,CACExoB,MAAOmB,KAINqnB,EACH,MAAMrnB,CAEV,CACF,GE2HF,OAlLA,cAAgC,GACpB0gB,4BAA4B/K,GAmBpC,OAlBuB,EAAAO,GAAA,GAAc,CACnCP,EAAKI,YACLJ,EAAKxH,cACLwH,EAAK8K,QAASzR,MACZ,EAAApb,GAAA,IAAK2hB,GAAWA,EAAO0H,aACvB,EAAA+D,GAAA,MAEFtuB,KAAKipB,kBAAmB1F,iBACvBjH,MACD,EAAApb,GAAA,IACE,EAAEuiB,EAAYC,EAAc6G,EAAWqK,QACnClR,GACAD,GACAmR,GACArK,KAKV,CAEA,WAAqB1H,GACnB,MAAM,UAAE0H,GAAc1H,GAChB,OAAEpU,GAAWzO,KAAK2tB,gBACxB3tB,KAAKkjB,UAAUb,WAAW,cAE1B,MAAMwS,QAA0B70B,KAAK0N,GAAIgd,eAAe,CACtDxV,QAASqV,EACTlW,UAAWX,GAAUc,WAGjBwU,EAAkB6L,EAAkBxJ,GAAG,IAAIrC,iBAAmB,EAG9D8L,OjBfmBr0B,OAC3BH,EACAmoB,EACAb,EACAH,KAEA,MAAMrJ,QAAYoJ,GAAoBC,GAAaI,QAGjD9B,GAAiC,CACjCzlB,UACAy0B,eAAgBtM,EAChB/T,UAAWmQ,GAAgB+C,KAG7B,OAAOxJ,EAAI4W,qBAAqBzD,WAAWC,KAAK,EiBAnByD,CACzB1K,EACA,CAACzH,IACDkG,EACAva,GAaF,GAVAzO,KAAK4tB,SAASK,KACZ,uBAAuB1D,WAAmBuK,KAE5C90B,KAAK0tB,gBAAgB7mB,MAAMiuB,EAAeD,EAAkBroB,QAC5DxM,KAAKkjB,UAAUb,WACb,cACA,eACAriB,KAAK0tB,gBAAgBpL,UAGnBwS,EAAe,EAAG,CAEpB,MAAMI,QAA6Bl1B,KAAKm1B,eACtC5K,EACAvB,EACAva,GAIFomB,EAAkB/oB,QAAQopB,EAC5B,OACMl1B,KAAKo1B,cAAc7K,EAAYsK,EAAmBpmB,EAC1D,CAEA,qBACE8b,EACAvB,EACAva,GAEA,MAAM4mB,QAA4BzM,GAChC2B,EACA,CAACzH,IACDkG,EhBrGyB,IgBuGzBhpB,KAAK2tB,iBAAiBlf,QAGlB6mB,EAA6B,GAC7BC,QAA0Bv1B,KAAK0N,GAAIgd,eAAe,CACtDxV,QAASqV,EACTlW,UAAWX,GAAUc,WAEjBghB,EAAuB,IAAIzZ,IAC/BwZ,EAAkBr0B,KAAK4W,GAAM,CAACA,EAAE/U,GAAI+U,MAGtC,gBAAiB2d,KAAeJ,EAAqB,CACnDr1B,KAAKkjB,UAAUb,WACb,cACA,yBACAriB,KAAK0tB,gBAAgBX,cAAc,IAErC,MAAM2I,EAAqBD,EAAYv0B,IAAI2xB,IAAa3xB,KAAK8F,IAC3D,MAAM,UAAE0N,EAAS,GAAEH,GAAOvN,EACpBgiB,EAAkBlE,GAAgBpQ,GAGlCihB,EAAoBH,EAAqBp1B,IAAImU,GAC/CuQ,GAAgBpQ,GAChB,EAGJ,MAAO,CACLQ,QAASqV,EACTxnB,GAAIwR,EACJF,UAAWX,GAAUc,SACrBwU,gBAAiB2M,EACjBnK,cAAexC,EACfhV,YAAa,EACboY,UAAU,EACVthB,KAAM,IAAK9D,EAAM0N,UAAWsU,GAC7B,IAGC0M,EAAmBlpB,OAAS,UACxBiZ,GACJzlB,KAAK0N,GAAI2e,cACT5d,EAFIgX,CAGJiQ,GACFJ,EAAUxpB,QAAQ4pB,GAEtB,CAEA,OAAOJ,CACT,CAEA,oBACE/K,EACAE,EACAhc,GAEA,MAAMmnB,EAAoC,GAG1C,UAAWzK,KAAYV,EAAW,CAChC,MAAM,GAAE1nB,EAAE,gBAAEimB,GAAoBmC,EAEhCnrB,KAAKkjB,UAAUb,WACb,cACA,4BACAriB,KAAK0tB,gBAAgBX,cAAc,IAGrC,MAAM8I,QAAqB9M,GACzBhmB,EACAimB,EACAhpB,KAAKipB,kBACL9I,GAAc4D,OACd/jB,KAAK2tB,iBAAiBlf,QAGxB,GAAIonB,EAAarpB,OAAS,EAAG,CAC3B,MAAMsc,EAAQ+M,EAAa30B,IAAIskB,UAIzBjD,GACJuG,GACCA,GAAUrD,GAAezlB,KAAK0N,GAAIykB,cAAe1jB,EAAvCgX,CAA+CqD,I1BrL/B,K0ByL7B,MAAMqD,EAAUsH,GAAyBtI,EAAUrC,EAAOyB,GAE1DqL,EAAiB9pB,KAAKqgB,EACxB,CACF,CAEIyJ,EAAiBppB,OAAS,SACtBiZ,GAAezlB,KAAK0N,GAAI2e,cAAe5d,EAAvCgX,CAA+CmQ,GAEvD51B,KAAKoiB,WAAW5H,gBAAgBob,EAClC,GCsBF,OAjMA,cAAgC,GAG9BziB,YACE7N,EACAuuB,EACA5Q,EACAgG,GACA,SAAE6K,GAAmC,CAAEA,SAAU,IAEjD,IAAK7Q,EAAK6S,YACR,MAAM,IAAIjb,MAAM,2BAGlB5I,MAAM3M,EAAMuuB,EAAY5Q,EAAMgG,EAAmB,CAC/C6K,aAdJ,KAAUiC,WAA8B,EAgBxC,CAEU/H,4BAA4B/K,GACpC,MAAM+S,EAAyB,IAAIla,GAAA,GAAyB,GAC5DmH,EAAK8K,SACDzR,MACA,EAAApb,GAAA,IAAK2hB,GAAWA,EAAO0H,aACvB,EAAA+D,GAAA,MAEDnS,WAAU,KACT6Z,EAAuB52B,MAAK,EAAM,IAGtC6jB,EAAK6S,YAAa3Z,WAAW4Z,IAC3B/1B,KAAK+1B,WAAaA,EAClBC,EAAuB52B,MAAK,GAE5BY,KAAKouB,SAAS,IAkBhB,OAfuB,EAAA5K,GAAA,GAAc,CACnCP,EAAKI,YACLJ,EAAK8K,QACL/tB,KAAKipB,kBAAmB1F,eACxByS,IACC1Z,MACD,EAAApb,GAAA,IACE,EAAEuiB,EAAYZ,EAAQsM,EAAsB8G,OACxCxS,KACAZ,EAAO0H,aACP4E,GACF8G,IAKR,CAEA,WAAqBpT,GACnB,MAAM,OAAEpU,GAAWzO,KAAK2tB,gBAExB3tB,KAAKkjB,UAAUb,WAAW,cAAe,gBACzC,MAAM,UAAEkI,GAAc1H,GAEhB,WAAEkT,GAAe/1B,KAEvBA,KAAKkjB,UAAUb,WAAW,cAE1BriB,KAAK4tB,SAASK,KACZ,qBAAqB1D,WAAmBwL,EAAWvpB,SACnD,CACEgkB,KAAM,eACNvqB,KAAM8vB,IAIV/1B,KAAK0tB,gBAAgB7mB,MAAMkvB,EAAWvpB,QACtCxM,KAAKkjB,UAAUb,WACb,cACA,UACAriB,KAAK0tB,gBAAgBpL,UAIvB,UAAW/f,KAAQwzB,QAEX/1B,KAAKkxB,UAAU3G,EAAYhoB,EAAMkM,EAE3C,CAEA,gBACE8b,EACAjqB,EACAmO,GAEA,IAAIynB,EAAc,GAClB,IACEl2B,KAAKkjB,UAAUb,WACb,cACA,iBAAiB/hB,OACjBN,KAAK0tB,gBAAgBpL,UAEvB,MAAM,cAAEkJ,EAAa,YAAExX,EAAW,KAAElJ,SAAe9K,KAAK0N,GAAIkjB,cAC1DrG,EACAjqB,IAGI,oBAAEurB,EAAsB,EAAC,uBAAED,EAAyB,GACxD9gB,GAAQ,CAAC,EAEL8c,EAAgBgE,EAAyB,EAEzCuK,QAA2BvN,GAC/BtoB,EACA0iB,GACA4E,EjB9IuB,IiBgJvBnZ,GAIF,gBAAiB2nB,KAAcD,EAAoB,CACjDn2B,KAAKkjB,UAAUb,WACb,cACA,QAAQ/hB,OACRN,KAAK0tB,gBAAgBX,cAAc,IAGrC,MAAMjE,EAAQsN,EAAWl1B,IAAIskB,KAErBgG,cAAe6K,EAAkBriB,YAAasiB,GACpDlD,GAAgBtK,EAAOyB,EAAWiB,EAAexX,GAInD,GAAI8U,EAAMtc,OAAS,EAAG,CACpB,MAAMmnB,EAAWd,GAAY/J,EAAMuC,IAAI,IACjCkL,EAA4B5C,EAAUjf,gBAEtC+Q,GAAezlB,KAAK0N,GAAIykB,cAAe1jB,EAAvCgX,CAA+CqD,GAErD,MAAM5U,EAAY4U,EAAM5nB,KAAKwoB,GAAMA,EAAEnV,WAC/BvU,KAAKipB,kBAAmBI,aAC5BnV,EACAiM,GAAcmS,MAGhB,MAAMlB,EAAc,CAClBlc,QAASqV,EACTlW,UAAWX,GAAUY,KACrBvR,GAAIzC,EACJ0oB,gBAAiB1B,KAAKqE,IACpB4K,EACA1K,GAEF7X,YAAasiB,EACb9K,cAAe6K,EACfjK,UAAU,EACVthB,KAAM,IACD6oB,EACH/H,uBAAwB2K,EACxB1K,8BAIEpG,GAAezlB,KAAK0N,GAAI2e,cAAe5d,EAAvCgX,CAA+C2L,GAErD8E,EAAYpqB,KAAKslB,EACnB,CACF,CACF,CAAE,MAAO1e,GAIP,GAHA1S,KAAK4tB,SAASzhB,MAAM,qBAAqB7L,UAAiB,CACxD6L,MAAOuG,IAEJkhB,GAAiBlhB,GAIpB,MADAwjB,EAAc,GACRxjB,EAHN1S,KAAKkjB,UAAUb,WAAW,QAAS3P,EAAItR,WAK3C,CAAE,QAEApB,KAAKoiB,WAAW5H,gBAAgB0b,EAClC,CACF,G,iDC5MK,MAAM,GAAexpB,GAC1B,IAAI6D,SAAQ,CAACC,EAASgmB,KACpB,MAEMC,EAFa,IAAI,KAAJ,CAAW,OAAQ,GAAOnqB,KAAKI,IAExBgqB,UAC1B,GAAAC,QAAA,OAAeF,GAAQ,CAAC/jB,EAAKkkB,KACvBlkB,GACF8jB,EAAO,IAAI3b,MAAM,+BAGnB,YAAY+b,GAAS,CAACzqB,EAAO9K,KAC3BmP,EAAQnP,EAAIw1B,sBAAsB,GAClC,GACF,I,yBCJN,MAAMjJ,IAAW,QAAoB,CACnCC,OAAQ,OACR2C,KAAM,6BAIKsG,GAA4B,CACvCC,EACAz2B,EACA02B,EACAvoB,IAEO,IAAI+P,GAAA,GAAiCkR,IAC1CA,EAAWtwB,KAAK,CAAEoX,OAAQ,QAASqH,MAAO,KAE1C,WACE,MAAMoZ,QAAwBF,EAAMG,aAAa52B,GAEjDovB,EAAWtwB,KAAK,CAAEoX,OAAQ,MAAOqH,MAAOoZ,IAExC,MAAME,EAAsB,IAAIpb,IAC9Bkb,EAAgB/1B,KAAKmB,GAAM,CAACA,EAAEmS,SAAUnS,MAGpC+0B,EAAwB/1B,GAC5B81B,EAAoB/2B,IAAIiB,IAAQ,CAC9B6T,QAAS5U,EACTgF,KAAM,GACNuI,WAAW,EACXwpB,UAAU,GAGRC,OCxCmB72B,OAC7BH,EACAmO,KAaA,MAAMvO,QAAiB,EAAAq3B,GAAA,GAAM,CAC3BnnB,OAAQ,MACR2C,IAAK,GAAGtJ,0BAAgCnJ,4BAAkCyiB,sBAC1EtU,WAGF,OAAKvO,EAAS+F,KAAKuxB,IAGZt3B,EAAS+F,KAAKuxB,IAAIt2B,KACtB8F,GAASA,EAAKke,GAAGrZ,MAAMsK,IAAI,GAAGtK,MAAMid,MAAM,GAAGvU,KAHvC,EAIR,EDc6B,CAAgBjU,EAASmO,GAC7CgpB,OCZgBh3B,OAC1BH,EACAmO,KAEA,MAAMipB,QAAoB,GAAYp3B,GAEhCJ,QAAiB,EAAAq3B,GAAA,GAAM,CAC3BnnB,OAAQ,MACR2C,IAAK,GAAGtJ,gCAAsCsZ,2BAAmC2U,qBACjFjpB,WAGF,OAAKvO,EAAS+F,KAAKuxB,IAGZt3B,EAAS+F,KAAKuxB,IAAIt2B,KAAK8F,GAASA,EAAKke,GAAGrZ,MAAMsK,IAAI,GAAGtK,MAAMyJ,SAFzD,EAEgE,EDH7C,CAAahV,EAASmO,GAExCkpB,EAAkBL,EAAY1uB,QACjCvH,IAAS41B,EAAgB/gB,MAAM4B,GAAMA,EAAEtD,WAAanT,GAAOyW,EAAEjK,cAG1D+pB,EAAsBH,EAAU7uB,QACnCrG,IAAU00B,EAAgB/gB,MAAM4B,GAAMA,EAAExC,SAAW/S,GAAQuV,EAAEuf,aAGhEzJ,GAASK,KACP,uBAAuB3tB,wBAA8B22B,EAAgBzqB,yBAAyBmrB,EAAgBnrB,yBAAyBorB,EAAoBprB,UAG7J,MAAMqrB,QAA2BtnB,QAAQuT,IACvC8T,EAAoB12B,KAAIT,MAAO6U,IAC7B,MAAMjU,QAAY,GAAYiU,GAExBwiB,EAAgB,IACjBV,EAAqB/1B,GACxBmT,SAAUnT,EACViU,SACA+hB,UAAU,GAKZ,aAFMN,EAAMgB,aAAaD,GACzBX,EAAoBlZ,IAAI5c,EAAKy2B,GACtBA,CAAa,KAIxBpI,EAAWtwB,KAAK,CAAEoX,OAAQ,MAAOqH,MAAOga,UAElCtnB,QAAQuT,IACZ6T,EAAgBz2B,KAAIT,MAAOY,IACzB,MAAMiU,SAAgB0hB,EAAoB31B,EAAK8e,GAAcqE,UACzD7iB,QAAQ0M,YACZ,GAAIiH,GAAUA,EAAO7I,MAAM,GAAgB,CACzC,MAAMqrB,EAAgB,IACjBV,EAAqB/1B,GACxBiU,SACAd,SAAUnT,EACVwM,WAAW,SAGPkpB,EAAMgB,aAAaD,GACzBX,EAAoBlZ,IAAI5c,EAAKy2B,GAC7BpI,EAAWtwB,KAAK,CAAEoX,OAAQ,MAAOqH,MAAO,CAACia,IAC3C,MAIJlK,GAASK,KAAK,uBAAuB3tB,WAMrCovB,EAAWtwB,KAAK,CAAEoX,OAAQ,WAAYqH,MAAO,KAE7C6R,EAAWhR,UACZ,EA/ED,GA+EKjM,OAAOC,IACVkb,GAASzhB,MAAM,uBAAuB7L,WAAkB,CAAE6L,MAAOuG,IACjEgd,EAAWvjB,MAAMuG,EAAI,GACrB,IE3FN,MAAM,IAAW,QAAoB,CAAEmb,OAAQ,SAGxC,MAAMmK,GAOX7kB,YAAY8P,GAJZ,KAAQb,WAAa,IAAI,GAEzB,KAAQ6V,MAAsD,CAAC,EAG7D,MAAM,YAAE5U,EAAW,cAAE5H,GAAkBwH,EACvCjjB,KAAKujB,gBAAiB,EAAAC,GAAA,GAAc,CAACH,EAAa5H,IAAgBa,MAChE,EAAApb,GAAA,IAAI,EAAEuiB,EAAYC,OAAoBD,KAAgBC,KAGxD1jB,KAAKujB,eAAepH,UAAU,CAC5B/c,KAAOuC,GACEA,GAAU3B,KAAKoiB,WAAWhI,kBAAkB,OAAQ,WAE7DjO,MAAQuG,GAAQ1S,KAAKoiB,WAAWhI,kBAAkB,OAAQ,QAAS1H,KAGrE,MAAMuW,EAAoB,IAAI,GAAuBhG,GAAMpc,QAErDqxB,EC7BK,SACbjV,GAEA,MAAM,YAAEI,EAAW,cAAE5H,EAAa,QAAEsS,GAAY9K,EAC1C/I,EAAU,IAAI,GAEpB,OAAO,EAAAsJ,GAAA,GAAc,CACnBH,EACA0K,EAASzR,MACP,EAAApb,GAAA,IAAK2hB,GAAWA,EAAO0H,aACvB,EAAA+D,GAAA,MAEF7S,IACCa,MACD,EAAA1T,GAAA,IACE,EAAE6a,EAAY8G,EAAW7G,OACrBD,KAAgBC,KAAkB6G,KAExC,EAAA2D,GAAA,IAAU,EAAE6I,EAAOxM,EAAW7G,MAC5B,MAAM,uBAAEN,GAA2BH,EACnC,IAAIkV,EAA4B,GAChC,OAAO,IAAI3Z,GAAA,GAA4BC,IACrCA,EAASrf,KAAK,IAEd03B,GACEC,EACAxM,EACAnH,GACAjH,WAAU,EAAG3F,SAAQqH,YACrB3D,EAAQS,KAAK,CAAE/Y,KAAM,iBAAkBiK,MAAO,CAAE2K,SAAQqH,WAEzC,UAAXrH,EACF2hB,EAAY,GACH,CAAC,MAAO,YAAYjiB,MAAM5W,GAAMA,IAAMkX,KAC/C2hB,EAAUrsB,QAAQ+R,GAGL,aAAXrH,IACFiI,EAASrf,KAAK+4B,GACd1Z,EAASC,WACX,GACA,GACF,IAGR,CDhB2B0Z,CAAqBnV,GAC5CiV,EAAe/b,WAAWgc,IACxB,GAASlK,KAAK,2BAAyB,CACrCuC,KAAM,YACNvqB,KAAMkyB,GACN,IAGJ,MAAMrC,EAAcoC,EAAe5b,MACjC,EAAApb,GAAA,IAAKmB,GAAMA,EAAEuG,QAAQkP,GAAMA,EAAEjK,eAC7B,EAAA3M,GAAA,IAAKmB,GAAMA,EAAEnB,KAAK4W,GAAMA,EAAExC,YAK5B,IAAI,GAAqB,eAAgB2N,EAAMgG,GAAmBpiB,QAElE,IAAI,GACF,Y/B/DoC,I+BiEpCoc,EACAgG,GACApiB,QAEF,IAAI,GACF,a/BrEkC,I+BuElC,IAAKoc,EAAM6S,eACX7M,GAEApiB,OACJ,CAEOunB,QAAQ9oB,GACbtF,KAAKi4B,MAAM3yB,IAAO8oB,SACpB,E,0CEiBF,OA3EA,MASEjb,YAAYkQ,GARZ,KAAQxH,OAAS,IAAIC,GAAA,EAA0B,IAAIC,KASjDsH,EAAYlH,WAAWzO,IACrB1N,KAAK+2B,MAAQrpB,CAAE,IAGjB2V,EACG/G,MACC,EAAA1T,GAAA,IAAQ6a,KAAiBA,KACzB,EAAAU,GAAA,IAAI,IAAM,GAAO8J,KAAK,oCACtB,EAAAvR,GAAA,IAAS,IAAM1c,KAAK6b,UACpB,EAAAjT,GAAA,IAAQ4T,GAAUA,EAAM/a,KAAO,KAC/B,EAAAib,GAAA,IAAUF,IAAU,EAAAkU,GAAA,IAAM,KAAM,EAAApkB,GAAA,GAAKtM,KAAKq4B,aAAa7b,SAExDL,UAAU,CAEThQ,MAAQuG,GAAQ,GAAQvG,MAAM,8BAA+BuG,IAEnE,CArBW8J,YACT,OAAOxc,KAAK6b,OAAO8H,UACrB,CAqBOpF,mBAAmBtc,GACxB,IAAKA,EACH,OAEF,MAAM,IAAEZ,GAAQY,EAEhBjC,KAAK6b,OAAOzc,KAAK,IAAI2c,IAAI/b,KAAK6b,OAAOhQ,OAAOoS,IAAI5c,EAAK,CAAEY,YACzD,CAEOq2B,aAAaxP,GAClB,IAAKA,IAAUA,EAAMtc,OACnB,OAEF,MAAMzJ,GAAK,UACX/C,KAAK6b,OAAOzc,KAAK,IAAI2c,IAAI/b,KAAK6b,OAAOhQ,OAAOoS,IAAIlb,EAAI,CAAE+lB,UACxD,CAEA,mBAA2BtM,GAEzBxc,KAAK6b,OAAOzc,KAAK,IAAI2c,KAErB,UAAY1a,EAAK2F,KAASwV,QAElBxc,KAAKu4B,iBAAiBvxB,GAG5BwV,EAAMU,OAAO7b,EAGjB,CAEA,uBAA+B2c,GAC7B,MAAM,QAAE/b,EAAO,MAAE6mB,GAAU9K,EAE3B,GAAI/b,EAAS,CAEX,MAAMu2B,E9BhFuB,CAAChkB,IAClC,MAAM,IAAEnT,EAAG,OAAEM,EAAM,KAAEmJ,EAAI,YAAEuD,GAAgBmG,GACrC,KAAE/S,EAAI,KAAE+I,EAAI,KAAE5I,EAAI,OAAEG,EAAM,UAAEF,GAAciJ,EAGhD,MAAO,CACLzJ,MACAI,KAAMA,GAAQ,EACd+I,KAAMA,GAAQ,UACd5I,OACAoL,KANWqB,GAAaqkB,QAAQ,KAAM,MAAQ,GAO9C+F,WAAY52B,IAAc,EAC1BE,OAAQA,GAAU,EACnB,E8BmEkB22B,CAAoBz2B,SAC7BjC,KAAK+2B,MAAO4B,aAAaH,EACjC,CAEI1P,GAASA,EAAMtc,OAAS,SAEpBxM,KAAK+2B,MAAO5E,cAAcrJ,EAEpC,G,YC/DF,MAsGM8P,GAtG4B,MAChC,MAAMvV,EAAc,IAAIyL,GAAA,EAElBrT,EAAgB,IAAIK,GAAA,OAAyC,GAE7DiS,EAAU,IAAIjS,GAAA,EAAmC,CACrDyO,UAAW,OAGb,IAAIsO,EACJ,MAAMjd,EAAkB,IAAI,GAAgByH,GAEtCyV,EAAY,IAAI,GAAard,EAAe,CAChDG,oBAEImd,EAAe,IAAI,GAInBC,EAAc,IAAIhB,GAAY,CAClC5U,uBAAwB3iB,MACtBY,EACA+Z,EAA0B+E,GAAc4D,SACrC+U,EAAUrZ,eAAepe,EAAK,CAAEme,gBAAgB,EAAMpE,aAC3DiI,cACA5H,gBACAsS,YAoCIkL,EAAgB,CACpBC,iBAAmBpQ,IACjBlN,EAAgB0c,aAAaxP,EAAM,GAIjCqQ,EAAU,CACdtyB,MA5BgBpG,MAAO24B,IACvB,IAWE,OAVIP,IACF,GAAQ93B,IAAI,oCACN83B,EAASjyB,QAEjBmyB,EAAa3e,kBAAkB,OAAQ,YACvCye,QAAiBnnB,GAAa0nB,GAE9B3d,EAAcrc,KAAKy5B,GAEnB9pB,YAAW,IAAMgqB,EAAa3e,kBAAkB,OAAQ,YAAY,IAC7D,CACT,CAAE,MAAO1H,GACP,GAAQ3R,IAAI,4BAA6B2R,GACzC,MAAMyD,EAAMzD,aAAemI,MAAQnI,EAAIC,QAAWD,EAElD,MADAqmB,EAAa3e,kBAAkB,OAAQ,QAASjE,GAC1C0E,MAAM1E,EACd,GAWAvP,KArCenG,UACXo4B,SACIA,EAASjyB,OAEjB6U,EAAcrc,UAAK,GACnB25B,EAAa3e,kBAAkB,OAAQ,WAAW,EAiClDif,YAAa54B,SAAYo4B,IAAY,QAAMA,GAC3C94B,OAAQU,SAAYo4B,GAAU94B,OAC9BkuB,KAAMxtB,SAAYo4B,GAAU5K,OAC5BqL,iBAAkB74B,MAAOY,EAAa0Q,IACpC8mB,GAAUS,iBAAiBj4B,EAAK0Q,GAClCsN,QAAS5e,MACPY,EACA4b,EACAvc,IACGo4B,EAAWzZ,QAAQhe,EAAK4b,EAAUvc,GACvC+e,eAAgBhf,MAAOY,EAAaX,IAClCo4B,EAAWrZ,eAAepe,EAAKX,GACjC64B,QAAS94B,MAAOY,GAAgBy3B,EAAUnZ,OAAOte,GACjDm4B,gBAAiB/4B,MAAOof,GAAmBiZ,EAAUlZ,eAAeC,GACpE4Z,WAAYh5B,SAAYq4B,EAAUhZ,QAClC4Z,WAAYj5B,MAAOwB,GAA2B42B,GAAUa,WAAWz3B,IAGrE,MAAO,CACL6Q,KA7DWrS,MAAOk5B,IAClBtW,EAAYjkB,KAAKu6B,EAAW,EA6D5BtV,cAAe,MAAQ5I,EAAc5P,MAErCstB,SAAS,QAAMA,GACfF,eAAe,QAAMA,GACrBH,WAAW,QAAMA,GACjBc,YAAct0B,GAAwB0zB,EAAY5K,QAAQ9oB,GAC1Du0B,UAAYhX,GACVkL,EAAQ3uB,KAAK,IAAK2uB,EAAQliB,SAAUgX,IACvC,EAGsBiX,GtC3DlB,IAA4BrY,GAAoBsY,GAApBtY,GsCgEnBuY,KtChEuCD,GsCgEjCnB,GtC/DpBrX,UACgC,IAArBE,GAAOwY,UAChBxY,GAAOwY,UAAa3sB,IAClB,MAAM9M,EAAO8M,EAAE4sB,MAAM,GACrB1Y,GAAgBhhB,IAEhB,QAAOu5B,GAAKv5B,EAAK,GAInB,QAAOu5B,G,sEuCxFJ,MAEMI,EAAgC,yB,mHCE7C,MAAMC,EAAqB,GAoJpB,MAAMC,EAAsB,CACjCC,EAAyC,CAAC,KAE1C,MAAMpgB,EAAU,IAAIC,iBAAiB,MAErC,SAASogB,EACPC,EACA7nB,EACA8nB,GAEA,MAAMlK,EAAM,IAAK+J,KAAmBG,GAChCA,GAAStuB,QACXokB,EAAIpkB,MAAQmN,KAAKC,UAAUkhB,EAAQtuB,QAErC+N,EAAQG,YAAY,CAClBzY,KAAM,MACNiK,MAAO,CAAE2uB,QAAO7nB,UAAS8nB,QAASlK,IAEtC,CAkBA,MAAO,CAAEtC,KAhBT,SAAiBtb,EAAY8nB,GAC3B,OAAOF,EAAiB,OAAQ5nB,EAAS8nB,EAC3C,EAcetuB,MAZf,SAAkBwG,EAAY8nB,GAC5B,OAAOF,EAAiB,QAAS5nB,EAAS8nB,EAC5C,EAUsB7Y,KARtB,SAAiBjP,EAAY8nB,GAC3B,OAAOF,EAAiB,OAAQ5nB,EAAS8nB,EAC3C,EAM4BC,MAJ5B,SAAkB/nB,EAAY8nB,GAC5B,OAAOF,EAAiB,OAAQ5nB,EAAS8nB,EAC3C,EAEmC,EAG/BE,EAzLN,SAAyBL,EAAyC,CAAC,GAQjE,IAAIM,EAAmB,CAAC,EAyCxB,SAAS75B,EACPy5B,EACA7nB,EACA8nB,EAA2BH,GAE3B,IACE,MAAMO,EAAmBJ,GAASK,UAC9BL,GAASK,UAAUnoB,GACnBA,GAxDR,SAAmBooB,EAAkBC,GAAW,GAG9C,IAFAZ,EAAQtuB,KAAKivB,GAENC,GAAYZ,EAAQ5tB,OAAS,KAClC4tB,EAAQlN,OAEZ,CA4DI+N,CARiB,CACfvmB,UAAW,IAAIxF,KACfsrB,QACA7nB,QAASkoB,EACTK,WAAYT,GAASS,WACrBT,QAAS,SAAOA,EAAS,CAAC,YAAa,iBAKlBx1B,OAAOsS,KAAKqjB,GAAkBpjB,QACnD,CAACC,EAAc2H,KACb,MAAMyD,EAAS+X,EAAiBxb,GAC1B+b,EAAcV,EAAQrb,GAC5B,OAAIyD,GAAUsY,EAEV1jB,GACW,QAAXoL,GACkB,IAAlBA,EAAOrW,QACPqW,EAAO3M,MAAMklB,GAAMA,IAAMD,IAGtB1jB,CAAG,IAEZ,IA/DN,SACE+iB,EACA7nB,EACA8nB,GAEA,MAAMlK,EAAM,SAAOkK,EAAS,CAC1B,YACA,SACA,SACA,OACA,UAEI,OAAE5M,EAAS,UAAIC,EAAS,QAAI0C,EAAO,QAAIvqB,EAAO,IAAOw0B,EACrDY,GAAU,IAAA5K,SAAQF,GAAO,GAAKA,EAEhCrR,MAAMiU,QAAQxgB,GAChB7R,EAAQ05B,MAAU7nB,EAAS0oB,GAIzBZ,GAASK,UACXh6B,EAAQ05B,GAAOC,GAASK,UAAUnoB,GAAU0oB,GAI9Cv6B,EAAQ05B,GAAO,IAAI3M,KAAUC,KAAU0C,MAAS7d,IAAW1M,EAAMo1B,EACnE,CAyCMC,CAAWd,EAAO7nB,EAAS8nB,EAE/B,CAAE,MAAOtuB,GACPrL,EAAQC,IAAI,eAAgBoL,EAC9B,CACF,CAyCA,OA3HgB,IAAIgO,iBAAiB,MAE7BmG,UAAaC,IACK,WAApBA,EAAMta,KAAKrE,OACbg5B,EAAmB,IAAKA,KAAqBra,EAAMta,KAAK4F,OAC1D,EAsHK,CACL9K,MACAktB,KAzCF,SAAiBtb,EAAY8nB,GAC3B,OAAO15B,EAAI,OAAQ4R,EAAS8nB,EAC9B,EAwCEtuB,MAtCF,SAAkBwG,EAAY8nB,GAC5B,OAAO15B,EAAI,QAAS4R,EAAS8nB,EAC/B,EAqCE7Y,KAnCF,SAAiBjP,EAAY8nB,GAC3B,OAAO15B,EAAI,OAAQ4R,EAAS8nB,EAC9B,EAkCEC,MAhCF,SAAkB/nB,EAAY8nB,GAC5B,OAAO15B,EAAI,OAAQ4R,EAAS8nB,EAC9B,EA+BEL,UACAmB,QAAS,IA7BFnB,EAAQl5B,KAAK65B,IAClB,MAAM,QAAEN,KAAY7Z,GAASma,GACvB,KACJvK,EAAO,UACP1C,EAAS,UACTD,EAAS,QACT5nB,EAAO,GACPkG,MAAAA,EAAQ,cACR+uB,EAAa,IACXT,GAAW,CAAC,EAChB,MAAO,IACF7Z,EACH4P,OACA1C,SACAD,SACA5nB,OACAkG,MAAAA,EACA+uB,aACD,IAYHpb,MAAO,IAAMsa,EAAQoB,OAAO,EAAGpB,EAAQ5tB,QACvCivB,oBA5H0B,IAAMb,EA8HpC,CAyCec,CAAa,CAAE7N,OAAQ,SAMtC,K,gTCpMI8N,EAA2B,CAAC,EAGhC,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBE,IAAjBD,EACH,OAAOA,EAAaE,QAGrB,IAAIlO,EAAS6N,EAAyBE,GAAY,CACjD94B,GAAI84B,EACJI,QAAQ,EACRD,QAAS,CAAC,GAUX,OANAE,EAAoBL,GAAU5I,KAAKnF,EAAOkO,QAASlO,EAAQA,EAAOkO,QAASJ,GAG3E9N,EAAOmO,QAAS,EAGTnO,EAAOkO,OACf,CAGAJ,EAAoBO,EAAID,EAGxBN,EAAoBQ,EAAI,WAGvB,IAAIC,EAAsBT,EAAoBU,OAAEP,EAAW,CAAC,IAAI,IAAI,IAAI,IAAI,MAAM,WAAa,OAAOH,EAAoB,MAAQ,IAElI,OADAS,EAAsBT,EAAoBU,EAAED,EAE7C,ECrCAT,EAAoBW,KAAO,CAAC,E9EAxBt9B,EAAW,GACf28B,EAAoBU,EAAI,SAAS36B,EAAQ66B,EAAUtc,EAAI9E,GACtD,IAAGohB,EAAH,CAMA,IAAIC,EAAeC,IACnB,IAAS5kB,EAAI,EAAGA,EAAI7Y,EAASuN,OAAQsL,IAAK,CACrC0kB,EAAWv9B,EAAS6Y,GAAG,GACvBoI,EAAKjhB,EAAS6Y,GAAG,GACjBsD,EAAWnc,EAAS6Y,GAAG,GAE3B,IAJA,IAGIM,GAAY,EACPukB,EAAI,EAAGA,EAAIH,EAAShwB,OAAQmwB,MACpB,EAAXvhB,GAAsBqhB,GAAgBrhB,IAAanW,OAAOsS,KAAKqkB,EAAoBU,GAAGM,OAAM,SAASxd,GAAO,OAAOwc,EAAoBU,EAAEld,GAAKod,EAASG,GAAK,IAChKH,EAAShB,OAAOmB,IAAK,IAErBvkB,GAAY,EACTgD,EAAWqhB,IAAcA,EAAerhB,IAG7C,GAAGhD,EAAW,CACbnZ,EAASu8B,OAAO1jB,IAAK,GACrB,IAAI+kB,EAAI3c,SACE6b,IAANc,IAAiBl7B,EAASk7B,EAC/B,CACD,CACA,OAAOl7B,CArBP,CAJCyZ,EAAWA,GAAY,EACvB,IAAI,IAAItD,EAAI7Y,EAASuN,OAAQsL,EAAI,GAAK7Y,EAAS6Y,EAAI,GAAG,GAAKsD,EAAUtD,IAAK7Y,EAAS6Y,GAAK7Y,EAAS6Y,EAAI,GACrG7Y,EAAS6Y,GAAK,CAAC0kB,EAAUtc,EAAI9E,EAwB/B,E+E5BAwgB,EAAoBkB,EAAI,SAAShP,GAChC,IAAIiP,EAASjP,GAAUA,EAAOkP,WAC7B,WAAa,OAAOlP,EAAgB,OAAG,EACvC,WAAa,OAAOA,CAAQ,EAE7B,OADA8N,EAAoBqB,EAAEF,EAAQ,CAAE57B,EAAG47B,IAC5BA,CACR,E9EPI59B,EAAW8F,OAAOi4B,eAAiB,SAASxc,GAAO,OAAOzb,OAAOi4B,eAAexc,EAAM,EAAI,SAASA,GAAO,OAAOA,EAAIyc,SAAW,EAQpIvB,EAAoBlS,EAAI,SAAS7d,EAAOuxB,GAEvC,GADU,EAAPA,IAAUvxB,EAAQ7L,KAAK6L,IAChB,EAAPuxB,EAAU,OAAOvxB,EACpB,GAAoB,iBAAVA,GAAsBA,EAAO,CACtC,GAAW,EAAPuxB,GAAavxB,EAAMmxB,WAAY,OAAOnxB,EAC1C,GAAW,GAAPuxB,GAAoC,mBAAfvxB,EAAMnK,KAAqB,OAAOmK,CAC5D,CACA,IAAIwxB,EAAKp4B,OAAOq4B,OAAO,MACvB1B,EAAoBiB,EAAEQ,GACtB,IAAIE,EAAM,CAAC,EACXr+B,EAAiBA,GAAkB,CAAC,KAAMC,EAAS,CAAC,GAAIA,EAAS,IAAKA,EAASA,IAC/E,IAAI,IAAIq+B,EAAiB,EAAPJ,GAAYvxB,EAAyB,iBAAX2xB,KAAyBt+B,EAAekM,QAAQoyB,GAAUA,EAAUr+B,EAASq+B,GACxHv4B,OAAOw4B,oBAAoBD,GAAS9mB,SAAQ,SAAS0I,GAAOme,EAAIne,GAAO,WAAa,OAAOvT,EAAMuT,EAAM,CAAG,IAI3G,OAFAme,EAAa,QAAI,WAAa,OAAO1xB,CAAO,EAC5C+vB,EAAoBqB,EAAEI,EAAIE,GACnBF,CACR,E+ExBAzB,EAAoBqB,EAAI,SAASjB,EAAS0B,GACzC,IAAI,IAAIte,KAAOse,EACX9B,EAAoB+B,EAAED,EAAYte,KAASwc,EAAoB+B,EAAE3B,EAAS5c,IAC5Ena,OAAO24B,eAAe5B,EAAS5c,EAAK,CAAEye,YAAY,EAAMz9B,IAAKs9B,EAAWte,IAG3E,ECPAwc,EAAoBkC,EAAI,CAAC,EAGzBlC,EAAoBtuB,EAAI,SAASywB,GAChC,OAAOxtB,QAAQuT,IAAI7e,OAAOsS,KAAKqkB,EAAoBkC,GAAGtmB,QAAO,SAASwmB,EAAU5e,GAE/E,OADAwc,EAAoBkC,EAAE1e,GAAK2e,EAASC,GAC7BA,CACR,GAAG,IACJ,ECPApC,EAAoBqC,EAAI,SAASF,GAEhC,OAAgB,MAAZA,EAAwB,kBAEhBA,EAAU,IAAM,CAAC,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,YAAYA,GAAW,WAC/H,ECLAnC,EAAoBsC,SAAW,SAASH,GAGxC,ECJAnC,EAAoBuC,EAAI,WACvB,GAA0B,iBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAOp+B,MAAQ,IAAIq+B,SAAS,cAAb,EAChB,CAAE,MAAO/wB,GACR,GAAsB,iBAAX1M,OAAqB,OAAOA,MACxC,CACA,CAPuB,GCAxBg7B,EAAoB+B,EAAI,SAASjd,EAAK4d,GAAQ,OAAOr5B,OAAO+V,UAAUgY,eAAeC,KAAKvS,EAAK4d,EAAO,ECCtG1C,EAAoBiB,EAAI,SAASb,GACX,oBAAXhwB,QAA0BA,OAAOuyB,aAC1Ct5B,OAAO24B,eAAe5B,EAAShwB,OAAOuyB,YAAa,CAAE1yB,MAAO,WAE7D5G,OAAO24B,eAAe5B,EAAS,aAAc,CAAEnwB,OAAO,GACvD,ECNA+vB,EAAoB4C,IAAM,SAAS1Q,GAGlC,OAFAA,EAAO2Q,MAAQ,GACV3Q,EAAO4Q,WAAU5Q,EAAO4Q,SAAW,IACjC5Q,CACR,ECJA8N,EAAoBR,EAAI,I,WCIxB,IAAIuD,EAAkB,CACrB,IAAK,GAkBN/C,EAAoBkC,EAAEhmB,EAAI,SAASimB,EAASC,GAEvCW,EAAgBZ,IAElBa,cAAchD,EAAoBR,EAAIQ,EAAoBqC,EAAEF,GAG/D,EAEA,IAAIc,EAAqB7E,KAAsB,gBAAIA,KAAsB,iBAAK,GAC1E8E,EAA6BD,EAAmB/yB,KAAKogB,KAAK2S,GAC9DA,EAAmB/yB,KAzBA,SAAS7F,GAC3B,IAAIu2B,EAAWv2B,EAAK,GAChB84B,EAAc94B,EAAK,GACnB+4B,EAAU/4B,EAAK,GACnB,IAAI,IAAI41B,KAAYkD,EAChBnD,EAAoB+B,EAAEoB,EAAalD,KACrCD,EAAoBO,EAAEN,GAAYkD,EAAYlD,IAIhD,IADGmD,GAASA,EAAQpD,GACdY,EAAShwB,QACdmyB,EAAgBnC,EAASyC,OAAS,EACnCH,EAA2B74B,EAC5B,C,IvFtBI7G,EAAOw8B,EAAoBQ,EAC/BR,EAAoBQ,EAAI,WACvB,OAAO7rB,QAAQuT,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,KAAK5iB,IAAI06B,EAAoBtuB,EAAGsuB,IAAsBl6B,KAAKtC,EAChG,EwFF0Bw8B,EAAoBQ,G","sources":["webpack://cyb/webpack/runtime/chunk loaded","webpack://cyb/webpack/runtime/create fake namespace object","webpack://cyb/webpack/runtime/startup chunk dependencies","webpack://cyb/./src/services/ipfs/utils/cid.ts","webpack://cyb/./src/services/ipfs/config.ts","webpack://cyb/./src/services/ipfs/node/impl/kubo.ts","webpack://cyb/./src/services/ipfs/node/impl/helia.ts","webpack://cyb/./src/services/ipfs/node/impl/configs/jsIpfsConfig.ts","webpack://cyb/./src/services/ipfs/node/impl/js-ipfs.ts","webpack://cyb/./src/types/networks.ts","webpack://cyb/./src/constants/defaultNetworks.ts","webpack://cyb/./src/constants/config.ts","webpack://cyb/./src/constants/patterns.ts","webpack://cyb/./src/services/ipfs/utils/stream.ts","webpack://cyb/./src/services/ipfs/utils/content.ts","webpack://cyb/./src/db.js","webpack://cyb/./src/services/ipfs/utils/ipfsCacheDb.ts","webpack://cyb/./src/services/ipfs/utils/cluster.ts","webpack://cyb/./src/services/ipfs/utils/utils-ipfs.ts","webpack://cyb/./src/services/ipfs/node/factory.ts","webpack://cyb/./src/services/ipfs/node/mixins/withCybFeatures.ts","webpack://cyb/./src/services/QueueManager/QueueStrategy.ts","webpack://cyb/./src/features/particle/utils.tsx","webpack://cyb/./src/services/CozoDb/types/entities.ts","webpack://cyb/./src/features/sense/redux/sense.redux.ts","webpack://cyb/./src/constants/localStorageKeys.ts","webpack://cyb/./src/redux/features/pocket.ts","webpack://cyb/./src/utils/config.ts","webpack://cyb/./src/services/backend/channels/BroadcastChannelSender.ts","webpack://cyb/./src/services/backend/channels/consts.ts","webpack://cyb/./src/services/QueueManager/QueueItemTimeoutError.ts","webpack://cyb/./src/services/QueueManager/constants.ts","webpack://cyb/./src/services/QueueManager/QueueManager.ts","webpack://cyb/./src/utils/rxjs/helpers.ts","webpack://cyb/./src/services/QueueManager/types.ts","webpack://cyb/./src/services/backend/workers/serializers.ts","webpack://cyb/./src/services/backend/workers/factoryMethods.ts","webpack://cyb/./src/services/backend/channels/broadcastStatus.ts","webpack://cyb/./src/utils/async/iterable.ts","webpack://cyb/./src/constants/app.ts","webpack://cyb/./src/services/backend/services/sync/services/consts.ts","webpack://cyb/./src/services/backend/services/sync/services/ParticlesResolverQueue/ParticlesResolverQueue.ts","webpack://cyb/./src/utils/date.ts","webpack://cyb/./src/services/CozoDb/mapping.ts","webpack://cyb/./src/utils/async/promise.ts","webpack://cyb/./src/generated/graphql.ts","webpack://cyb/./src/services/backend/services/indexer/types.ts","webpack://cyb/./src/services/lcd/utils/mapping.ts","webpack://cyb/./src/services/backend/services/indexer/utils/graphqlClient.ts","webpack://cyb/./src/services/backend/services/indexer/cyberlinks.ts","webpack://cyb/./src/services/backend/services/indexer/consts.ts","webpack://cyb/./src/services/backend/services/sync/services/utils/links.ts","webpack://cyb/./src/services/backend/services/indexer/transactions.ts","webpack://cyb/./src/services/backend/services/sync/services/utils/sense.ts","webpack://cyb/./src/services/backend/services/sync/services/SyncTransactionsLoop/services/chat.ts","webpack://cyb/./src/services/backend/services/sync/services/ProgressTracker/ProgressTracker.ts","webpack://cyb/./src/services/backend/services/sync/services/BaseSyncLoop/BaseSync.ts","webpack://cyb/./src/services/backend/services/sync/services/utils/rxjs/withInitializer.ts","webpack://cyb/./src/services/backend/services/sync/services/BaseSyncLoop/BaseSyncClient.ts","webpack://cyb/./src/services/backend/services/sync/services/SyncTransactionsLoop/SyncTransactionsLoop.ts","webpack://cyb/./src/services/lcd/websocket.ts","webpack://cyb/./src/utils/dto.ts","webpack://cyb/./src/services/backend/services/sync/utils.ts","webpack://cyb/./src/utils/exceptions/helpers.ts","webpack://cyb/./src/services/backend/services/sync/services/BaseSyncLoop/BaseSyncLoop.ts","webpack://cyb/./src/services/backend/services/sync/services/utils/rxjs/loop.ts","webpack://cyb/./src/services/backend/services/sync/services/SyncParticlesLoop/SyncParticlesLoop.ts","webpack://cyb/./src/services/backend/services/sync/services/SyncMyFriendsLoop/SyncMyFriendsLoop.ts","webpack://cyb/./src/utils/ipfs/helpers.ts","webpack://cyb/./src/services/community/community.ts","webpack://cyb/./src/services/community/lcd.ts","webpack://cyb/./src/services/backend/services/sync/sync.ts","webpack://cyb/./src/services/backend/services/sync/services/CommunitySync/CommunitySync.ts","webpack://cyb/./src/services/backend/services/DeferredDbSaver/DeferredDbSaver.ts","webpack://cyb/./src/services/backend/workers/background/worker.ts","webpack://cyb/./src/utils/logging/constants.ts","webpack://cyb/./src/utils/logging/cyblog.ts","webpack://cyb/webpack/bootstrap","webpack://cyb/webpack/runtime/amd options","webpack://cyb/webpack/runtime/compat get default export","webpack://cyb/webpack/runtime/define property getters","webpack://cyb/webpack/runtime/ensure chunk","webpack://cyb/webpack/runtime/get javascript chunk filename","webpack://cyb/webpack/runtime/get mini-css chunk filename","webpack://cyb/webpack/runtime/global","webpack://cyb/webpack/runtime/hasOwnProperty shorthand","webpack://cyb/webpack/runtime/make namespace object","webpack://cyb/webpack/runtime/node module decorator","webpack://cyb/webpack/runtime/publicPath","webpack://cyb/webpack/runtime/importScripts chunk loading","webpack://cyb/webpack/startup"],"sourcesContent":["var deferred = [];\n__webpack_require__.O = function(result, chunkIds, fn, priority) {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every(function(key) { return __webpack_require__.O[key](chunkIds[j]); })) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","var getProto = Object.getPrototypeOf ? function(obj) { return Object.getPrototypeOf(obj); } : function(obj) { return obj.__proto__; };\nvar leafPrototypes;\n// create a fake namespace object\n// mode & 1: value is a module id, require it\n// mode & 2: merge all properties of value into the ns\n// mode & 4: return value when already ns object\n// mode & 16: return value when it's Promise-like\n// mode & 8|1: behave like require\n__webpack_require__.t = function(value, mode) {\n\tif(mode & 1) value = this(value);\n\tif(mode & 8) return value;\n\tif(typeof value === 'object' && value) {\n\t\tif((mode & 4) && value.__esModule) return value;\n\t\tif((mode & 16) && typeof value.then === 'function') return value;\n\t}\n\tvar ns = Object.create(null);\n\t__webpack_require__.r(ns);\n\tvar def = {};\n\tleafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];\n\tfor(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {\n\t\tObject.getOwnPropertyNames(current).forEach(function(key) { def[key] = function() { return value[key]; }; });\n\t}\n\tdef['default'] = function() { return value; };\n\t__webpack_require__.d(ns, def);\n\treturn ns;\n};","var next = __webpack_require__.x;\n__webpack_require__.x = function() {\n\treturn Promise.all([385,775,746,356,975].map(__webpack_require__.e, __webpack_require__)).then(next);\n};","import { CID } from 'multiformats/cid';\n\nexport const stringToCid = (s: string) => CID.parse(s);\nexport const stringToIpfsPath = (s: string) => `/ipfs/${s}`;\n","import { IPFSNodes, IpfsOptsType } from './types';\n\nexport const CYBER_NODE_SWARM_PEER_ID =\n  'QmUgmRxoLtGERot7Y6G7UyF6fwvnusQZfGR15PuE6pY3aB';\n\nexport const CYBERNODE_SWARM_ADDR_WSS = `/dns4/swarm.io.cybernode.ai/tcp/443/wss/p2p/${CYBER_NODE_SWARM_PEER_ID}`;\nexport const CYBERNODE_SWARM_ADDR_TCP = `/ip4/88.99.105.146/tcp/4001/p2p/${CYBER_NODE_SWARM_PEER_ID}`;\n\nexport const IPFS_CLUSTER_URL = 'https://io.cybernode.ai';\n\nexport const CYBER_GATEWAY_URL = 'https://gateway.ipfs.cybernode.ai';\n\nexport const FILE_SIZE_DOWNLOAD = 20 * 10 ** 6;\n\nexport const getIpfsOpts = () => {\n  let ipfsOpts: IpfsOptsType = {\n    ipfsNodeType: IPFSNodes.HELIA,\n    urlOpts: '/ip4/127.0.0.1/tcp/5001', // default url\n    userGateway: 'http://127.0.0.1:8080',\n  };\n\n  // get type ipfs\n  const lsTypeIpfs = localStorage.getItem('ipfsState');\n  if (lsTypeIpfs !== null) {\n    const lsTypeIpfsData = JSON.parse(lsTypeIpfs);\n    ipfsOpts = { ...ipfsOpts, ...lsTypeIpfsData };\n  }\n\n  localStorage.setItem('ipfsState', JSON.stringify(ipfsOpts));\n\n  return ipfsOpts as IpfsOptsType;\n};\n","import { IPFSHTTPClient, create as createKuboClient } from 'kubo-rpc-client';\nimport { multiaddr } from '@multiformats/multiaddr';\n\nimport { stringToCid, stringToIpfsPath } from '../../utils/cid';\nimport {\n  AbortOptions,\n  CatOptions,\n  IpfsNodeType,\n  InitOptions,\n  IpfsFileStats,\n  IpfsNode,\n  IpfsNodePrperties,\n} from '../../types';\nimport { CYBER_GATEWAY_URL } from '../../config';\n\nclass KuboNode implements IpfsNode {\n  readonly nodeType: IpfsNodeType = 'external';\n\n  private node?: IPFSHTTPClient;\n\n  private _config: IpfsNodePrperties = {};\n\n  get config() {\n    return this._config;\n  }\n\n  private _isStarted: boolean = false;\n\n  get isStarted() {\n    return this._isStarted;\n  }\n\n  private async initConfig() {\n    const response = await this.node!.config.get('Addresses.Gateway');\n    if (!response) {\n      return { gatewayUrl: CYBER_GATEWAY_URL };\n    }\n    const address = multiaddr(response as string).nodeAddress();\n\n    return { gatewayUrl: `http://${address.address}:${address.port}` };\n  }\n\n  async init(options?: InitOptions) {\n    this.node = createKuboClient(options);\n    this._config = await this.initConfig();\n\n    if (typeof window !== 'undefined') {\n      window.node = this.node;\n      window.toCid = stringToCid;\n    }\n    console.log(\n      'IPFS - Kubo addrs',\n      (await this.node.swarm.localAddrs()).map((a) => a.toString())\n    );\n    this._isStarted = true;\n  }\n\n  async stat(cid: string, options: AbortOptions = {}): Promise<IpfsFileStats> {\n    return this.node!.files.stat(stringToIpfsPath(cid), {\n      ...options,\n      withLocal: true,\n      size: true,\n    }).then((result) => {\n      const { type, size, sizeLocal, local, blocks } = result;\n      return {\n        type,\n        size: size || -1,\n        sizeLocal: sizeLocal || -1,\n        blocks,\n      };\n    });\n  }\n\n  cat(cid: string, options: CatOptions = {}) {\n    return this.node!.cat(stringToCid(cid), options);\n  }\n\n  async add(content: File | string, options: AbortOptions = {}) {\n    return (await this.node!.add(content, options)).cid.toString();\n  }\n\n  async pin(cid: string, options: AbortOptions = {}) {\n    return (await this.node!.pin.add(stringToCid(cid), options)).toString();\n  }\n\n  async getPeers() {\n    return (await this.node!.swarm.peers()).map((c) => c.peer.toString());\n  }\n\n  async stop() {}\n  async start() {}\n\n  async connectPeer(address: string) {\n    const addr = multiaddr(address);\n    await this.node!.bootstrap.add(addr);\n\n    await this.node!.swarm.connect(addr);\n    return true;\n  }\n\n  ls() {\n    return this.node!.pin.ls();\n  }\n\n  async info() {\n    const { repoSize } = await this.node!.stats.repo();\n\n    const responseId = await this.node!.id();\n    const { agentVersion, id } = responseId;\n    return { id: id.toString(), agentVersion, repoSize };\n  }\n}\n\n// eslint-disable-next-line import/no-unused-modules\nexport default KuboNode;\n","import { Helia, Pin, createHelia } from 'helia';\nimport { IDBBlockstore } from 'blockstore-idb';\nimport { IDBDatastore } from 'datastore-idb';\nimport { Libp2p, createLibp2p } from 'libp2p';\nimport { noise } from '@chainsafe/libp2p-noise';\nimport { yamux } from '@chainsafe/libp2p-yamux';\n// import { mplex } from '@libp2p/mplex';\n\nimport { circuitRelayTransport } from 'libp2p/circuit-relay';\nimport { UnixFS, unixfs, AddOptions } from '@helia/unixfs';\nimport { bootstrap } from '@libp2p/bootstrap';\nimport { webRTC, webRTCDirect } from '@libp2p/webrtc';\nimport { webSockets } from '@libp2p/websockets';\nimport { webTransport } from '@libp2p/webtransport';\nimport { identifyService } from 'libp2p/identify';\nimport { multiaddr, protocols } from '@multiformats/multiaddr';\nimport { LsResult } from 'ipfs-core-types/src/pin';\n\nimport {\n  AbortOptions,\n  CatOptions,\n  IpfsNodeType,\n  IpfsFileStats,\n  IpfsNode,\n} from '../../types';\n// import { all } from '@libp2p/websockets/filters';\nimport { stringToCid } from '../../utils/cid';\nimport { CYBER_GATEWAY_URL } from '../../config';\n\nasync function* mapToLsResult(\n  iterable: AsyncIterable<Pin>\n): AsyncIterable<LsResult> {\n  // eslint-disable-next-line no-restricted-syntax\n  for await (const item of iterable) {\n    const { cid, metadata } = item;\n    yield { cid: cid.toV0(), metadata, type: 'recursive' };\n  }\n}\n\nconst libp2pFactory = async (\n  datastore: IDBDatastore,\n  bootstrapList: string[] = []\n) => {\n  const libp2p = await createLibp2p({\n    datastore,\n    // addresses: {\n    //   listen: [\n    //     '/ip4/127.0.0.1/tcp/0',\n    //     '/dns4/swarm.io.cybernode.ai/tcp/443/wss/p2p/QmUgmRxoLtGERot7Y6G7UyF6fwvnusQZfGR15PuE6pY3aB',\n    //   ],\n    // },\n    transports: [\n      webSockets(),\n      webTransport(),\n      webRTC({\n        rtcConfiguration: {\n          iceServers: [\n            {\n              urls: [\n                'stun:stun.l.google.com:19302',\n                'stun:global.stun.twilio.com:3478',\n                'STUN:freestun.net:3479',\n                'STUN:stun.bernardoprovenzano.net:3478',\n                'STUN:stun.aa.net.uk:3478',\n              ],\n            },\n            {\n              credential: 'free',\n              username: 'free',\n              urls: ['TURN:freestun.net:3479', 'TURNS:freestun.net:5350'],\n            },\n          ],\n        },\n      }),\n      webRTCDirect(),\n      circuitRelayTransport({\n        discoverRelays: 1,\n      }),\n    ],\n    connectionEncryption: [noise()],\n    streamMuxers: [yamux()],\n    connectionGater: {\n      denyDialMultiaddr: () => {\n        return false;\n        // by default we refuse to dial local addresses from the browser since they\n        // are usually sent by remote peers broadcasting undialable multiaddrs but\n        // here we are explicitly connecting to a local node so do not deny dialing\n        // any discovered address\n      },\n    },\n    peerDiscovery: [\n      bootstrap({\n        list: bootstrapList,\n      }),\n    ],\n    services: {\n      identify: identifyService(),\n    },\n  });\n  return libp2p;\n};\n\nconst addOptionsV0: Partial<AddOptions> = {\n  cidVersion: 0,\n  rawLeaves: false,\n};\n\nclass HeliaNode implements IpfsNode {\n  readonly nodeType: IpfsNodeType = 'helia';\n\n  get config() {\n    return { gatewayUrl: CYBER_GATEWAY_URL };\n  }\n\n  private _isStarted = false;\n\n  get isStarted() {\n    return this._isStarted;\n  }\n\n  private node?: Helia;\n\n  private fs?: UnixFS;\n\n  async init() {\n    const blockstore = new IDBBlockstore('helia-bs');\n    await blockstore.open();\n\n    const datastore = new IDBDatastore('helia-ds');\n    await datastore.open();\n\n    const bootstrapList = [\n      '/dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN',\n      '/dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa',\n      '/dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb',\n      '/dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt',\n      '/dns4/swarm.io.cybernode.ai/tcp/443/wss/p2p/QmUgmRxoLtGERot7Y6G7UyF6fwvnusQZfGR15PuE6pY3aB',\n    ];\n    const libp2p = await libp2pFactory(datastore, bootstrapList);\n\n    this.node = await createHelia({ blockstore, datastore, libp2p });\n\n    this.fs = unixfs(this.node);\n\n    if (typeof window !== 'undefined') {\n      window.libp2p = libp2p;\n      window.node = this.node;\n      window.fs = this.fs;\n      window.toCid = stringToCid;\n    }\n\n    // DEBUG\n    libp2p.addEventListener('peer:connect', (evt) => {\n      const peerId = evt.detail.toString();\n      const conn = libp2p.getConnections(peerId) || [];\n      const transportsByAddr = Object.fromEntries(\n        conn.map((c) => [\n          c.remoteAddr.toString(),\n          c.remoteAddr.protoCodes().map((v) => protocols(v)?.name),\n        ])\n      );\n      console.debug(`Connected to ${peerId}`, transportsByAddr);\n\n      // console.log(\n      //   '---------ppppp',\n      //   peerId,\n      //   conn,\n      //   conn?.remoteAddr.protoCodes().map((v) => protocols(v)?.name)\n      // ); //.includes(WEBRTC_CODE)\n      // if (conn && conn.stat) {\n      //   const transport = conn.stat.transport; // This might vary based on libp2p version\n      //   console.log(`Connected to ${peerId} using transport ${transport}`);\n      // } else {\n      //   console.log(`Connected to ${peerId}`);\n      // }\n    });\n    libp2p.addEventListener('peer:disconnect', (evt) => {\n      console.debug(`Disconnected from ${evt.detail.toString()}`);\n    });\n    console.log(\n      'IPFS - Helia addrs',\n      libp2p.getMultiaddrs().map((a) => a.toString())\n    );\n    // const webrtcConn = await libp2p.dial(\n    //   multiaddr(\n    //     '/ip4/127.0.0.1/udp/4001/quic-v1/webtransport/certhash/uEiDHumbyZRFV1Av7qH9-2l5HGgU2a2UqM6eloqO0vYz5pQ/certhash/uEiDD_TuVgih5_ua31Z4MVbNq7WSw095UAQmZqdUFMDTVRA/p2p/12D3KooWEYGfgK4dEY3spfuDKVq6Jpiyj4KxP1r6HS5RFp5WHebz'\n    //   )\n    // );\n    // console.log('----webrtcConn', webrtcConn);\n\n    this._isStarted = true;\n  }\n\n  async stat(cid: string, options: AbortOptions = {}): Promise<IpfsFileStats> {\n    return this.fs!.stat(stringToCid(cid), options).then((result) => {\n      const { type, fileSize, localFileSize, blocks, dagSize, mtime } = result;\n      return {\n        type,\n        size: fileSize || -1,\n        sizeLocal: localFileSize || -1,\n        blocks,\n      };\n    });\n  }\n\n  cat(cid: string, options: CatOptions = {}) {\n    return this.fs!.cat(stringToCid(cid), options);\n  }\n\n  async add(content: File | string, options: AbortOptions = {}) {\n    // Options to keep CID in V0 format 'Qm....';\n    const optionsV0 = {\n      ...options,\n      ...addOptionsV0,\n    } as Partial<AddOptions>;\n\n    let cid;\n\n    if (content instanceof File) {\n      const fileName = content.name;\n      const arrayBuffer = await content.arrayBuffer();\n      const data = new Uint8Array(arrayBuffer);\n      cid = await this.fs!.addFile(\n        { path: fileName, content: data },\n        optionsV0\n      );\n    } else {\n      const data = new TextEncoder().encode(content);\n      cid = await this.fs!.addBytes(data, optionsV0);\n    }\n    // console.log('----added to helia', cid.toString());\n    this.pin(cid.toString(), options);\n    return cid.toString();\n  }\n\n  async pin(cid: string, options: AbortOptions = {}) {\n    const cid_ = stringToCid(cid);\n    const isPinned = await this.node?.pins.isPinned(cid_, options);\n    if (!isPinned) {\n      const pinResult = (\n        await this.node?.pins.add(cid_, options)\n      )?.cid.toString();\n      // console.log('------pin', pinResult);\n    }\n    // console.log('------pinned', cid, isPinned);\n    return undefined;\n  }\n\n  async getPeers() {\n    return this.node!.libp2p!.getConnections().map((c) =>\n      c.remotePeer.toString()\n    );\n  }\n\n  async stop() {\n    await this.node?.stop();\n  }\n\n  async start() {\n    await this.node?.start();\n  }\n\n  async connectPeer(address: string) {\n    const conn = await this.node!.libp2p!.dial(multiaddr(address));\n    return true;\n  }\n\n  ls() {\n    const result = mapToLsResult(this.node!.pins.ls());\n    return result;\n  }\n\n  async info() {\n    const id = this.node!.libp2p.peerId.toString();\n    const agentVersion = this.node!.libp2p!.services!.identify!.host!\n      .agentVersion as string;\n    return { id, agentVersion, repoSize: -1 };\n  }\n}\n\n// eslint-disable-next-line import/no-unused-modules\nexport default HeliaNode;\n","// eslint-disable-next-line import/no-unresolved\nimport { webSockets } from '@libp2p/websockets';\nimport * as filters from '@libp2p/websockets/filters';\nimport { Options } from 'ipfs-core/dist/src/types';\n\nconst configIpfs = (): Options => ({\n  start: true,\n  repo: 'ipfs-repo-cyber-v2',\n  relay: {\n    enabled: false,\n    hop: {\n      enabled: false,\n    },\n  },\n  preload: {\n    enabled: false,\n  },\n  config: {\n    API: {\n      HTTPHeaders: {\n        'Access-Control-Allow-Methods': ['PUT', 'POST'],\n        'Access-Control-Allow-Origin': [\n          'http://localhost:3000',\n          'http://127.0.0.1:5001',\n          'http://127.0.0.1:8888',\n          'http://localhost:8888',\n        ],\n      },\n    },\n    Addresses: {\n      Gateway: '/ip4/127.0.0.1/tcp/8080',\n      Swarm: [\n        // '/dns4/ws-star.discovery.cybernode.ai/tcp/443/wss/p2p-webrtc-star',\n        // '/dns4/wrtc-star1.par.dwebops.pub/tcp/443/wss/p2p-webrtc-star',\n        // '/dns4/wrtc-star2.sjc.dwebops.pub/tcp/443/wss/p2p-webrtc-star',\n      ],\n      Delegates: [\n        // '/dns4/node0.delegate.ipfs.io/tcp/443/https',\n        // '/dns4/node1.delegate.ipfs.io/tcp/443/https',\n        // '/dns4/node2.delegate.ipfs.io/tcp/443/https',\n      ],\n    },\n    Discovery: {\n      MDNS: {\n        Enabled: true,\n        Interval: 10,\n      },\n      webRTCStar: {\n        Enabled: false,\n      },\n    },\n    Bootstrap: [\n      // '/dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN',\n      // '/dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb',\n      // '/dnsaddr/bootstrap.libp2p.io/p2p/QmZa1sAxajnQjVM8WjWXoMbmPd7NsWhfKsPkErzpm9wGkp',\n      // '/dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa',\n      // '/dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt',\n      // '/dns4/ws-star.discovery.cybernode.ai/tcp/4430/wss/p2p/QmUgmRxoLtGERot7Y6G7UyF6fwvnusQZfGR15PuE6pY3aB',\n    ],\n    Pubsub: {\n      Enabled: false,\n    },\n    Swarm: {\n      ConnMgr: {\n        HighWater: 300,\n        LowWater: 50,\n      },\n      DisableNatPortMap: false,\n    },\n    Routing: {\n      Type: 'dhtclient',\n    },\n  },\n  libp2p: {\n    transports: [\n      // This is added for local demo!\n      // In a production environment the default filter should be used\n      // where only DNS + WSS addresses will be dialed by websockets in the browser.\n      webSockets({\n        filter: filters.dnsWss,\n      }),\n    ],\n    nat: {\n      enabled: false,\n    },\n  },\n  EXPERIMENTAL: {\n    ipnsPubsub: false,\n  },\n});\n\nexport default configIpfs;\n","import {\n  AbortOptions,\n  CatOptions,\n  IpfsNodeType,\n  IpfsFileStats,\n  IpfsNode,\n  IpfsNodePrperties,\n} from '../../types';\nimport { create as createJsIpfsClient, IPFS } from 'ipfs-core';\nimport { stringToCid, stringToIpfsPath } from '../../utils/cid';\nimport { multiaddr } from '@multiformats/multiaddr';\n\nimport configIpfs from './configs/jsIpfsConfig';\nimport { CYBER_GATEWAY_URL } from '../../config';\n\nclass JsIpfsNode implements IpfsNode {\n  readonly nodeType: IpfsNodeType = 'embedded';\n\n  get config() {\n    return { gatewayUrl: CYBER_GATEWAY_URL };\n  }\n\n  private _isStarted: boolean = false;\n\n  get isStarted() {\n    return this._isStarted;\n  }\n\n  private node?: IPFS;\n\n  async init() {\n    this.node = await createJsIpfsClient(configIpfs());\n    if (typeof window !== 'undefined') {\n      window.node = this.node;\n      window.toCid = stringToCid;\n    }\n\n    this._isStarted = true;\n  }\n\n  async stat(cid: string, options: AbortOptions = {}): Promise<IpfsFileStats> {\n    return this.node!.files.stat(stringToIpfsPath(cid), {\n      ...options,\n      withLocal: true,\n      size: true,\n    }).then((result) => {\n      const { type, size, sizeLocal, local, blocks } = result;\n      return {\n        type,\n        size: size || -1,\n        sizeLocal: sizeLocal || -1,\n        blocks,\n      };\n    });\n  }\n\n  cat(cid: string, options: CatOptions = {}) {\n    return this.node!.cat(stringToCid(cid), options);\n  }\n\n  async add(content: File | string, options: AbortOptions = {}) {\n    return (await this.node!.add(content, options)).cid.toString();\n  }\n\n  async pin(cid: string, options: AbortOptions = {}) {\n    return (await this.node!.pin.add(stringToCid(cid), options)).toString();\n  }\n\n  async getPeers() {\n    return (await this.node!.swarm.peers()).map((c) => c.peer.toString());\n  }\n\n  async stop() {}\n  async start() {}\n\n  async connectPeer(address: string) {\n    const addr = multiaddr(address);\n    await this.node!.bootstrap.add(addr);\n\n    await this.node!.swarm.connect(addr);\n    return true;\n  }\n\n  ls() {\n    return this.node!.pin.ls();\n  }\n\n  async info() {\n    const response = await this.node!.stats.repo();\n    const repoSize = Number(response.repoSize);\n\n    const responseId = await this.node!.id();\n    const { agentVersion, id } = responseId;\n    return { id: id.toString(), agentVersion, repoSize };\n  }\n}\n\n// eslint-disable-next-line import/no-unused-modules\nexport default JsIpfsNode;\n","export const enum Networks {\n  BOSTROM = 'bostrom',\n  SPACE_PUSSY = 'space-pussy',\n  ETH = 'eth',\n  OSMO = 'osmo',\n  TERRA = 'terra',\n  COSMOS = 'cosmoshub-4',\n}\n\nexport type NetworkConfig = {\n  CHAIN_ID: Networks;\n  BASE_DENOM: string;\n  DENOM_LIQUID: string;\n  RPC_URL: string;\n  LCD_URL: string;\n  WEBSOCKET_URL: string;\n  INDEX_HTTPS: string;\n  INDEX_WEBSOCKET: string;\n  BECH32_PREFIX: string;\n  MEMO_KEPLR: string;\n};\n\nexport type NetworksList = {\n  [key in Networks]: NetworkConfig;\n};\n","import { NetworkConfig, Networks } from 'src/types/networks';\n\ntype NetworksList = {\n  [key in Networks.BOSTROM | Networks.SPACE_PUSSY]: NetworkConfig;\n};\n\nconst defaultNetworks: NetworksList = {\n  bostrom: {\n    CHAIN_ID: Networks.BOSTROM,\n    BASE_DENOM: 'boot',\n    DENOM_LIQUID: 'hydrogen',\n    RPC_URL: 'https://rpc.bostrom.cybernode.ai',\n    LCD_URL: 'https://lcd.bostrom.cybernode.ai',\n    WEBSOCKET_URL: 'wss://rpc.bostrom.cybernode.ai/websocket',\n    INDEX_HTTPS: 'https://index.bostrom.cybernode.ai/v1/graphql',\n    INDEX_WEBSOCKET: 'wss://index.bostrom.cybernode.ai/v1/graphql',\n    BECH32_PREFIX: 'bostrom',\n    MEMO_KEPLR: '[bostrom] cyb.ai, using keplr',\n  },\n  'space-pussy': {\n    CHAIN_ID: Networks.SPACE_PUSSY,\n    BASE_DENOM: 'pussy',\n    DENOM_LIQUID: 'liquidpussy',\n    RPC_URL: 'https://rpc.space-pussy.cybernode.ai/',\n    LCD_URL: 'https://lcd.space-pussy.cybernode.ai',\n    WEBSOCKET_URL: 'wss://rpc.space-pussy.cybernode.ai/websocket',\n    INDEX_HTTPS: 'https://index.space-pussy.cybernode.ai/v1/graphql',\n    INDEX_WEBSOCKET: 'wss://index.space-pussy.cybernode.ai/v1/graphql',\n    BECH32_PREFIX: 'pussy',\n    MEMO_KEPLR: '[space-pussy] cyb.ai, using keplr',\n  },\n};\n\nexport default defaultNetworks;\n","import { Networks } from 'src/types/networks';\nimport defaultNetworks from './defaultNetworks';\n\nconst DEFAULT_CHAIN_ID: Networks.BOSTROM | Networks.SPACE_PUSSY =\n  Networks.BOSTROM;\n\nexport const CHAIN_ID = process.env.CHAIN_ID || DEFAULT_CHAIN_ID;\n\nexport const LCD_URL =\n  process.env.LCD_URL || defaultNetworks[DEFAULT_CHAIN_ID].LCD_URL;\n\nexport const RPC_URL =\n  process.env.RPC_URL || defaultNetworks[DEFAULT_CHAIN_ID].RPC_URL;\n\nexport const WEBSOCKET_URL =\n  process.env.WEBSOCKET_URL || defaultNetworks[DEFAULT_CHAIN_ID].WEBSOCKET_URL;\n\nexport const INDEX_HTTPS =\n  process.env.INDEX_HTTPS || defaultNetworks[DEFAULT_CHAIN_ID].INDEX_HTTPS;\n\nexport const INDEX_WEBSOCKET =\n  process.env.INDEX_WEBSOCKET ||\n  defaultNetworks[DEFAULT_CHAIN_ID].INDEX_WEBSOCKET;\n\nexport const BECH32_PREFIX =\n  process.env.BECH32_PREFIX || defaultNetworks[DEFAULT_CHAIN_ID].BECH32_PREFIX;\n\nconst BECH32_PREFIX_VAL = `${BECH32_PREFIX}val`;\n\nexport const BECH32_PREFIX_VALOPER = `${BECH32_PREFIX_VAL}oper`;\n\nexport const BECH32_PREFIX_VAL_CONS = `${BECH32_PREFIX_VAL}cons`;\n\nexport const BASE_DENOM =\n  process.env.BASE_DENOM || defaultNetworks[DEFAULT_CHAIN_ID].BASE_DENOM;\n\nexport const DENOM_LIQUID =\n  process.env.DENOM_LIQUID || defaultNetworks[DEFAULT_CHAIN_ID].DENOM_LIQUID;\n\nexport const CYBER_GATEWAY =\n  process.env.CYBER_GATEWAY || 'https://gateway.ipfs.cybernode.ai';\n\nexport const DIVISOR_CYBER_G = 10 ** 9;\n\nexport const DEFAULT_GAS_LIMITS = 200000;\n\nexport const COIN_DECIMALS_RESOURCE = 3;\n\nexport const { MEMO_KEPLR } = defaultNetworks[DEFAULT_CHAIN_ID];\n","import { BECH32_PREFIX, BECH32_PREFIX_VALOPER } from './config';\n\nexport const PATTERN_CYBER = new RegExp(\n  `^${BECH32_PREFIX}[a-zA-Z0-9]{39}$`,\n  'g'\n);\n\nexport const PATTERN_IPFS_HASH = /^Qm[a-zA-Z0-9]{44}$/g;\n\nexport const PATTERN_CYBER_CONTRACT = new RegExp(\n  `^${BECH32_PREFIX}[a-zA-Z0-9]{59}$`,\n  'g'\n);\n\nexport const PATTERN_CYBER_VALOPER = new RegExp(\n  `^${BECH32_PREFIX_VALOPER}valoper[a-zA-Z0-9]{39}$`,\n  'g'\n);\n\nexport const PATTERN_COSMOS = /^cosmos[a-zA-Z0-9]{39}$/g;\n\nexport const PATTERN_OSMOS = /^osmo[a-zA-Z0-9]{39}$/g;\n\nexport const PATTERN_TERRA = /^terra[a-zA-Z0-9]{39}$/g;\n\nexport const PATTERN_ETH = /^0x[a-fA-F0-9]{40}$/g;\n\nexport const PATTERN_TX = /[0-9a-fA-F]{64}$/g;\n\nexport const PATTERN_BLOCK = /^[0-9]+$/g;\n\nexport const PATTERN_HTTP = /^https:\\/\\/|^http:\\/\\//g;\n\nexport const PATTERN_HTML = /<\\/?[\\w\\d]+>/gi;\n","/* eslint-disable valid-jsdoc */\n/* eslint-disable import/no-unused-modules */\nimport { fileTypeFromBuffer } from 'file-type';\nimport { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nimport { Uint8ArrayLike } from '../types';\n\ntype ResultWithMime = {\n  result: Uint8ArrayLike;\n  mime: string | undefined;\n  firstChunk: Uint8Array | undefined;\n};\n\ntype StreamDoneCallback = (\n  chunks: Array<Uint8Array>,\n  mime: string | undefined\n) => Promise<void> | void;\n\n// interface AsyncIterableWithReturn<T> extends AsyncIterable<T> {\n//   return?: (value?: unknown) => Promise<IteratorResult<T>>;\n// }\n\nexport const getMimeFromUint8Array = async (\n  raw: Uint8Array | undefined\n): Promise<string | undefined> => {\n  if (!raw) {\n    return 'unknown';\n  }\n  // TODO: try to pass only first N-bytes\n  const fileType = await fileTypeFromBuffer(raw);\n\n  return fileType?.mime || 'text/plain';\n};\n\nexport async function toAsyncIterableWithMime(\n  stream: ReadableStream<Uint8Array>,\n  flush?: StreamDoneCallback\n): Promise<ResultWithMime> {\n  const [firstChunkStream, fullStream] = stream.tee();\n  const chunks: Array<Uint8Array> = []; // accumulate all the data to pim/save\n\n  // Read the first chunk from the stream\n  const firstReader = firstChunkStream.getReader();\n  const { value } = await firstReader.read();\n  const mime = value ? await getMimeFromUint8Array(value) : undefined;\n\n  const restReader = fullStream.getReader();\n\n  const asyncIterable: AsyncIterable<Uint8Array> = {\n    async *[Symbol.asyncIterator]() {\n      while (true) {\n        const { done, value } = await restReader.read();\n        if (done) {\n          flush && flush(chunks, mime);\n          return; // Exit the loop when done\n        }\n        flush && chunks.push(value);\n        yield value; // Yield the value to the consumer\n      }\n    },\n  };\n\n  return { mime, result: asyncIterable, firstChunk: value };\n}\n\nexport async function toReadableStreamWithMime(\n  stream: ReadableStream<Uint8Array>,\n  flush?: StreamDoneCallback\n): Promise<ResultWithMime> {\n  const [firstChunkStream, fullStream] = stream.tee();\n  const chunks: Array<Uint8Array> = []; // accumulate all the data to pim/save\n\n  // Read the first chunk from the stream\n  const firstReader = firstChunkStream.getReader();\n  const { value } = await firstReader.read();\n  const mime = value ? await getMimeFromUint8Array(value) : undefined;\n\n  const modifiedStream = new ReadableStream<Uint8Array>({\n    async pull(controller) {\n      const restReader = fullStream.getReader();\n      const { done, value } = await restReader.read();\n      if (done) {\n        controller.close();\n        flush && flush(chunks, mime);\n      } else {\n        controller.enqueue(value);\n        flush && chunks.push(value);\n      }\n      restReader.releaseLock();\n    },\n    cancel() {\n      firstChunkStream.cancel();\n      fullStream.cancel();\n    },\n  });\n\n  return { mime, result: modifiedStream, firstChunk: value };\n}\n\nexport type onProgressCallback = (progress: number) => void;\n\nexport const getResponseResult = async (\n  response: Uint8ArrayLike,\n  onProgress?: onProgressCallback\n) => {\n  let bytesDownloaded = 0;\n  try {\n    if (response instanceof Uint8Array) {\n      onProgress && onProgress(response.byteLength);\n      return response;\n    }\n    const chunks: Array<Uint8Array> = [];\n\n    if (response instanceof ReadableStream) {\n      const reader = response.getReader();\n\n      const readStream = async ({\n        done,\n        value,\n      }: ReadableStreamReadResult<Uint8Array>): Promise<Uint8Array> => {\n        if (done) {\n          return uint8ArrayConcat(chunks);\n        }\n\n        chunks.push(value!);\n        bytesDownloaded += value!.byteLength;\n        onProgress && onProgress(bytesDownloaded);\n        return reader.read().then(readStream);\n      };\n\n      const readArray: Uint8Array = await reader.read().then(readStream);\n\n      return readArray;\n    }\n\n    const reader = response[Symbol.asyncIterator]();\n\n    // if (cid === 'QmRqms6Utkk6L4mtyLQXY2spcQ8Pk7fBBTNjvxa9jTNrXp') {\n    //   debugger;\n    // }\n    // eslint-disable-next-line no-restricted-syntax\n    for await (const chunk of reader) {\n      if (chunk instanceof Uint8Array) {\n        chunks.push(chunk);\n        bytesDownloaded += chunk.byteLength;\n        onProgress && onProgress(bytesDownloaded);\n      }\n    }\n    const result = uint8ArrayConcat(chunks);\n    return result;\n  } catch (error) {\n    console.error(\n      `Error reading stream/iterable.\\r\\n Probably Hot reload error!`,\n      error\n    );\n\n    return undefined;\n  }\n};\n","import { toString as uint8ArrayToAsciiString } from 'uint8arrays/to-string';\nimport isSvg from 'is-svg';\nimport { PATTERN_HTTP, PATTERN_IPFS_HASH } from 'src/constants/patterns';\nimport {\n  IPFSContentDetails,\n  IPFSContentMaybe,\n  IpfsContentType,\n} from '../types';\nimport { getResponseResult, onProgressCallback } from './stream';\n\nfunction createObjectURL(rawData: Uint8Array, type: string) {\n  const blob = new Blob([rawData], { type });\n  return URL.createObjectURL(blob);\n}\n\nfunction createImgData(rawData: Uint8Array, type: string) {\n  const imgBase64 = uint8ArrayToAsciiString(rawData, 'base64');\n  const file = `data:${type};base64,${imgBase64}`;\n  return file;\n}\n\n// eslint-disable-next-line import/no-unused-modules\nexport const detectContentType = (\n  mime: string | undefined\n): IpfsContentType => {\n  if (mime) {\n    if (mime.includes('video')) {\n      return 'video';\n    }\n\n    if (mime.includes('audio')) {\n      return 'audio';\n    }\n\n    if (mime.includes('epub')) {\n      return 'epub';\n    }\n  }\n\n  return 'other';\n};\n\nconst basic = /\\s?<!doctype html>|(<html\\b[^>]*>|<body\\b[^>]*>|<x-[^>]+>)+/i;\n\nfunction isHtml(string: string) {\n  const newString = string.trim().slice(0, 1000);\n  return basic.test(newString);\n}\n\nfunction shortenString(string: string, length = 300) {\n  return string.length > length ? `${string.slice(0, length)}...` : string;\n}\n\n// eslint-disable-next-line import/no-unused-modules\nexport const chunksToBlob = (\n  chunks: Array<Uint8Array>,\n  mime: string | undefined\n) => new Blob(chunks, mime ? { type: mime } : {});\n\n// eslint-disable-next-line import/no-unused-modules, import/prefer-default-export\nexport const parseArrayLikeToDetails = async (\n  content: IPFSContentMaybe,\n  cid: string,\n  onProgress?: onProgressCallback\n): Promise<IPFSContentDetails> => {\n  try {\n    const mime = content?.meta?.mime;\n    const response: IPFSContentDetails = {\n      link: `/ipfs/${cid}`,\n      gateway: false,\n      cid,\n    };\n    const initialType = detectContentType(mime);\n    if (['video', 'audio', 'epub'].indexOf(initialType) > -1) {\n      return { ...response, type: initialType, gateway: true };\n    }\n\n    const rawData = content?.result\n      ? await getResponseResult(content.result, onProgress)\n      : undefined;\n\n    if (!mime) {\n      response.text = `Can't detect MIME for ${cid.toString()}`;\n      response.gateway = true; // ???\n    } else if (\n      mime.indexOf('text/plain') !== -1 ||\n      mime.indexOf('application/xml') !== -1\n    ) {\n      if (isSvg(Buffer.from(rawData))) {\n        response.type = 'image';\n        response.content = createImgData(rawData, 'image/svg+xml'); // file\n      } else {\n        const dataBase64 = uint8ArrayToAsciiString(rawData);\n        // TODO: search can bel longer for 42???!\n        // also cover ipns links\n        response.link =\n          dataBase64.length > 42 ? `/ipfs/${cid}` : `/search/${dataBase64}`;\n\n        if (dataBase64.match(PATTERN_IPFS_HASH)) {\n          response.gateway = true;\n          response.type = 'other';\n          response.content = dataBase64;\n          response.link = `/ipfs/${cid}`;\n        } else if (dataBase64.match(PATTERN_HTTP)) {\n          response.type = 'link';\n          response.gateway = false;\n          response.content = dataBase64;\n          response.link = `/ipfs/${cid}`;\n        } else if (isHtml(dataBase64)) {\n          response.type = 'other';\n          response.gateway = true;\n          response.content = cid.toString();\n        } else {\n          response.type = 'text';\n          response.content = dataBase64;\n          response.text = shortenString(dataBase64);\n        }\n      }\n    } else if (mime.indexOf('image') !== -1) {\n      response.content = createImgData(rawData, mime); // file\n      response.type = 'image';\n      response.gateway = false;\n    } else if (mime.indexOf('application/pdf') !== -1) {\n      response.type = 'pdf';\n      response.content = createObjectURL(rawData, mime); // file\n      response.gateway = true; // ???\n    }\n\n    return response;\n  } catch (e) {\n    console.log('----parseRawIpfsData', e, cid);\n    return undefined;\n  }\n};\n\nexport const contentToUint8Array = async (\n  content: File | string\n): Promise<Uint8Array> => {\n  return new Uint8Array(\n    typeof content === 'string'\n      ? Buffer.from(content)\n      : await content.arrayBuffer()\n  );\n};\n\nexport const createTextPreview = (\n  array: Uint8Array | undefined,\n  mime?: string,\n  previewLength = 150\n) => {\n  return array && mime && mime === 'text/plain'\n    ? uint8ArrayToAsciiString(array).slice(0, previewLength)\n    : undefined;\n};\n","import Dexie from 'dexie';\n\nconst db = new Dexie('cyber-page-cash');\ndb.version(3).stores({\n  cid: 'cid',\n  following: 'cid',\n});\n\nexport default db;\n","import db from 'src/db';\n\nconst ipfsCacheDb = () => {\n  const add = async (cid: string, raw: Uint8Array): Promise<void> => {\n    const dbValue = await db.table('cid').get({ cid });\n\n    if (!dbValue) {\n      const ipfsContentAddtToInddexdDB = {\n        cid,\n        data: raw,\n      };\n      db.table('cid').add(ipfsContentAddtToInddexdDB);\n    }\n  };\n\n  const get = async (cid: string): Promise<Uint8Array | undefined> => {\n    // TODO: use cursor\n    const dbValue = await db.table('cid').get({ cid });\n\n    // backward compatibility\n    return dbValue?.data || dbValue?.content;\n  };\n\n  return { add, get };\n};\n\nexport default ipfsCacheDb();\n","import {\n  AddResponse,\n  PinResponse,\n} from '@nftstorage/ipfs-cluster/dist/src/interface';\n\nimport { Cluster } from '@nftstorage/ipfs-cluster';\nimport { IPFS_CLUSTER_URL } from '../config';\n\nconst cyberCluster = () => {\n  const cluster = new Cluster(IPFS_CLUSTER_URL);\n\n  const add = async (\n    file: File | string\n  ): Promise<AddResponse | PinResponse | undefined> => {\n    const dataFile =\n      typeof file === 'string' ? new File([file], 'file.txt') : file;\n    return cluster.add(dataFile, { cidVersion: 0, rawLeaves: false });\n  };\n\n  const status = async (cid: string) => cluster.status(cid);\n  return { add, status };\n};\n\nexport default cyberCluster();\n","/* eslint-disable import/no-unused-modules */\nimport { concat as uint8ArrayConcat } from 'uint8arrays/concat';\n\nimport { Option } from 'src/types';\nimport {\n  // getIpfsUserGatewanAndNodeType,\n  IPFSContentMaybe,\n  IPFSContentMeta,\n  CallBackFuncStatus,\n  IpfsContentSource,\n  IpfsNode,\n} from '../types';\n\nimport { getMimeFromUint8Array, toAsyncIterableWithMime } from './stream';\n\nimport ipfsCacheDb from './ipfsCacheDb';\nimport cyberCluster from './cluster';\n\nimport { contentToUint8Array, createTextPreview } from './content';\n\nimport { CYBER_GATEWAY_URL, FILE_SIZE_DOWNLOAD } from '../config';\n\n// Get data by CID from local storage\nconst loadIPFSContentFromDb = async (\n  cid: string\n): Promise<IPFSContentMaybe> => {\n  // TODO: enable, disabled for tests\n\n  // TODO: use cursor\n  const data = await ipfsCacheDb.get(cid);\n  if (data && data.length) {\n    // TODO: use cursor\n    const mime = await getMimeFromUint8Array(data);\n    const textPreview = createTextPreview(data, mime);\n\n    const meta: IPFSContentMeta = {\n      type: 'file', // `TODO: ipfs refactor dir support ?\n      size: data.length,\n      sizeLocal: data.length,\n      mime,\n    };\n    return { result: data, cid, meta, source: 'db', textPreview };\n  }\n\n  return undefined;\n};\n\nconst emptyMeta: IPFSContentMeta = {\n  type: 'file',\n  size: undefined,\n  local: undefined,\n  sizeLocal: undefined,\n};\n\nconst fetchIPFSContentMeta = async (\n  cid: string,\n  node?: IpfsNode,\n  signal?: AbortSignal\n): Promise<IPFSContentMeta> => {\n  if (node) {\n    const meta = await node.stat(cid, { signal });\n    return meta;\n  }\n  return emptyMeta;\n};\n\nconst fetchIPFSContentFromNode = async (\n  cid: string,\n  node?: IpfsNode,\n  controller?: AbortController\n): Promise<IPFSContentMaybe> => {\n  const controllerLegacy = controller || new AbortController();\n  const { signal } = controllerLegacy;\n  let timer: NodeJS.Timeout | undefined;\n\n  if (!node) {\n    console.log('--------fetchIPFSContentFromNode NO NODE INTIALIZED--------');\n    return undefined;\n  }\n\n  if (!controller) {\n    timer = setTimeout(() => {\n      controllerLegacy.abort();\n    }, 1000 * 60 * 1);\n  } // 1 min\n\n  // TODO: cover ipns case\n  try {\n    // const stat = await node.files.stat(path, { signal });\n    const startTime = Date.now();\n    const meta = await fetchIPFSContentMeta(cid, node, signal);\n    const statsDoneTime = Date.now();\n    meta.statsTime = statsDoneTime - startTime;\n    const allowedSize = meta.size ? meta.size < FILE_SIZE_DOWNLOAD : false;\n    timer && clearTimeout(timer);\n\n    switch (meta.type) {\n      case 'directory': {\n        // TODO: return directory structure\n        return { cid, availableDownload: true, source: 'node', meta };\n      }\n      default: {\n        // Get sample of content\n        const { value: firstChunk } = await node\n          .cat(cid, { signal, length: 2048, offset: 0 })\n          [Symbol.asyncIterator]()\n          .next();\n\n        const mime = await getMimeFromUint8Array(firstChunk);\n        const fullyDownloaded =\n          meta.size && meta.size > -1 && firstChunk.length >= meta.size;\n\n        const textPreview = createTextPreview(firstChunk, mime);\n\n        if (fullyDownloaded) {\n          await ipfsCacheDb.add(cid, uint8ArrayConcat([firstChunk]));\n        }\n\n        // If all content fits in first chunk return byte-array instead iterable\n        const stream = fullyDownloaded\n          ? firstChunk\n          : allowedSize\n          ? node.cat(cid, { signal })\n          : undefined;\n\n        meta.catTime = Date.now() - statsDoneTime;\n\n        // TODO: add to db flag that content is pinned TO local node\n        // if already pinned skip pin\n        if (!meta.local && allowedSize) {\n          node.pin(cid);\n\n          meta.pinTime = Date.now() - meta.catTime;\n        } else {\n          meta.pinTime = -1;\n        }\n\n        return {\n          result: stream,\n          textPreview,\n          cid,\n          meta: { ...meta, mime },\n          source: 'node',\n        };\n        // }\n      }\n    }\n  } catch (error) {\n    console.debug('error fetchIPFSContentFromNode', error);\n    return { cid, availableDownload: true, source: 'node', meta: emptyMeta };\n  }\n};\n\nconst fetchIPFSContentFromGateway = async (\n  cid: string,\n  node?: IpfsNode,\n  controller?: AbortController,\n  headers?: Record<string, string>\n): Promise<IPFSContentMaybe> => {\n  // fetch META only from external node(toooo slow), TODO: fetch meta from cybernode\n  const isExternalNode = node?.nodeType === 'external';\n  const meta = isExternalNode\n    ? await fetchIPFSContentMeta(cid, node, controller?.signal)\n    : emptyMeta;\n\n  const contentUrl = `${CYBER_GATEWAY_URL}/ipfs/${cid}`;\n  const response = await fetch(contentUrl, {\n    method: 'GET',\n    signal: controller?.signal,\n    headers,\n  });\n\n  if (response && response.body) {\n    // fetch doesn't provide any headers in our case :(\n\n    // const contentLength = parseInt(\n    //   response.headers['content-length'] || '-1',\n    //   10\n    // );\n    // const contentType = response.headers['content-type'];\n\n    // Extract meta if ipfs prob/node not started yet\n    // if (!meta.mime) {\n    //   meta = { ...meta, mime: contentType };\n    // }\n\n    // TODO: fix\n    const flushResults = (chunks: Uint8Array[]) =>\n      !isExternalNode\n        ? ipfsCacheDb.add(cid, uint8ArrayConcat(chunks))\n        : Promise.resolve();\n\n    const { mime, result, firstChunk } = await toAsyncIterableWithMime(\n      response.body,\n      flushResults\n    );\n\n    const textPreview = createTextPreview(firstChunk, mime);\n    return {\n      cid,\n      textPreview,\n      meta: { ...meta, mime },\n      result,\n      source: 'gateway',\n      contentUrl,\n    };\n  }\n\n  return undefined;\n};\n\ntype fetchContentOptions = {\n  controller?: AbortController;\n  node?: IpfsNode;\n  headers?: Record<string, string>;\n};\n\nasync function fetchIpfsContent(\n  cid: string,\n  source: IpfsContentSource,\n  options: fetchContentOptions\n): Promise<IPFSContentMaybe> {\n  const { node, controller, headers } = options;\n\n  try {\n    switch (source) {\n      case 'db':\n        return loadIPFSContentFromDb(cid);\n      case 'node':\n        return fetchIPFSContentFromNode(cid, node, controller);\n      case 'gateway':\n        return fetchIPFSContentFromGateway(cid, node, controller, headers);\n      default:\n        return undefined;\n    }\n  } catch (e) {\n    console.log('----fetchIpfsContent error', e);\n    return undefined;\n  }\n}\n\nconst getIPFSContent = async (\n  cid: string,\n  node?: IpfsNode,\n  controller?: AbortController,\n  callBackFuncStatus?: CallBackFuncStatus\n): Promise<IPFSContentMaybe> => {\n  const dataRsponseDb = await loadIPFSContentFromDb(cid);\n  if (dataRsponseDb !== undefined) {\n    return dataRsponseDb;\n  }\n\n  if (node) {\n    callBackFuncStatus && callBackFuncStatus('trying to get with a node');\n    // console.log('----Fetch from node', cid);\n    const ipfsContent = await fetchIPFSContentFromNode(cid, node, controller);\n\n    return ipfsContent;\n  }\n\n  callBackFuncStatus && callBackFuncStatus('trying to get with a gatway');\n  // console.log('----Fetch from gateway', cid);\n  const respnseGateway = await fetchIPFSContentFromGateway(\n    cid,\n    node,\n    controller\n  );\n\n  return respnseGateway;\n};\n\nconst catIPFSContentFromNode = (\n  cid: string,\n  node?: IpfsNode,\n  offset?: number,\n  controller?: AbortController\n): AsyncIterable<Uint8Array> | undefined => {\n  if (!node) {\n    console.log(\n      '--------fetchIPFSContentFromNode NO NODE INTIALIZED TODO: cover case--------'\n    );\n    return undefined;\n  }\n\n  // TODO: cover ipns case\n\n  return node.cat(cid, { offset, signal: controller?.signal });\n};\n\n// const nodeContentFindProvs = async (\n//   node: AppIPFS,\n//   cid: string,\n//   offset: number,\n//   controller?: AbortController\n// ): AsyncIterable<number> | undefined => {\n//   if (!node) {\n//     console.log(\n//       '--------fetchIPFSContentFromNode NO NODE INTIALIZED TODO: cover case--------'\n//     );\n//     return undefined;\n//   }\n\n//   // TODO: cover ipns case\n//   const path = `/ipfs/${cid}`;\n\n//   const providers = node.dht.findProvs(path, {\n//     signal: controller?.signal,\n//   });\n\n//   let count = 0;\n//   for await (const provider of providers) {\n//     //  console.log(provider.id.toString())\n//     //  id: PeerId\n//     // multiaddrs: Multiaddr[]\n//     // protocols: string[]\n//     count++;\n//   }\n\n//   return count;\n// };\n\nconst addContenToIpfs = async (\n  node: IpfsNode,\n  content: File | string\n): Promise<Option<string>> => {\n  let cid;\n  if (node) {\n    cid = await node.add(content);\n  }\n  // TODO: WARN - TMP solution make cluster call non-awaitable\n  cyberCluster.add(content);\n  // Save to local cache\n  cid && (await ipfsCacheDb.add(cid, await contentToUint8Array(content)));\n  return cid;\n};\n\nexport {\n  getIPFSContent,\n  catIPFSContentFromNode,\n  fetchIpfsContent,\n  addContenToIpfs,\n};\n","// import { getNodeAutoDialInterval } from './utils-ipfs';\nimport { IpfsNodeType, IpfsNode, CybIpfsNode, IpfsOptsType } from '../types';\nimport KuboNode from './impl/kubo';\nimport HeliaNode from './impl/helia';\nimport JsIpfsNode from './impl/js-ipfs';\n// import EnhancedIpfsNode from './node/enhancedNode';\nimport {\n  CYBERNODE_SWARM_ADDR_TCP,\n  CYBERNODE_SWARM_ADDR_WSS,\n  CYBER_NODE_SWARM_PEER_ID,\n} from '../config';\nimport { withCybFeatures } from './mixins/withCybFeatures';\n\nconst nodeClassMap: Record<IpfsNodeType, new () => IpfsNode> = {\n  helia: HeliaNode,\n  embedded: JsIpfsNode,\n  external: KuboNode,\n};\n\n// eslint-disable-next-line import/no-unused-modules, import/prefer-default-export\nexport async function initIpfsNode(\n  options: IpfsOptsType\n): Promise<CybIpfsNode> {\n  const { ipfsNodeType, ...restOptions } = options;\n\n  const swarmPeerId = CYBER_NODE_SWARM_PEER_ID;\n\n  const swarmPeerAddress =\n    ipfsNodeType === 'external'\n      ? CYBERNODE_SWARM_ADDR_TCP\n      : CYBERNODE_SWARM_ADDR_WSS;\n\n  const EnhancedClass = withCybFeatures(nodeClassMap[ipfsNodeType], {\n    swarmPeerId,\n    swarmPeerAddress,\n  });\n\n  const instance = new EnhancedClass();\n\n  await instance.init({ url: restOptions.urlOpts });\n  // TODO: REFACT\n  //   instance.connMgrGracePeriod = await getNodeAutoDialInterval(instance);\n  // window.ipfs = instance;\n\n  console.log('----init', ipfsNodeType);\n\n  await instance.reconnectToSwarm();\n  return instance;\n}\n","import { IpfsNode, CybIpfsNode, IpfsContentType } from '../../types';\nimport { parseArrayLikeToDetails } from '../../utils/content';\nimport { addContenToIpfs, getIPFSContent } from '../../utils/utils-ipfs';\n\ntype WithCybFeaturesOptions = {\n  swarmPeerId: string;\n  swarmPeerAddress: string;\n};\n\nfunction withCybFeatures<TBase extends new (...args: any[]) => IpfsNode>(\n  Base: TBase,\n  options: WithCybFeaturesOptions\n) {\n  return class CybIpfsNodeMixin extends Base implements CybIpfsNode {\n    async fetchWithDetails(cid: string, parseAs?: IpfsContentType) {\n      const response = await getIPFSContent(cid, this);\n      const details = await parseArrayLikeToDetails(response, cid);\n\n      return !parseAs\n        ? details\n        : details?.type === parseAs\n        ? details\n        : undefined;\n    }\n\n    async addContent(content: File | string) {\n      return addContenToIpfs(this, content);\n    }\n\n    async isConnectedToSwarm() {\n      return !!(await super.getPeers()).find(\n        (peerId) => peerId === options.swarmPeerId\n      );\n    }\n\n    async reconnectToSwarm(lastConnectedTimestamp?: number) {\n      if (!(await this.isConnectedToSwarm())) {\n        // TODO: refactor using timeout for node config\n\n        //   const needToReconnect =\n        //     Date.now() - lastConnectedTimestamp <\n        //     DEFAULT_CONNECTION_LIFETIME_SECONDS;\n        super\n          .connectPeer(options.swarmPeerAddress)\n          .then(() => {\n            console.log(`🐝 connected to swarm - ${options.swarmPeerAddress}`);\n            return true;\n          })\n          .catch((err) => {\n            console.log(\n              `Can't connect to swarm ${options.swarmPeerAddress}: ${err.message}`\n            );\n            return false;\n          });\n      }\n    }\n  };\n}\n\nexport { withCybFeatures };\n","import { IQueueStrategy, QueueSettings, QueueSource } from './types';\n\nexport class QueueStrategy implements IQueueStrategy {\n  settings: QueueSettings;\n\n  order: QueueSource[];\n\n  constructor(settings: QueueSettings, order: QueueSource[]) {\n    this.settings = settings;\n    this.order = order;\n  }\n\n  getNextSource(source: QueueSource): QueueSource | undefined {\n    const index = this.order.indexOf(source);\n    return index < this.order.length ? this.order[index + 1] : undefined;\n  }\n}\n","export function isParticle(value: string) {\n  // copied from src/utils/config.ts , to prevent crash in worker, need refactor\n  // import { PATTERN_IPFS_HASH } from 'src/utils/config';\n  return Boolean(value.match(/^Qm[a-zA-Z0-9]{44}$/g));\n}\n","import { PinType } from 'ipfs-core-types/src/pin';\nimport { QueuePriority } from 'src/services/QueueManager/types';\nimport { Transaction } from 'src/services/backend/services/indexer/types';\nimport {\n  SenseChatExtension,\n  SenseLinkMeta,\n  SenseListItemtMeta,\n  SenseTransactionMeta,\n} from 'src/services/backend/types/sense';\nimport { IpfsContentType } from 'src/services/ipfs/types';\nimport { NeuronAddress, ParticleCid, TransactionHash } from 'src/types/base';\nimport { DtoToEntity } from 'src/types/dto';\n\ntype PinEntryType = Exclude<PinType, 'all'>;\n// example of db optimization for classifiers\n\nexport const PinTypeMap: Record<PinEntryType, number> = {\n  indirect: -1,\n  direct: 0,\n  recursive: 1,\n};\n\nexport enum EntryType {\n  transactions = 1,\n  particle = 2,\n  chat = 3,\n}\n\n// Transaction if formed by frontend\n// Should be replaced after sync\n\nexport type PinDbEntity = {\n  cid: string;\n  type: keyof typeof PinTypeMap;\n};\n\nexport type TransactionDbEntity = {\n  hash: string;\n  index: number;\n  type: string;\n  timestamp: number;\n  block_height: number;\n  value: Transaction['value'];\n  success: boolean;\n  memo: string;\n  neuron: NeuronAddress;\n};\n\ntype SyncItemMeta = DtoToEntity<\n  (SenseLinkMeta | SenseTransactionMeta) & SenseChatExtension\n>;\n\nexport type SyncStatusDbEntity = {\n  entry_type: EntryType;\n  id: NeuronAddress | ParticleCid;\n  owner_id: NeuronAddress;\n  timestamp_update: number;\n  timestamp_read: number;\n  disabled: boolean;\n  unread_count: number;\n  meta: SyncItemMeta;\n};\n\nexport type ParticleDbEntity = {\n  id: ParticleCid;\n  size: number;\n  size_local: number;\n  blocks: number;\n  mime: string;\n  type: IpfsContentType;\n  text: string;\n};\n\nexport type LinkDbEntity = {\n  from: ParticleCid;\n  to: ParticleCid;\n  neuron: NeuronAddress;\n  timestamp: number;\n  transaction_hash: string;\n};\n\nexport type ConfigDbEntity = {\n  key: string;\n  group_key: string;\n  value: NonNullable<unknown>;\n};\n\nexport enum SyncQueueStatus {\n  pending = 0,\n  executing = 1,\n  done = 2,\n  error = -1,\n}\n\nexport type SyncQueueDbEntity = {\n  id: string;\n  status: SyncQueueStatus;\n  priority: QueuePriority | number;\n};\n\nexport type CommunityDbEntity = {\n  ownerId: NeuronAddress;\n  particle: ParticleCid;\n  neuron: NeuronAddress;\n  name: string;\n  following: boolean;\n  follower: boolean;\n};\n\nexport type DbEntity =\n  | TransactionDbEntity\n  | ParticleDbEntity\n  | SyncStatusDbEntity\n  | ConfigDbEntity\n  | SyncQueueDbEntity;\n","import {\n  createAsyncThunk,\n  createSelector,\n  createSlice,\n  PayloadAction,\n} from '@reduxjs/toolkit';\nimport { SenseApi } from 'src/contexts/backend/services/senseApi';\nimport {\n  SenseItemLinkMeta,\n  SenseListItem,\n  SenseListItemTransactionMeta,\n  SenseUnread,\n} from 'src/services/backend/types/sense';\nimport { isParticle } from '../../particle/utils';\nimport { SenseItemId } from '../types/sense';\nimport { EntryType } from 'src/services/CozoDb/types/entities';\nimport {\n  MsgMultiSendValue,\n  MsgSendValue,\n} from 'src/services/backend/services/indexer/types';\nimport { RootState } from 'src/redux/store';\n\n// similar to blockchain/tx/message type\nexport type SenseItem = {\n  id: SenseItemId;\n  transactionHash: string;\n\n  // add normal type\n  type: string;\n\n  meta: SenseListItem['meta'];\n  timestamp: string;\n  memo: string | undefined;\n  from: string;\n\n  // for optimistic update\n  status?: 'pending' | 'error';\n  fromLog?: boolean;\n};\n\ntype Chat = {\n  id: SenseItemId;\n  isLoading: boolean;\n  error: string | undefined;\n  data: SenseItem[];\n  unreadCount: number;\n};\n\ntype SliceState = {\n  list: {\n    isLoading: boolean;\n    data: string[];\n    error: string | undefined;\n  };\n  chats: {\n    [key in SenseItemId]?: Chat;\n  };\n  summary: {\n    unreadCount: {\n      total: number;\n      particles: number;\n      neurons: number;\n    };\n  };\n};\n\nconst initialState: SliceState = {\n  list: {\n    isLoading: false,\n    data: [],\n    error: undefined,\n  },\n  chats: {},\n  summary: {\n    unreadCount: {\n      total: 0,\n      particles: 0,\n      neurons: 0,\n    },\n  },\n};\n\nfunction formatApiData(item: SenseListItem): SenseItem {\n  if (item.entryType === EntryType.chat && item.meta.to) {\n    item.entryType = EntryType.particle;\n  }\n\n  const { meta } = item;\n\n  const formatted: SenseItem = {\n    timestamp: new Date(meta.timestamp).toISOString(),\n\n    // lol\n    transactionHash:\n      item.transactionHash ||\n      item.hash ||\n      item.meta.transaction_hash ||\n      item.meta.hash ||\n      item.meta.transactionHash,\n\n    memo: item.memo || meta.memo,\n\n    senseChatId: item.id,\n    // not good\n    unreadCount: item.unreadCount || 0,\n  };\n\n  switch (item.entryType) {\n    case EntryType.chat:\n    case EntryType.transactions: {\n      const meta = item.meta as SenseListItemTransactionMeta;\n      const { type } = meta;\n\n      let from = item.ownerId;\n\n      if (type === 'cosmos.bank.v1beta1.MsgSend') {\n        const value = meta.value as MsgSendValue;\n        from = value.fromAddress;\n      } else if (type === 'cosmos.bank.v1beta1.MsgMultiSend') {\n        const value = meta.value as MsgMultiSendValue;\n\n        from = value.inputs[0].address;\n      }\n\n      Object.assign(formatted, {\n        type,\n        from,\n        meta: item.meta.value,\n      });\n\n      break;\n    }\n\n    case EntryType.particle: {\n      const meta = item.meta as SenseItemLinkMeta;\n\n      Object.assign(formatted, {\n        type: 'cyber.graph.v1beta1.MsgCyberlink',\n        from: meta.neuron,\n        meta: meta,\n        fromLog: true,\n      });\n\n      break;\n    }\n\n    default:\n      // sholdn't be\n      debugger;\n      return {};\n  }\n\n  return formatted;\n}\n\nconst getSenseList = createAsyncThunk(\n  'sense/getSenseList',\n  async (senseApi: SenseApi) => {\n    const data = await senseApi!.getList();\n    return data.map(formatApiData);\n  }\n);\n\nconst getSenseChat = createAsyncThunk(\n  'sense/getSenseChat',\n  async ({ id, senseApi }: { id: SenseItemId; senseApi: SenseApi }) => {\n    const particle = isParticle(id);\n\n    if (particle) {\n      const links = await senseApi!.getLinks(id);\n      const formattedLinks = links.map((item) => {\n        if (item.timestamp === 0) {\n          // FIXME:\n          return;\n        }\n        return formatApiData({\n          ...item,\n          id,\n          entryType: EntryType.particle,\n          meta: item,\n        });\n      });\n\n      return formattedLinks.filter(Boolean);\n    }\n\n    const data = await senseApi!.getFriendItems(id);\n    const formattedData = data.map((item) => {\n      const entryType = item.to ? EntryType.particle : EntryType.chat;\n      return formatApiData({\n        ...item,\n        entryType,\n        id,\n        meta: item,\n      });\n    });\n\n    return formattedData;\n  }\n);\n\nconst markAsRead = createAsyncThunk(\n  'sense/markAsRead',\n  async ({ id, senseApi }: { id: SenseItemId; senseApi: SenseApi }) => {\n    return senseApi!.markAsRead(id);\n  }\n);\n\nconst newChatStructure: Chat = {\n  id: '',\n  isLoading: false,\n  data: [],\n  error: undefined,\n  unreadCount: 0,\n};\n\nfunction checkIfMessageExists(chat: Chat, newMessage: SenseItem) {\n  const lastMessages = chat.data.slice(-5);\n\n  const isMessageExists = lastMessages.some((msg) => {\n    return msg.transactionHash === newMessage.transactionHash;\n  });\n\n  return isMessageExists;\n}\n\nconst slice = createSlice({\n  name: 'sense',\n  initialState,\n  reducers: {\n    // backend may push this action\n    updateSenseList: {\n      reducer: (state, action: PayloadAction<SenseItem[]>) => {\n        const data = action.payload;\n\n        data.forEach((message) => {\n          const { senseChatId: id } = message;\n\n          if (!state.chats[id]) {\n            state.chats[id] = { ...newChatStructure };\n          }\n\n          const chat = state.chats[id]!;\n\n          Object.assign(chat, {\n            id,\n            // fix ts\n            unreadCount: message.unreadCount || 0,\n          });\n\n          if (!checkIfMessageExists(chat, message)) {\n            chat.data = chat.data.concat(message);\n          }\n        });\n\n        slice.caseReducers.orderSenseList(state);\n      },\n      prepare: (data: SenseListItem[]) => {\n        return {\n          payload: data.map(formatApiData),\n        };\n      },\n    },\n    // optimistic update\n    addSenseItem(\n      state,\n      action: PayloadAction<{ id: SenseItemId; item: SenseItem }>\n    ) {\n      const { id, item } = action.payload;\n      const chat = state.chats[id]!;\n\n      chat.data.push({\n        ...item,\n        meta: item.meta,\n        status: 'pending',\n      });\n\n      const newList = state.list.data.filter((item) => item !== id);\n      newList.unshift(id);\n      state.list.data = newList;\n    },\n    // optimistic confirm/error\n    updateSenseItem(\n      state,\n      action: PayloadAction<{\n        chatId: SenseItemId;\n        txHash: string;\n        isSuccess: boolean;\n      }>\n    ) {\n      const { chatId, txHash, isSuccess } = action.payload;\n      const chat = state.chats[chatId]!;\n\n      const item = chat.data.find((item) => item.transactionHash === txHash);\n\n      if (item) {\n        if (isSuccess) {\n          delete item.status;\n        } else {\n          item.status = 'error';\n        }\n      }\n    },\n    orderSenseList(state) {\n      const chatsLastMessage = Object.keys(state.chats).reduce<\n        {\n          id: string;\n          lastMsg: SenseItem;\n        }[]\n      >((acc, id) => {\n        const chat = state.chats[id]!;\n\n        // may be loading this moment, no data\n        if (!chat.data.length) {\n          return acc;\n        }\n\n        const lastMsg = chat.data[chat.data.length - 1];\n        acc.push({ id, lastMsg });\n\n        return acc;\n      }, []);\n\n      const sorted = chatsLastMessage.sort((a, b) => {\n        return (\n          Date.parse(b.lastMsg.timestamp) - Date.parse(a.lastMsg.timestamp)\n        );\n      });\n\n      state.list.data = sorted.map((i) => i.id);\n    },\n    reset() {\n      return initialState;\n    },\n  },\n\n  extraReducers: (builder) => {\n    builder.addCase(getSenseList.pending, (state) => {\n      state.list.isLoading = true;\n    });\n\n    builder.addCase(getSenseList.fulfilled, (state, action) => {\n      state.list.isLoading = false;\n\n      const newList: SliceState['list']['data'] = [];\n\n      action.payload.forEach((message) => {\n        const { senseChatId: id } = message;\n\n        if (!state.chats[id]) {\n          state.chats[id] = { ...newChatStructure };\n        }\n\n        const chat = state.chats[id]!;\n\n        Object.assign(chat, {\n          id,\n          // fix\n          unreadCount: message.unreadCount || 0,\n        });\n\n        if (!checkIfMessageExists(chat, message)) {\n          chat.data = chat.data.concat(message);\n        }\n\n        newList.push(id);\n      });\n\n      state.list.data = newList;\n    });\n    builder.addCase(getSenseList.rejected, (state, action) => {\n      console.error(action);\n\n      state.list.isLoading = false;\n      state.list.error = action.error.message;\n    });\n\n    builder.addCase(getSenseChat.pending, (state, action) => {\n      const { id } = action.meta.arg;\n\n      if (!state.chats[id]) {\n        state.chats[id] = { ...newChatStructure };\n      }\n\n      // don't understand why ts warning\n      state.chats[id].isLoading = true;\n    });\n\n    builder.addCase(getSenseChat.fulfilled, (state, action) => {\n      const { id } = action.meta.arg;\n      const chat = state.chats[id]!;\n      chat.isLoading = false;\n\n      chat.id = id;\n\n      chat.data = action.payload;\n    });\n    builder.addCase(getSenseChat.rejected, (state, action) => {\n      console.error(action);\n\n      const chat = state.chats[action.meta.arg.id]!;\n      chat.isLoading = false;\n      chat.error = action.error.message;\n    });\n\n    // maybe add .pending, .rejected\n    // can be optimistic\n    builder.addCase(markAsRead.fulfilled, (state, action) => {\n      const { id } = action.meta.arg;\n      const chat = state.chats[id]!;\n\n      const particle = isParticle(id);\n\n      const { unreadCount } = chat;\n\n      state.summary.unreadCount.total -= unreadCount;\n      if (particle) {\n        state.summary.unreadCount.particles -= unreadCount;\n      } else {\n        state.summary.unreadCount.neurons -= unreadCount;\n      }\n\n      chat.unreadCount = 0;\n    });\n  },\n});\n\nconst selectUnreadCounts = createSelector(\n  (state: RootState) => state.sense.chats,\n  (chats) => {\n    let unreadCountParticle = 0;\n    let unreadCountNeuron = 0;\n\n    Object.values(chats).forEach(({ id, unreadCount }) => {\n      const particle = isParticle(id);\n\n      if (particle) {\n        unreadCountParticle += unreadCount;\n      } else {\n        unreadCountNeuron += unreadCount;\n      }\n    });\n\n    const total = unreadCountParticle + unreadCountNeuron;\n\n    return {\n      total,\n      particles: unreadCountParticle,\n      neurons: unreadCountNeuron,\n    };\n  }\n);\n\nexport const { addSenseItem, updateSenseItem, updateSenseList, reset } =\n  slice.actions;\n\nexport { getSenseList, getSenseChat, markAsRead };\n\n// selectors\nexport { selectUnreadCounts };\n\nexport default slice.reducer;\n","export const localStorageKeys = {\n  pocket: {\n    POCKET: 'pocket',\n    POCKET_ACCOUNT: 'pocketAccount',\n  },\n  MENU_SHOW: 'menuShow',\n};\n","import { Dispatch } from 'redux';\nimport { localStorageKeys } from 'src/constants/localStorageKeys';\n\nimport {\n  Account,\n  AccountValue,\n  Accounts,\n  DefaultAccount,\n} from 'src/types/defaultAccount';\nimport { PayloadAction, createSlice } from '@reduxjs/toolkit';\nimport { POCKET } from '../../utils/config';\nimport { RootState } from '../store';\n\ntype SliceState = {\n  actionBar: {\n    tweet: string;\n  };\n  defaultAccount: DefaultAccount;\n  accounts: null | Accounts;\n};\n\nconst initialState: SliceState = {\n  actionBar: {\n    tweet: POCKET.STAGE_TWEET_ACTION_BAR.TWEET, // stage for tweet ActionBar: 'addAvatar' 'follow' 'tweet'\n  },\n  defaultAccount: {\n    name: null,\n    account: null,\n  },\n  accounts: null,\n};\n\nconst checkAddress = (obj, network, address) =>\n  Object.keys(obj).some((k) => {\n    if (obj[k][network]) {\n      return obj[k][network].bech32 === address;\n    }\n  });\n\nfunction saveToLocalStorage(state: SliceState) {\n  const { defaultAccount, accounts } = state;\n\n  defaultAccount &&\n    localStorage.setItem(\n      localStorageKeys.pocket.POCKET,\n      JSON.stringify({\n        [defaultAccount.name]: defaultAccount.account,\n      })\n    );\n  accounts &&\n    localStorage.setItem(\n      localStorageKeys.pocket.POCKET_ACCOUNT,\n      JSON.stringify(accounts)\n    );\n}\n\nconst slice = createSlice({\n  name: 'pocket',\n  initialState,\n  reducers: {\n    setDefaultAccount: (\n      state,\n      {\n        payload: { name, account },\n      }: PayloadAction<{ name: string; account?: Account }>\n    ) => {\n      state.defaultAccount = {\n        name,\n        account: account || state.accounts?.[name] || null,\n      };\n\n      saveToLocalStorage(state);\n    },\n    setAccounts: (state, { payload }: PayloadAction<Accounts>) => {\n      state.accounts = payload;\n\n      saveToLocalStorage(state);\n    },\n    setStageTweetActionBar: (state, { payload }: PayloadAction<string>) => {\n      state.actionBar.tweet = payload;\n    },\n\n    // bullshit\n    deleteAddress: (state, { payload }: PayloadAction<string>) => {\n      if (state.accounts) {\n        Object.keys(state.accounts).forEach((accountKey) => {\n          Object.keys(state.accounts[accountKey]).forEach((networkKey) => {\n            if (state.accounts[accountKey][networkKey].bech32 === payload) {\n              delete state.accounts[accountKey][networkKey];\n\n              if (Object.keys(state.accounts[accountKey]).length === 0) {\n                delete state.accounts[accountKey];\n              }\n\n              if (state.defaultAccount?.account?.cyber?.bech32 === payload) {\n                const entries = Object.entries(state.accounts);\n\n                const entryCyber = entries.find(\n                  ([, value]) => value.cyber?.bech32\n                );\n\n                if (entryCyber) {\n                  state.defaultAccount = {\n                    name: entryCyber[0],\n                    account: entryCyber[1],\n                  };\n                } else {\n                  state.defaultAccount = {\n                    name: null,\n                    account: null,\n                  };\n                }\n              }\n\n              saveToLocalStorage(state);\n            }\n          });\n        });\n      }\n    },\n  },\n});\n\nexport const selectCurrentAddress = (store: RootState) =>\n  store.pocket.defaultAccount.account?.cyber?.bech32;\n\nexport const {\n  setDefaultAccount,\n  setAccounts,\n  setStageTweetActionBar,\n  deleteAddress,\n} = slice.actions;\n\nexport default slice.reducer;\n\n// refactor this\nexport const initPocket = () => (dispatch: Dispatch) => {\n  let defaultAccounts = null;\n  let defaultAccountsKeys = null;\n  let accountsTemp: Accounts | null = null;\n\n  const localStoragePocketAccount = localStorage.getItem(\n    localStorageKeys.pocket.POCKET_ACCOUNT\n  );\n  const localStoragePocket = localStorage.getItem(\n    localStorageKeys.pocket.POCKET\n  );\n  if (localStoragePocket !== null) {\n    const localStoragePocketData = JSON.parse(localStoragePocket);\n    const keyPocket = Object.keys(localStoragePocketData)[0];\n    const accountPocket = Object.values(localStoragePocketData)[0];\n    defaultAccounts = accountPocket;\n    defaultAccountsKeys = keyPocket;\n  }\n  if (localStoragePocketAccount !== null) {\n    const localStoragePocketAccountData = JSON.parse(localStoragePocketAccount);\n    if (localStoragePocket === null) {\n      const keys0 = Object.keys(localStoragePocketAccountData)[0];\n      localStorage.setItem(\n        localStorageKeys.pocket.POCKET,\n        JSON.stringify({ [keys0]: localStoragePocketAccountData[keys0] })\n      );\n      defaultAccounts = localStoragePocketAccountData[keys0];\n      defaultAccountsKeys = keys0;\n    } else if (defaultAccountsKeys !== null) {\n      accountsTemp = {\n        [defaultAccountsKeys]:\n          localStoragePocketAccountData[defaultAccountsKeys] || undefined,\n        ...localStoragePocketAccountData,\n      };\n    }\n  } else {\n    localStorage.removeItem(localStorageKeys.pocket.POCKET);\n    localStorage.removeItem(localStorageKeys.pocket.POCKET_ACCOUNT);\n  }\n\n  defaultAccountsKeys &&\n    defaultAccounts &&\n    dispatch(\n      setDefaultAccount({\n        name: defaultAccountsKeys,\n        account: defaultAccounts,\n      })\n    );\n\n  accountsTemp &&\n    Object.keys(accountsTemp).forEach((key) => {\n      if (!accountsTemp[key] || Object.keys(accountsTemp[key]).length === 0) {\n        delete accountsTemp[key];\n      }\n    });\n\n  accountsTemp && dispatch(setAccounts(accountsTemp));\n};\n\nconst defaultNameAccount = () => {\n  let key = 'Account 1';\n  let count = 1;\n\n  const localStorageCount = localStorage.getItem('count');\n\n  if (localStorageCount !== null) {\n    const dataCount = JSON.parse(localStorageCount);\n    count = parseFloat(dataCount);\n    key = `Account ${count}`;\n  }\n\n  localStorage.setItem('count', JSON.stringify(count + 1));\n\n  return key;\n};\n\nexport const addAddressPocket =\n  (accounts: AccountValue) => (dispatch: Dispatch) => {\n    const key = accounts.name || defaultNameAccount();\n\n    let dataPocketAccount = null;\n    let valueObj = {};\n    let pocketAccount: Accounts = {};\n\n    const localStorageStory = localStorage.getItem(\n      localStorageKeys.pocket.POCKET_ACCOUNT\n    );\n\n    if (localStorageStory !== null) {\n      dataPocketAccount = JSON.parse(localStorageStory);\n      valueObj = Object.values(dataPocketAccount);\n    }\n\n    const isAdded = !checkAddress(valueObj, 'cyber', accounts.bech32);\n\n    if (!isAdded) {\n      return;\n    }\n\n    const cyberAccounts: Account = {\n      cyber: accounts,\n    };\n\n    if (localStorageStory !== null) {\n      pocketAccount = { [key]: cyberAccounts, ...dataPocketAccount };\n    } else {\n      pocketAccount = { [key]: cyberAccounts };\n    }\n\n    if (Object.keys(pocketAccount).length > 0) {\n      dispatch(setAccounts(pocketAccount));\n      if (accounts.keys !== 'read-only') {\n        dispatch(setDefaultAccount({ name: key, account: cyberAccounts }));\n      }\n    }\n  };\n","const LEDGER = {\n  STAGE_INIT: 0,\n  STAGE_SELECTION: 1,\n  STAGE_LEDGER_INIT: 2,\n  STAGE_READY: 3,\n  STAGE_WAIT: 4,\n  STAGE_GENERATED: 5,\n  STAGE_SUBMITTED: 6,\n  STAGE_CONFIRMING: 7,\n  STAGE_CONFIRMED: 8,\n  STAGE_ERROR: 15,\n  HDPATH: [44, 118, 0, 0, 0],\n};\n\nconst GENESIS_SUPPLY = 1000000000000000;\nconst TOTAL_GOL_GENESIS_SUPPLY = 50000000000000;\n\nconst POCKET = {\n  STAGE_TWEET_ACTION_BAR: {\n    ADD_AVATAR: 'addAvatar',\n    FOLLOW: 'follow',\n    TWEET: 'tweet',\n  },\n};\n\nexport { LEDGER, GENESIS_SUPPLY, TOTAL_GOL_GENESIS_SUPPLY, POCKET };\n","import { updateSenseList } from 'src/features/sense/redux/sense.redux';\nimport { setDefaultAccount } from 'src/redux/features/pocket';\nimport { Account } from 'src/types/defaultAccount';\nimport { SenseListItem } from '../types/sense';\nimport {\n  BroadcastChannelMessage,\n  ServiceName,\n  ServiceStatus,\n  SyncEntryName,\n  SyncProgress,\n} from '../types/services';\nimport { CYB_BROADCAST_CHANNEL } from './consts';\n\nclass BroadcastChannelSender {\n  private channel: BroadcastChannel;\n\n  constructor() {\n    this.channel = new BroadcastChannel(CYB_BROADCAST_CHANNEL);\n  }\n\n  public postServiceStatus(\n    name: ServiceName,\n    status: ServiceStatus,\n    message?: string\n  ) {\n    this.channel.postMessage({\n      type: 'service_status',\n      value: { name, status, message },\n    });\n  }\n\n  public postSyncEntryProgress(entry: SyncEntryName, state: SyncProgress) {\n    // console.log('postSyncEntryProgress', entry, state);\n    this.channel.postMessage({ type: 'sync_entry', value: { entry, state } });\n  }\n\n  public postSenseUpdate(senseList: SenseListItem[]) {\n    // console.log('postSenseUpdate', senseList);\n    if (senseList.length > 0) {\n      this.channel.postMessage(updateSenseList(senseList));\n    }\n  }\n\n  public postSetDefaultAccount(name: string, account?: Account) {\n    this.channel.postMessage(\n      setDefaultAccount({\n        name,\n        account,\n      })\n    );\n  }\n\n  post(msg: BroadcastChannelMessage) {\n    this.channel.postMessage(msg);\n  }\n}\n\nexport default BroadcastChannelSender;\n","export const CYB_BROADCAST_CHANNEL = 'cyb-broadcast-channel';\n","export class QueueItemTimeoutError extends Error {\n  constructor(timeoutMs: number) {\n    super(`Timeout after ${timeoutMs}`);\n    Object.setPrototypeOf(this, QueueItemTimeoutError.prototype);\n  }\n}\n","/* eslint-disable import/prefer-default-export */\nexport const CustomHeaders = {\n  XCybSource: 'X-Cyb-Source',\n};\n\nexport enum XCybSourceValues {\n  sharedWorker = 'shared-worker',\n}\n","import {\n  BehaviorSubject,\n  EMPTY,\n  Observable,\n  catchError,\n  debounceTime,\n  filter,\n  interval,\n  map,\n  merge,\n  mergeMap,\n  of,\n  throwError,\n  timeout,\n} from 'rxjs';\n\nimport * as R from 'ramda';\n\nimport { CybIpfsNode, IpfsContentSource } from 'src/services/ipfs/types';\nimport { fetchIpfsContent } from 'src/services/ipfs/utils/utils-ipfs';\nimport { ParticleCid } from 'src/types/base';\n\nimport { promiseToObservable } from '../../utils/rxjs/helpers';\n\nimport type {\n  IDeferredDbSaver,\n  QueueItem,\n  QueueItemAsyncResult,\n  QueueItemCallback,\n  QueueItemOptions,\n  QueueItemResult,\n  QueueSource,\n  QueueStats,\n} from './types';\n\nimport { QueueStrategy } from './QueueStrategy';\n\nimport BroadcastChannelSender from '../backend/channels/BroadcastChannelSender';\nimport { QueueItemTimeoutError } from './QueueItemTimeoutError';\nimport { CustomHeaders, XCybSourceValues } from './constants';\n\nconst QUEUE_DEBOUNCE_MS = 33;\nconst CONNECTION_KEEPER_RETRY_MS = 5000;\n\nfunction getQueueItemTotalPriority(item: QueueItem): number {\n  return (item.priority || 0) + (item.viewPortPriority || 0);\n}\n\nconst debugCid = (cid: ParticleCid, prefix: string, ...args) => {\n  console.log(`>>> ${prefix}: ${cid}`, ...args);\n};\n\nconst strategies = {\n  external: new QueueStrategy(\n    {\n      db: { timeout: 5000, maxConcurrentExecutions: 999 },\n      node: { timeout: 60 * 1000, maxConcurrentExecutions: 50 },\n      gateway: { timeout: 21000, maxConcurrentExecutions: 11 },\n    },\n    ['db', 'node', 'gateway']\n  ),\n  embedded: new QueueStrategy(\n    {\n      db: { timeout: 5000, maxConcurrentExecutions: 999 },\n      node: { timeout: 60 * 1000, maxConcurrentExecutions: 50 },\n      gateway: { timeout: 21000, maxConcurrentExecutions: 11 },\n    },\n    ['db', 'gateway', 'node']\n  ),\n  helia: new QueueStrategy(\n    {\n      db: { timeout: 5000, maxConcurrentExecutions: 999 },\n      node: { timeout: 6 * 1000, maxConcurrentExecutions: 50 }, // TODO: set to 60\n      gateway: { timeout: 3 * 1000, maxConcurrentExecutions: 11 },\n    },\n    ['db', 'node', 'gateway']\n  ),\n};\n\ntype QueueMap = Map<ParticleCid, QueueItem>;\n\nclass QueueManager {\n  private queue$ = new BehaviorSubject<QueueMap>(new Map());\n\n  private node: CybIpfsNode | undefined = undefined;\n\n  private defferedDbSaver?: IDeferredDbSaver;\n\n  private strategy: QueueStrategy;\n\n  private queueDebounceMs: number;\n\n  private lastNodeCallTime: number = Date.now();\n\n  private channel = new BroadcastChannelSender();\n\n  private executing: Record<QueueSource, Set<ParticleCid>> = {\n    db: new Set(),\n    node: new Set(),\n    gateway: new Set(),\n  };\n\n  private switchStrategy(strategy: QueueStrategy): void {\n    this.strategy = strategy;\n  }\n\n  public async setNode(node: CybIpfsNode, customStrategy?: QueueStrategy) {\n    console.log(`switch node from ${this.node?.nodeType} to ${node.nodeType}`);\n    this.node = node;\n    this.switchStrategy(customStrategy || strategies[node.nodeType]);\n  }\n\n  private getItemBySourceAndPriority(queue: QueueMap) {\n    const pendingItems = [...queue.values()].filter(\n      (i) => i.status === 'pending'\n    );\n\n    const pendingBySource = R.groupBy((i) => i.source, pendingItems);\n\n    const itemsToExecute: QueueItem[] = [];\n    // eslint-disable-next-line no-loop-func, no-restricted-syntax\n    for (const [queueSource, items] of Object.entries(pendingBySource)) {\n      const settings = this.strategy.settings[queueSource as IpfsContentSource];\n\n      const executeCount =\n        settings.maxConcurrentExecutions -\n        this.executing[queueSource as IpfsContentSource].size;\n\n      const itemsByPriority = items\n        .sort(\n          (a, b) => getQueueItemTotalPriority(b) - getQueueItemTotalPriority(a)\n        )\n        .slice(0, executeCount);\n\n      // console.log('---itemsByPriority', itemsByPriority);\n\n      itemsToExecute.push(...itemsByPriority);\n    }\n\n    return itemsToExecute;\n  }\n\n  private postSummary() {\n    const summary = `(total: ${this.queue$.value.size} |  db - ${this.executing.db.size} node - ${this.executing.node.size} gateway - ${this.executing.gateway.size})`;\n\n    this.channel.postServiceStatus('ipfs', 'started', summary);\n  }\n\n  private fetchData$(item: QueueItem) {\n    const { cid, source, callbacks, controller } = item;\n    // const abortController = controller || new AbortController();\n    const settings = this.strategy.settings[source];\n    this.executing[source].add(cid);\n    this.postSummary();\n    const queueItem = this.queue$.value.get(cid);\n    // Mutate item without next\n    this.queue$.value.set(cid, {\n      ...queueItem,\n      status: 'executing',\n      executionTime: Date.now(),\n      controller: new AbortController(),\n    } as QueueItem);\n    // debugCid(cid, 'fetchData', cid, source);\n    callbacks.map((callback) => callback(cid, 'executing', source));\n\n    return promiseToObservable(async () => {\n      try {\n        const res = await fetchIpfsContent(cid, source, {\n          controller,\n          node: this.node,\n          headers: {\n            [CustomHeaders.XCybSource]: XCybSourceValues.sharedWorker,\n          },\n        }).then((content) => {\n          this.defferedDbSaver?.enqueueIpfsContent(content);\n\n          return content;\n        });\n        return res;\n      } catch (e) {\n        // console.log('---promtoo', e);\n        throw e;\n      }\n    }).pipe(\n      timeout({\n        each: settings.timeout,\n        with: () =>\n          throwError(() => {\n            controller?.abort('timeout');\n            return new QueueItemTimeoutError(settings.timeout);\n          }),\n      }),\n      map((result): QueueItemResult => {\n        return {\n          item,\n          status: result ? 'completed' : 'error',\n          source,\n          result,\n        };\n      }),\n      catchError((error): Observable<QueueItemResult> => {\n        // debugCid(cid, 'fetchData - fetchIpfsContent catchErr', error);\n        if (error instanceof QueueItemTimeoutError) {\n          return of({\n            item,\n            status: 'timeout',\n            source,\n          });\n        }\n\n        if (error?.name === 'AbortError') {\n          return of({ item, status: 'cancelled', source });\n        }\n        return of({ item, status: 'error', source });\n      })\n    );\n  }\n\n  /**\n   * Mutate queue item, and return new queue\n   * @param cid\n   * @param changes\n   * @returns\n   */\n  private mutateQueueItem(cid: string, changes: Partial<QueueItem>) {\n    const queue = this.queue$.value;\n    const item = queue.get(cid);\n    if (item) {\n      queue.set(cid, { ...item, ...changes });\n    }\n\n    return this.queue$.next(queue);\n  }\n\n  private removeAndNext(cid: string): void {\n    const queue = this.queue$.value;\n    queue.delete(cid);\n    this.queue$.next(queue);\n  }\n\n  // reset status and switch to next source\n  private switchSourceAndNext(item: QueueItem, nextSource: QueueSource): void {\n    item.callbacks.map((callback) => callback(item.cid, 'pending', nextSource));\n\n    this.mutateQueueItem(item.cid, { status: 'pending', source: nextSource });\n  }\n\n  private cancelDeprioritizedItems(queue: QueueMap): QueueMap {\n    (['node', 'gateway'] as IpfsContentSource[]).forEach((source) => {\n      Array.from(this.executing[source]).forEach((cid) => {\n        const item = queue.get(cid);\n        if (item && getQueueItemTotalPriority(item) < 0 && item.controller) {\n          // abort request and move to pending\n          item.controller.abort('cancelled');\n          item.callbacks.map((callback) =>\n            callback(item.cid, 'pending', item.source)\n          );\n\n          queue.set(cid, { ...item, status: 'pending' });\n          // console.log('-----cancel item', item, queue);\n\n          this.executing[source].delete(cid);\n        }\n      });\n    });\n\n    return queue;\n  }\n\n  private releaseExecution(cid: string) {\n    // eslint-disable-next-line no-restricted-syntax\n    Object.keys(this.executing).forEach((key) =>\n      this.executing[key as IpfsContentSource].delete(cid)\n    );\n  }\n\n  constructor(\n    ipfsInstance$: Observable<CybIpfsNode | undefined>,\n    {\n      strategy,\n      queueDebounceMs,\n      defferedDbSaver,\n    }: {\n      strategy?: QueueStrategy;\n      queueDebounceMs?: number;\n      defferedDbSaver?: IDeferredDbSaver;\n    }\n  ) {\n    ipfsInstance$.subscribe((node) => {\n      if (node) {\n        this.setNode(node);\n      }\n    });\n\n    this.strategy = strategy || strategies.embedded;\n    this.queueDebounceMs = queueDebounceMs || QUEUE_DEBOUNCE_MS;\n    this.defferedDbSaver = defferedDbSaver;\n\n    // Little hack to handle keep-alive connection to swarm cyber node\n    // Fix some lag with node peers(when it shown swarm node in peers but not  connected anymore)\n    interval(CONNECTION_KEEPER_RETRY_MS)\n      .pipe(filter(() => this.queue$.value.size > 0 && !!this.node))\n      .subscribe(() => this.node!.reconnectToSwarm(this.lastNodeCallTime));\n\n    this.queue$\n      .pipe(\n        // tap(() => console.log('----QUEUE')),\n        debounceTime(this.queueDebounceMs),\n        map((queue) => this.cancelDeprioritizedItems(queue)),\n        mergeMap((queue) => {\n          const workItems = this.getItemBySourceAndPriority(queue);\n          // console.log('---workItems', workItems);\n          if (workItems.length > 0) {\n            // wake up connnection to swarm cyber node\n            this.node?.reconnectToSwarm(this.lastNodeCallTime);\n\n            return merge(...workItems.map((item) => this.fetchData$(item)));\n          }\n          return EMPTY;\n        })\n      )\n      .subscribe(({ item, status, source, result }) => {\n        const { cid } = item;\n        const callbacks = this.queue$.value.get(cid)?.callbacks || [];\n        // fix to process dublicated items\n        // debugCid(cid, 'subscribe', cid, source, status, result, callbacks);\n\n        callbacks.map((callback) => callback(cid, status, source, result));\n\n        // HACK to use with GracePeriod for reconnection\n        if (source === 'node') {\n          this.lastNodeCallTime = Date.now();\n        }\n\n        this.executing[source].delete(cid);\n\n        // success execution -> next\n        if (status === 'completed' || status === 'cancelled') {\n          // debugCid(cid, '------done', item, status, source, result);\n          this.removeAndNext(cid);\n        } else {\n          // debugCid(cid, '------error', item, status, source, result);\n\n          // Retry -> (next sources) or -> next\n          const nextSource = this.strategy.getNextSource(source);\n\n          if (nextSource) {\n            this.switchSourceAndNext(item, nextSource);\n          } else {\n            this.removeAndNext(cid);\n            // notify thatn nothing found from all sources\n            callbacks.map((callback) =>\n              callback(cid, 'not_found', source, result)\n            );\n          }\n        }\n\n        this.postSummary();\n      });\n  }\n\n  public enqueue(\n    cid: string,\n    callback: QueueItemCallback,\n    options: QueueItemOptions = {}\n  ): void {\n    const queue = this.queue$.value;\n    const existingItem = queue.get(cid);\n    // debugCid(cid, '----/--enqueue ', cid, existingItem);\n\n    // In case if item already in queue,\n    // just attach one more callback to quieued item\n    if (existingItem) {\n      this.mutateQueueItem(cid, {\n        callbacks: [...existingItem.callbacks, callback],\n      });\n    } else {\n      const source = options.initialSource || this.strategy.order[0];\n      const item: QueueItem = {\n        cid,\n        callbacks: [callback],\n        source, // initial method to fetch\n        status: 'pending',\n        postProcessing: true, // by default rune-post-processing enabled\n        ...options,\n      };\n\n      callback(cid, 'pending', source);\n\n      queue.set(cid, item);\n      this.queue$.next(queue);\n    }\n  }\n\n  public enqueueAndWait(\n    cid: string,\n    options: QueueItemOptions = {}\n  ): Promise<QueueItemAsyncResult> {\n    return new Promise((resolve) => {\n      const callback = ((cid, status, source, result) => {\n        if (status === 'completed' || status === 'not_found') {\n          resolve({ status, source, result });\n        }\n      }) as QueueItemCallback;\n\n      this.enqueue(cid, callback, options);\n    });\n  }\n\n  public updateViewPortPriority(cid: string, viewPortPriority: number) {\n    this.mutateQueueItem(cid, { viewPortPriority });\n  }\n\n  public cancel(cid: string): void {\n    const queue = this.queue$.value;\n    const item = queue.get(cid);\n    // console.log('-----cancel item', item, item?.controller);\n    if (item) {\n      // If item has no abortController we can just remove it,\n      // otherwise abort&keep-to-finalize\n      if (!item.controller) {\n        this.removeAndNext(cid);\n      } else {\n        item.controller.abort('cancelled');\n      }\n    }\n  }\n\n  public cancelByParent(parent: string): void {\n    const queue = this.queue$.value;\n\n    queue.forEach((item, cid) => {\n      if (item.parent === parent) {\n        this.releaseExecution(cid);\n        item.controller?.abort('cancelled');\n        queue.delete(cid);\n      }\n    });\n\n    this.queue$.next(queue);\n  }\n\n  public clear(): void {\n    const queue = this.queue$.value;\n\n    queue.forEach((item, cid) => {\n      this.releaseExecution(cid);\n      item.controller?.abort('cancelled');\n      queue.delete(cid);\n    });\n\n    this.queue$.next(new Map());\n  }\n\n  public getQueueMap(): QueueMap {\n    return this.queue$.value;\n  }\n\n  public getQueueList(): QueueItem[] {\n    return Array.from(this.queue$.value.values());\n  }\n\n  public getStats(): QueueStats[] {\n    const fn = R.pipe(\n      R.countBy<QueueItem>(R.prop('status')),\n      R.toPairs,\n      R.map(R.zipObj(['status', 'count']))\n    );\n\n    return fn(this.getQueueList()) as QueueStats[];\n  }\n}\n\n// TODO: MOVE TO SEPARATE FILE AS GLOBAL VARIABLE\n// const queueManager = new QueueManager<IPFSContentMaybe>();\n\n// if (typeof window !== 'undefined') {\n//   window.qm = queueManager;\n// }\n\n// export { queueManager };\nexport default QueueManager;\n","import { Observable } from 'rxjs';\n\n/**\n * Convert promise to observable\n * @param promiseFactory\n * @returns\n */\nexport function promiseToObservable<T>(promiseFactory: () => Promise<T>) {\n  return new Observable<T>((observer) => {\n    promiseFactory()\n      .then((response) => {\n        observer.next(response);\n        observer.complete();\n      })\n      .catch((error) => {\n        console.debug('----promiseToObservable error', error); //, error\n        observer.error(error);\n      });\n  });\n}\n","import { IPFSContentMaybe, IpfsContentSource } from '../ipfs/types';\nimport { LinkDbEntity } from '../CozoDb/types/entities';\nimport { LinkDto } from '../CozoDb/types/dto';\n\n/* eslint-disable import/no-unused-modules */\nexport type QueueItemStatus =\n  | 'pending'\n  | 'executing'\n  | 'timeout'\n  | 'completed'\n  | 'cancelled'\n  | 'error'\n  | 'not_found';\n\nexport type QueueSourceSettings = {\n  timeout: number;\n  maxConcurrentExecutions: number;\n};\n\nexport type QueueSource = IpfsContentSource;\n\nexport type QueueSettings = Record<QueueSource, QueueSourceSettings>;\n\nexport interface IQueueStrategy {\n  settings: QueueSettings;\n  order: QueueSource[];\n  getNextSource(source: QueueSource): QueueSource | undefined;\n}\n\nexport type QueueStats = {\n  status: QueueItemStatus;\n  count: number;\n};\n\nexport enum QueuePriority {\n  ZERO = 0,\n  LOW = 0.1,\n  MEDIUM = 0.5,\n  HIGH = 0.9,\n  URGENT = 1,\n}\nexport type QueueItemOptions = {\n  parent?: string;\n  priority?: QueuePriority | number;\n  viewPortPriority?: number;\n  initialSource?: QueueSource;\n  postProcessing?: boolean;\n};\n\nexport type QueueItemCallback = (\n  cid: string,\n  status: QueueItemStatus,\n  source: QueueSource,\n  result?: IPFSContentMaybe\n) => void;\n\nexport type QueueItem = {\n  cid: string;\n  source: QueueSource;\n  status: QueueItemStatus;\n  callbacks: QueueItemCallback[];\n  controller?: AbortController;\n  executionTime?: number;\n} & Omit<QueueItemOptions, 'initialSource'>;\n\nexport type QueueItemResult = {\n  item: QueueItem;\n  status: QueueItemStatus;\n  source: QueueSource;\n  result?: IPFSContentMaybe;\n};\n\nexport type QueueItemAsyncResult = Omit<QueueItemResult, 'item'>;\n\nexport type QueueItemPostProcessor = (\n  content: IPFSContentMaybe\n) => Promise<IPFSContentMaybe>;\n\nexport interface IDeferredDbSaver {\n  // postProcess: (content: IPFSContentMaybe) => Promise<IPFSContentMaybe>;\n  enqueueIpfsContent: (content: IPFSContentMaybe) => void;\n  enqueueLinks: (links: LinkDto[]) => void;\n}\n\nexport type FetchParticleAsync = (\n  cid: string,\n  options?: QueueItemOptions\n) => Promise<QueueItemAsyncResult>;\n","import type { TransferHandler } from 'comlink';\nimport { IPFSContent } from 'src/services/ipfs/types';\n\ntype IPFSContentTransferable = Omit<IPFSContent, 'result'> & {\n  port: MessagePort;\n};\n\nfunction createAsyncIterable(port: MessagePort): AsyncIterable<Uint8Array> {\n  return {\n    async *[Symbol.asyncIterator](): AsyncGenerator<\n      Uint8Array,\n      void,\n      undefined\n    > {\n      let done = false;\n      while (!done) {\n        // eslint-disable-next-line no-loop-func\n        const promise = new Promise<Uint8Array | null>((resolve) => {\n          // resolve = res;\n          port.onmessage = (event: MessageEvent) => {\n            if (event.data === null) {\n              done = true;\n              resolve(null);\n            } else {\n              resolve(event.data);\n            }\n          };\n        });\n        // eslint-disable-next-line no-await-in-loop\n        const value = await promise;\n        // eslint-disable-next-line no-await-in-loop\n        if (value !== null) {\n          yield value;\n        }\n      }\n    },\n  };\n}\n\nconst IPFSContentTransferHandler: TransferHandler<\n  IPFSContent | undefined,\n  IPFSContentTransferable | null\n> = {\n  canHandle: (obj: IPFSContent | undefined) =>\n    obj && obj.result && typeof obj.result[Symbol.asyncIterator] === 'function',\n  serialize(obj: IPFSContent) {\n    if (obj === undefined) {\n      return [null, []];\n    }\n    const { result, ...rest } = obj;\n    const { port1, port2 } = new MessageChannel();\n    if (result) {\n      (async () => {\n        // eslint-disable-next-line no-restricted-syntax\n        for await (const value of result) {\n          port1.postMessage(value);\n        }\n        port1.postMessage(null); // Send  \"end\" message\n\n        port1.close();\n      })();\n    }\n    return [{ ...rest, port: port2 }, [port2]];\n  },\n  deserialize(serializedObj: IPFSContentTransferable | null) {\n    if (!serializedObj) {\n      return undefined;\n    }\n    const { port, ...rest } = serializedObj;\n\n    return {\n      ...rest,\n      result: createAsyncIterable(port),\n    };\n  },\n};\n\nexport { IPFSContentTransferHandler };\n","import { wrap, Remote, expose, transferHandlers } from 'comlink';\nimport { IPFSContentTransferHandler } from './serializers';\n\ntype WorkerType = SharedWorker | Worker;\n\nconst isSharedWorkersSupported = typeof SharedWorker !== 'undefined';\n\nconst isSharedWorkerUsed = isSharedWorkersSupported && !process.env.IS_DEV;\n\n// apply serializers for custom types\nfunction installTransferHandlers() {\n  transferHandlers.set('IPFSContent', IPFSContentTransferHandler);\n}\n\nfunction safeStringify(obj: any): string {\n  try {\n    return JSON.stringify(obj);\n  } catch (error) {\n    return String(obj);\n  }\n}\n\n// Override console.log to send logs to main thread\nfunction overrideLogging(worker: Worker | MessagePort) {\n  const consoleLogMap = {\n    log: { original: console.log },\n    error: { original: console.error },\n    warn: { original: console.warn },\n  };\n  const replaceConsoleLog = (method: keyof typeof consoleLogMap) => {\n    const { original } = consoleLogMap[method];\n\n    consoleLogMap[method].original = console[method];\n\n    console[method] = (...args) => {\n      original.apply(console, args);\n      const serializableArgs = args.map((arg) => safeStringify(arg));\n\n      worker.postMessage({ type: 'console', method, args: serializableArgs });\n    };\n  };\n\n  Object.keys(consoleLogMap).forEach((method) =>\n    replaceConsoleLog(method as keyof typeof consoleLogMap)\n  );\n}\n\n// Install handlers for logging from worker\nfunction installLoggingHandler(worker: Worker | MessagePort, name: string) {\n  // Add event listener\n  worker.addEventListener('message', (event) => {\n    if (event.data.type === 'console') {\n      const { method, args } = event.data;\n\n      console[method](name, ...args);\n    }\n  });\n}\n\n// Create Shared Worker with fallback to usual Worker(in case of DEV too)\nexport function createWorkerApi<T>(\n  workerUrl: URL,\n  workerName: string\n): { worker: WorkerType; workerApiProxy: Remote<T> } {\n  installTransferHandlers();\n  //&& !process.env.IS_DEV\n  if (isSharedWorkerUsed) {\n    const worker = new SharedWorker(workerUrl, { name: workerName });\n    installLoggingHandler(worker.port, workerName);\n    return { worker, workerApiProxy: wrap<T>(worker.port) };\n  }\n\n  const worker = new Worker(workerUrl);\n  // installLoggingHandler(worker, workerName);\n  return { worker, workerApiProxy: wrap<T>(worker) };\n}\n\nexport function exposeWorkerApi<T>(worker: WorkerType, api: T) {\n  installTransferHandlers();\n  if (typeof worker.onconnect !== 'undefined') {\n    worker.onconnect = (e) => {\n      const port = e.ports[0];\n      overrideLogging(port);\n\n      expose(api, port);\n    };\n  } else {\n    // overrideLogging(worker);\n    expose(api);\n  }\n}\n","import { createCyblogChannel } from 'src/utils/logging/cyblog';\nimport {\n  ProgressTracking,\n  SyncEntryName,\n  SyncProgress,\n} from '../types/services';\nimport BroadcastChannelSender from './BroadcastChannelSender';\n\nexport const broadcastStatus = (\n  name: SyncEntryName,\n  channelApi: BroadcastChannelSender\n) => {\n  // const cyblogCh = createCyblogChannel({ thread: 'bckd', module: name });\n  return {\n    sendStatus: (\n      status: SyncProgress['status'],\n      message?: string,\n      progress?: ProgressTracking\n    ) => {\n      // cyblogCh.info(`>>>$ sync ${name} status: ${status} message: ${message}`);\n      channelApi.postSyncEntryProgress(name, {\n        status,\n        message,\n        progress,\n        done: ['active', 'error', 'listen'].some((s) => s === status),\n      });\n    },\n  };\n};\n","async function* arrayToAsyncIterable<T>(array: T[]): AsyncIterable<T> {\n  // eslint-disable-next-line no-restricted-syntax\n  for (const item of array) {\n    yield item;\n  }\n}\n\nasync function asyncIterableBatchProcessor<T, K>(\n  items: AsyncIterable<T> | Iterable<T>,\n  batchProcess: (arg: T[]) => Promise<K>,\n  batchSize = 10\n): Promise<void> {\n  let batch = [];\n  // eslint-disable-next-line no-restricted-syntax\n  for await (const item of items) {\n    batch.push(item);\n    if (batch.length === batchSize) {\n      await batchProcess(batch);\n      batch = [];\n    }\n  }\n  // process the rest\n  if (batch.length > 0) {\n    await batchProcess(batch);\n  }\n}\n\nasync function asyncIterableToArray<T>(asyncIterable: AsyncIterable<T>) {\n  const resultArray = [];\n  // eslint-disable-next-line no-restricted-syntax\n  for await (const item of asyncIterable) {\n    resultArray.push(item);\n  }\n  return resultArray;\n}\n// Create a helper function to create AsyncIterable from a list and iterate one by one\nfunction createAsyncIterable<T>(data: T[]): AsyncIterable<T> {\n  let index = 0;\n  return {\n    [Symbol.asyncIterator]() {\n      return {\n        next(): Promise<IteratorResult<T>> {\n          if (index < data.length) {\n            return Promise.resolve({ done: false, value: data[index++] });\n          }\n          return Promise.resolve({ done: true, value: undefined as any });\n        },\n      };\n    },\n  };\n}\n\n// eslint-disable-next-line import/prefer-default-export\nexport async function* fetchIterableByOffset<T, P>(\n  fetchFunction: (params: P & { offset: number }) => Promise<T[]>,\n  params: P\n): AsyncGenerator<T[], void, undefined> {\n  let offset = 0;\n  while (true) {\n    // eslint-disable-next-line no-await-in-loop\n    const items = await fetchFunction({ ...params, offset });\n\n    if (items.length === 0) {\n      break;\n    }\n\n    yield items;\n\n    offset += items.length;\n  }\n}\n\nexport {\n  arrayToAsyncIterable,\n  asyncIterableBatchProcessor,\n  asyncIterableToArray,\n  createAsyncIterable,\n};\n","// export const CID_AVATAR = 'Qmf89bXkJH9jw4uaLkHmZkxQ51qGKfUPtAMxA8rTwBrmTs';\nexport const CID_TWEET = 'QmbdH2WBamyKLPE5zu4mJ9v49qvY8BFfoumoVPMR5V4Rvx';\n\nexport const CID_FOLLOW = 'QmPLSA5oPqYxgc8F7EwrM8WS9vKrr1zPoDniSRFh8HSrxx';\n\nexport const INFINITY = '∞';\n\nexport const WP =\n  'https://ipfs.io/ipfs/QmQ1Vong13MDNxixDyUdjniqqEj8sjuNEBYMyhQU4gQgq3';\n\nexport const CYBER_CONGRESS_ADDRESS =\n  'bostrom1xszmhkfjs3s00z2nvtn7evqxw3dtus6yr8e4pw';\n","import { CID_FOLLOW, CID_TWEET } from 'src/constants/app';\nimport { SyncEntryName } from 'src/services/backend/types/services';\n\nexport const MY_PARTICLES_SYNC_INTERVAL = 5 * 60 * 1000; // 60 sec\nexport const MY_FRIENDS_SYNC_INTERVAL = 5 * 60 * 1000; // 60 sec\nexport const IPFS_SYNC_INTERVAL = 15 * 60 * 1000; // 15 minutes\n\nexport const MAX_DATABASE_PUT_SIZE = 500;\n\nexport const MAX_LINKS_RESOLVE_BATCH = 20;\n\nexport const DAY_IN_MS = 24 * 60 * 60 * 1000;\n\nexport const SENSE_FRIEND_PARTICLES = [CID_TWEET, CID_FOLLOW];\n\nexport const SYNC_ENTRIES_TO_TRACK_PROGRESS = [\n  'my-friends',\n  'particles',\n  'transactions',\n] as SyncEntryName[];\n","import {\n  BehaviorSubject,\n  Observable,\n  filter,\n  mergeMap,\n  tap,\n  map,\n  combineLatest,\n  share,\n  EMPTY,\n} from 'rxjs';\nimport BroadcastChannelSender from 'src/services/backend/channels/BroadcastChannelSender';\nimport { broadcastStatus } from 'src/services/backend/channels/broadcastStatus';\nimport { ParticleCid } from 'src/types/base';\nimport { SyncQueueStatus } from 'src/services/CozoDb/types/entities';\nimport { QueuePriority } from 'src/services/QueueManager/types';\nimport { asyncIterableBatchProcessor } from 'src/utils/async/iterable';\n\nimport DbApi from '../../../DbApi/DbApi';\n\nimport { FetchIpfsFunc } from '../../types';\nimport { ServiceDeps } from '../types';\nimport { SyncQueueItem } from './types';\nimport { MAX_DATABASE_PUT_SIZE } from '../consts';\n\nconst QUEUE_BATCH_SIZE = 100;\n\nclass ParticlesResolverQueue {\n  public isInitialized$: Observable<boolean>;\n\n  private db: DbApi | undefined;\n\n  private waitForParticleResolve: FetchIpfsFunc;\n\n  private statusApi = broadcastStatus('resolver', new BroadcastChannelSender());\n\n  private _syncQueue$ = new BehaviorSubject<Map<ParticleCid, SyncQueueItem>>(\n    new Map()\n  );\n\n  public get queue(): Map<ParticleCid, SyncQueueItem> {\n    return this._syncQueue$.getValue();\n  }\n\n  private _loop$: Observable<any> | undefined;\n\n  public get loop$(): Observable<any> | undefined {\n    return this._loop$;\n  }\n\n  constructor(deps: ServiceDeps) {\n    if (!deps.waitForParticleResolve) {\n      throw new Error('waitForParticleResolve is not defined');\n    }\n\n    this.waitForParticleResolve = deps.waitForParticleResolve;\n\n    deps.dbInstance$.subscribe(async (db) => {\n      this.db = db;\n      await this.loadSyncQueue();\n    });\n\n    this.isInitialized$ = combineLatest([\n      deps.dbInstance$,\n      deps.ipfsInstance$,\n    ]).pipe(\n      map(([dbInstance, ipfsInstance]) => !!ipfsInstance && !!dbInstance)\n    );\n  }\n\n  private async processSyncQueue(pendingItems: SyncQueueItem[]) {\n    // console.log('------processSyncQueue ', pendingItems);\n\n    const batchSize = pendingItems.length;\n\n    this.statusApi.sendStatus(\n      'in-progress',\n      `processing batch ${batchSize}/${batchSize} batch. ${this.queue.size} pending...`\n    );\n\n    let i = batchSize;\n    await Promise.all(\n      pendingItems.map(async (item) => {\n        const { id } = item;\n        // eslint-disable-next-line no-await-in-loop\n        return this.waitForParticleResolve(id, QueuePriority.MEDIUM).then(\n          async (result) => {\n            if (result.status === 'not_found') {\n              await this.db!.updateSyncQueue({\n                id,\n                status: SyncQueueStatus.error,\n              });\n            } else {\n              await this.db!.removeSyncQueue(id);\n            }\n\n            const queue = this._syncQueue$.value;\n            queue.delete(id);\n            i--;\n            this._syncQueue$.next(queue);\n\n            this.statusApi.sendStatus(\n              'in-progress',\n              `processing batch ${batchSize - i}/${batchSize} batch. ${\n                this.queue.size\n              } pending...`\n            );\n          }\n        );\n      })\n    );\n  }\n\n  start() {\n    const source$ = this.isInitialized$.pipe(\n      tap((q) => console.log(`sync queue isInitialized - ${q}`)),\n      filter((isInitialized) => isInitialized === true),\n      mergeMap(() => this._syncQueue$), // Merge the queue$ stream here.\n      // tap((q) => console.log(`sync queue - ${q.size}`)),\n      filter((q) => q.size > 0),\n      mergeMap((queue) => {\n        const list = [...queue.values()];\n\n        const executingCount = list.filter(\n          (i) => i.status === SyncQueueStatus.executing\n        ).length;\n\n        const batchSize = QUEUE_BATCH_SIZE - executingCount;\n\n        if (batchSize > 0) {\n          const pendingItems = list\n            .filter((i) => i.status === SyncQueueStatus.pending)\n            .sort((a, b) => {\n              return a.priority - b.priority;\n            })\n            .slice(0, batchSize);\n\n          if (pendingItems.length > 0) {\n            pendingItems.forEach((i) => {\n              queue.set(i.id, {\n                ...i,\n                status: SyncQueueStatus.executing,\n              });\n            });\n\n            this._syncQueue$.next(queue);\n\n            this.statusApi.sendStatus('in-progress', `starting...`);\n            return this.processSyncQueue(pendingItems);\n          }\n        }\n\n        return EMPTY;\n      })\n    );\n\n    this._loop$ = source$.pipe(share());\n\n    this._loop$.subscribe({\n      next: (result) => {\n        this.statusApi.sendStatus('active');\n      },\n      error: (err) => this.statusApi.sendStatus('error', err.toString()),\n    });\n\n    return this;\n  }\n\n  public async fetchDirect(cid: ParticleCid) {\n    return this.waitForParticleResolve(cid, QueuePriority.URGENT);\n  }\n\n  public async enqueueBatch(cids: ParticleCid[], priority: QueuePriority) {\n    return asyncIterableBatchProcessor(\n      cids,\n      (cids) =>\n        this.enqueue(\n          cids.map((cid) => ({\n            id: cid /* from is tweet */,\n            priority,\n          }))\n        ),\n      MAX_DATABASE_PUT_SIZE\n    );\n  }\n\n  public async enqueue(items: SyncQueueItem[]) {\n    if (items.length === 0) {\n      return;\n    }\n    await this.db!.putSyncQueue(items);\n    const queue = this._syncQueue$.value;\n\n    items.forEach((item) =>\n      queue.set(item.id, { ...item, status: SyncQueueStatus.pending })\n    );\n    this._syncQueue$.next(queue);\n  }\n\n  private async loadSyncQueue() {\n    const queue = await this.db!.getSyncQueue({\n      statuses: [SyncQueueStatus.pending],\n    }).then((items) => new Map(items.map((item) => [item.id, item])));\n\n    this._syncQueue$.next(new Map([...queue, ...this.queue]));\n  }\n}\n\nexport default ParticlesResolverQueue;\n","import dateFormat from 'dateformat';\n\nexport const numberToUtcDate = (timestamp: number) =>\n  dateFormat(new Date(timestamp), 'yyyy-mm-dd\"T\"HH:MM:ss.l', true);\n\nexport const dateToUtcNumber = (isoString: string) =>\n  Date.parse(isoString.endsWith('Z') ? isoString : `${isoString}Z`);\n\nexport const getNowUtcNumber = () => Date.now();\n\nfunction roundMilliseconds(dateTimeString: string) {\n  const date = new Date(dateTimeString);\n  const roundedMilliseconds = Math.round(date.getMilliseconds() / 1000) * 1000;\n  date.setMilliseconds(roundedMilliseconds);\n  return dateFormat(date, 'yyyy-mm-dd\"T\"HH:MM:ss.l');\n}\nfunction getCurrentTimezoneOffset() {\n  const now = new Date();\n  return -now.getTimezoneOffset() / 60;\n}\n\nfunction pluralizeUnit(quantity: number, unit: string): string {\n  return quantity === 1 ? unit : `${unit}s`;\n}\n\nconst minuteInMs = 60000; // 60 seconds * 1000 milliseconds\nconst hourInMs = 3600000; // 60 minutes * 60 seconds * 1000 milliseconds\nconst dayInMs = 86400000; // 24 hours * 60 minutes * 60 seconds * 1000 milliseconds\n\nfunction convertTimestampToString(timestamp: number): string {\n  if (timestamp < minuteInMs) {\n    const seconds = Math.floor(timestamp / 1000);\n    return `${seconds} ${pluralizeUnit(seconds, 'second')}`;\n  }\n  if (timestamp < hourInMs) {\n    const minutes = Math.floor(timestamp / minuteInMs);\n    return `${minutes} ${pluralizeUnit(minutes, 'minute')}`;\n  }\n  if (timestamp < dayInMs) {\n    const hours = Math.floor(timestamp / hourInMs);\n    return `${hours} ${pluralizeUnit(hours, 'hour')}`;\n  }\n\n  const days = Math.floor(timestamp / dayInMs);\n  return `${days} ${pluralizeUnit(days, 'day')}`;\n}\n\nexport { roundMilliseconds, convertTimestampToString };\n","import { LsResult } from 'ipfs-core-types/src/pin';\nimport { dateToUtcNumber } from 'src/utils/date';\nimport { NeuronAddress, ParticleCid, TransactionHash } from 'src/types/base';\nimport { IPFSContent } from '../ipfs/types';\nimport { LinkDbEntity, PinTypeMap } from './types/entities';\nimport { Transaction } from '../backend/services/indexer/types';\nimport { LinkDto, ParticleDto, PinDto, TransactionDto } from './types/dto';\nimport { CyberlinksByParticleQuery } from 'src/generated/graphql';\n\nexport const mapParticleToEntity = (particle: IPFSContent): ParticleDto => {\n  const { cid, result, meta, textPreview } = particle;\n  const { size, mime, type, blocks, sizeLocal } = meta;\n  // hack to fix string command\n  const text = textPreview?.replace(/\"/g, \"'\") || '';\n  return {\n    cid,\n    size: size || 0,\n    mime: mime || 'unknown',\n    type,\n    text,\n    size_local: sizeLocal || -1,\n    blocks: blocks || 0,\n  };\n};\n\n//TODO: REFACTOR\nexport const mapPinToEntity = (pin: LsResult): PinDto => ({\n  cid: pin.cid.toString(),\n  type: PinTypeMap[pin.type],\n});\n\nexport const mapIndexerTransactionToEntity = (\n  neuron: string,\n  tx: Transaction\n): TransactionDto => {\n  const {\n    transaction_hash,\n    index,\n    transaction: {\n      memo,\n      block: { timestamp, height },\n      success,\n    },\n    type,\n    value,\n  } = tx;\n  return {\n    hash: transaction_hash,\n    index,\n    type,\n    timestamp: dateToUtcNumber(timestamp),\n    // value: JSON.stringify(value),\n    memo,\n    value,\n    success,\n    neuron,\n    blockHeight: height,\n  };\n};\n\n// export const mapSyncStatusToEntity = (\n//   id: NeuronAddress | ParticleCid,\n//   entryType: EntryType,\n//   unreadCount: number,\n//   timestampUpdate: number,\n//   lastId: TransactionHash | ParticleCid = '',\n//   timestampRead: number = timestampUpdate,\n//   meta: Object = {}\n// ): SyncStatusDbEntity => {\n//   return {\n//     entry_type: entryType,\n//     id,\n//     timestamp_update: timestampUpdate,\n//     timestamp_read: timestampRead,\n//     unread_count: unreadCount,\n//     disabled: false,\n//     last_id: lastId,\n//     meta,\n//   };\n// };\n\nexport const mapLinkToLinkDto = (\n  from: ParticleCid,\n  to: ParticleCid,\n  neuron: NeuronAddress = '',\n  timestamp: number = 0\n): LinkDto => ({\n  from,\n  to,\n  neuron,\n  timestamp,\n});\n\nexport const mapLinkFromIndexerToDto = ({\n  from,\n  to,\n  neuron,\n  timestamp,\n  transaction_hash,\n}: CyberlinksByParticleQuery['cyberlinks'][0]): LinkDto => ({\n  from,\n  to,\n  neuron,\n  timestamp: dateToUtcNumber(timestamp),\n  transactionHash: transaction_hash,\n});\n","export async function waitUntil(cond: () => boolean, timeoutDuration = 60000) {\n  if (cond()) {\n    return true;\n  }\n\n  const waitPromise = new Promise((resolve) => {\n    const interval = setInterval(() => {\n      if (cond()) {\n        clearInterval(interval);\n        resolve(true);\n      }\n    }, 10);\n  });\n\n  const timeoutPromise = new Promise((_, reject) => {\n    setTimeout(() => {\n      reject(new Error('waitUntil timed out!'));\n    }, timeoutDuration);\n  });\n\n  return Promise.race([waitPromise, timeoutPromise]);\n}\n\n// eslint-disable-next-line import/no-unused-modules\nexport function makeCancellable<T extends (...args: any[]) => Promise<any>>(\n  func: T,\n  signal: AbortSignal\n): (...funcArgs: Parameters<T>) => Promise<ReturnType<T>> {\n  return async (...args: Parameters<T>): Promise<ReturnType<T>> => {\n    // Promise that listens for the abort signal\n    const abortPromise = new Promise<ReturnType<T>>((_, reject) => {\n      const abortHandler = () => {\n        signal.removeEventListener('abort', abortHandler); // Clean up the event listener\n        reject(new DOMException('The operation was aborted.', 'AbortError'));\n      };\n      signal.addEventListener('abort', abortHandler, { once: true });\n    });\n\n    // Wrapping the original function in a promise\n    const taskPromise = new Promise<ReturnType<T>>(async (resolve, reject) => {\n      try {\n        const result = await func(...args);\n        resolve(result);\n      } catch (error) {\n        reject(error);\n      }\n    });\n\n    // Using Promise.race to handle cancellation\n    return Promise.race([taskPromise, abortPromise]);\n  };\n}\n\nexport function throwIfAborted<T extends (...args: any[]) => Promise<any>>(\n  func: T,\n  signal: AbortSignal\n): (...funcArgs: Parameters<T>) => Promise<ReturnType<T>> {\n  return async (...args: Parameters<T>): Promise<ReturnType<T>> => {\n    if (signal.aborted) {\n      throw new DOMException('The operation was aborted.', 'AbortError');\n    }\n    return func(...args);\n  };\n}\n\n/**\n * Promise will be rejected after timeout.\n *\n * @param promise\n * @param timeout ms\n * @param abortController trigger abort\n * @returns\n */\n// eslint-disable-next-line import/no-unused-modules\nexport async function withTimeout<T>(\n  promise: Promise<T>,\n  timeout: number,\n  abortController?: AbortController\n): Promise<T> {\n  return Promise.race([\n    promise,\n    new Promise<T>((_, reject) => {\n      const timer = setTimeout(() => {\n        abortController?.abort('timeout');\n        clearTimeout(timer);\n        reject(new DOMException('timeout', 'AbortError'));\n      }, timeout);\n    }),\n  ]);\n}\n","import { gql } from '@apollo/client';\nimport * as Apollo from '@apollo/client';\nexport type Maybe<T> = T | null;\nexport type InputMaybe<T> = Maybe<T>;\nexport type Exact<T extends { [key: string]: unknown }> = { [K in keyof T]: T[K] };\nexport type MakeOptional<T, K extends keyof T> = Omit<T, K> & { [SubKey in K]?: Maybe<T[SubKey]> };\nexport type MakeMaybe<T, K extends keyof T> = Omit<T, K> & { [SubKey in K]: Maybe<T[SubKey]> };\nexport type MakeEmpty<T extends { [key: string]: unknown }, K extends keyof T> = { [_ in K]?: never };\nexport type Incremental<T> = T | { [P in keyof T]?: P extends ' $fragmentName' | '__typename' ? T[P] : never };\nconst defaultOptions = {} as const;\n/** All built-in and custom scalars, mapped to their actual values */\nexport type Scalars = {\n  ID: { input: string; output: string; }\n  String: { input: string; output: string; }\n  Boolean: { input: boolean; output: boolean; }\n  Int: { input: number; output: number; }\n  Float: { input: number; output: number; }\n  _coin: { input: any; output: any; }\n  _text: { input: any; output: any; }\n  bigint: { input: any; output: any; }\n  coin: { input: any; output: any; }\n  date: { input: any; output: any; }\n  float8: { input: any; output: any; }\n  json: { input: any; output: any; }\n  jsonb: { input: any; output: any; }\n  numeric: { input: any; output: any; }\n  timestamp: { input: any; output: any; }\n};\n\n/** Boolean expression to compare columns of type \"Boolean\". All fields are combined with logical 'AND'. */\nexport type Boolean_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['Boolean']['input']>;\n  _gt?: InputMaybe<Scalars['Boolean']['input']>;\n  _gte?: InputMaybe<Scalars['Boolean']['input']>;\n  _in?: InputMaybe<Array<Scalars['Boolean']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['Boolean']['input']>;\n  _lte?: InputMaybe<Scalars['Boolean']['input']>;\n  _neq?: InputMaybe<Scalars['Boolean']['input']>;\n  _nin?: InputMaybe<Array<Scalars['Boolean']['input']>>;\n};\n\n/** Boolean expression to compare columns of type \"Int\". All fields are combined with logical 'AND'. */\nexport type Int_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['Int']['input']>;\n  _gt?: InputMaybe<Scalars['Int']['input']>;\n  _gte?: InputMaybe<Scalars['Int']['input']>;\n  _in?: InputMaybe<Array<Scalars['Int']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['Int']['input']>;\n  _lte?: InputMaybe<Scalars['Int']['input']>;\n  _neq?: InputMaybe<Scalars['Int']['input']>;\n  _nin?: InputMaybe<Array<Scalars['Int']['input']>>;\n};\n\n/** Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'. */\nexport type String_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['String']['input']>;\n  _gt?: InputMaybe<Scalars['String']['input']>;\n  _gte?: InputMaybe<Scalars['String']['input']>;\n  /** does the column match the given case-insensitive pattern */\n  _ilike?: InputMaybe<Scalars['String']['input']>;\n  _in?: InputMaybe<Array<Scalars['String']['input']>>;\n  /** does the column match the given POSIX regular expression, case insensitive */\n  _iregex?: InputMaybe<Scalars['String']['input']>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  /** does the column match the given pattern */\n  _like?: InputMaybe<Scalars['String']['input']>;\n  _lt?: InputMaybe<Scalars['String']['input']>;\n  _lte?: InputMaybe<Scalars['String']['input']>;\n  _neq?: InputMaybe<Scalars['String']['input']>;\n  /** does the column NOT match the given case-insensitive pattern */\n  _nilike?: InputMaybe<Scalars['String']['input']>;\n  _nin?: InputMaybe<Array<Scalars['String']['input']>>;\n  /** does the column NOT match the given POSIX regular expression, case insensitive */\n  _niregex?: InputMaybe<Scalars['String']['input']>;\n  /** does the column NOT match the given pattern */\n  _nlike?: InputMaybe<Scalars['String']['input']>;\n  /** does the column NOT match the given POSIX regular expression, case sensitive */\n  _nregex?: InputMaybe<Scalars['String']['input']>;\n  /** does the column NOT match the given SQL regular expression */\n  _nsimilar?: InputMaybe<Scalars['String']['input']>;\n  /** does the column match the given POSIX regular expression, case sensitive */\n  _regex?: InputMaybe<Scalars['String']['input']>;\n  /** does the column match the given SQL regular expression */\n  _similar?: InputMaybe<Scalars['String']['input']>;\n};\n\n/** Boolean expression to compare columns of type \"_coin\". All fields are combined with logical 'AND'. */\nexport type _Coin_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['_coin']['input']>;\n  _gt?: InputMaybe<Scalars['_coin']['input']>;\n  _gte?: InputMaybe<Scalars['_coin']['input']>;\n  _in?: InputMaybe<Array<Scalars['_coin']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['_coin']['input']>;\n  _lte?: InputMaybe<Scalars['_coin']['input']>;\n  _neq?: InputMaybe<Scalars['_coin']['input']>;\n  _nin?: InputMaybe<Array<Scalars['_coin']['input']>>;\n};\n\n/** Boolean expression to compare columns of type \"_text\". All fields are combined with logical 'AND'. */\nexport type _Text_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['_text']['input']>;\n  _gt?: InputMaybe<Scalars['_text']['input']>;\n  _gte?: InputMaybe<Scalars['_text']['input']>;\n  _in?: InputMaybe<Array<Scalars['_text']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['_text']['input']>;\n  _lte?: InputMaybe<Scalars['_text']['input']>;\n  _neq?: InputMaybe<Scalars['_text']['input']>;\n  _nin?: InputMaybe<Array<Scalars['_text']['input']>>;\n};\n\n/** columns and relationships of \"_transaction\" */\nexport type _Transaction = {\n  fee?: Maybe<Scalars['jsonb']['output']>;\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  hash?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  index?: Maybe<Scalars['bigint']['output']>;\n  involved_accounts_addresses?: Maybe<Scalars['_text']['output']>;\n  logs?: Maybe<Scalars['jsonb']['output']>;\n  memo?: Maybe<Scalars['String']['output']>;\n  messages?: Maybe<Scalars['jsonb']['output']>;\n  raw_log?: Maybe<Scalars['String']['output']>;\n  signatures?: Maybe<Scalars['_text']['output']>;\n  signer_infos?: Maybe<Scalars['jsonb']['output']>;\n  subject1?: Maybe<Scalars['String']['output']>;\n  subject2?: Maybe<Scalars['String']['output']>;\n  success?: Maybe<Scalars['Boolean']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n  value?: Maybe<Scalars['jsonb']['output']>;\n};\n\n\n/** columns and relationships of \"_transaction\" */\nexport type _TransactionFeeArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n\n/** columns and relationships of \"_transaction\" */\nexport type _TransactionLogsArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n\n/** columns and relationships of \"_transaction\" */\nexport type _TransactionMessagesArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n\n/** columns and relationships of \"_transaction\" */\nexport type _TransactionSigner_InfosArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n\n/** columns and relationships of \"_transaction\" */\nexport type _TransactionValueArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n/** aggregated selection of \"_transaction\" */\nexport type _Transaction_Aggregate = {\n  aggregate?: Maybe<_Transaction_Aggregate_Fields>;\n  nodes: Array<_Transaction>;\n};\n\n/** aggregate fields of \"_transaction\" */\nexport type _Transaction_Aggregate_Fields = {\n  avg?: Maybe<_Transaction_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<_Transaction_Max_Fields>;\n  min?: Maybe<_Transaction_Min_Fields>;\n  stddev?: Maybe<_Transaction_Stddev_Fields>;\n  stddev_pop?: Maybe<_Transaction_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<_Transaction_Stddev_Samp_Fields>;\n  sum?: Maybe<_Transaction_Sum_Fields>;\n  var_pop?: Maybe<_Transaction_Var_Pop_Fields>;\n  var_samp?: Maybe<_Transaction_Var_Samp_Fields>;\n  variance?: Maybe<_Transaction_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"_transaction\" */\nexport type _Transaction_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<_Transaction_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type _Transaction_Avg_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"_transaction\". All fields are combined with a logical 'AND'. */\nexport type _Transaction_Bool_Exp = {\n  _and?: InputMaybe<Array<_Transaction_Bool_Exp>>;\n  _not?: InputMaybe<_Transaction_Bool_Exp>;\n  _or?: InputMaybe<Array<_Transaction_Bool_Exp>>;\n  fee?: InputMaybe<Jsonb_Comparison_Exp>;\n  gas_used?: InputMaybe<Bigint_Comparison_Exp>;\n  gas_wanted?: InputMaybe<Bigint_Comparison_Exp>;\n  hash?: InputMaybe<String_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  index?: InputMaybe<Bigint_Comparison_Exp>;\n  involved_accounts_addresses?: InputMaybe<_Text_Comparison_Exp>;\n  logs?: InputMaybe<Jsonb_Comparison_Exp>;\n  memo?: InputMaybe<String_Comparison_Exp>;\n  messages?: InputMaybe<Jsonb_Comparison_Exp>;\n  raw_log?: InputMaybe<String_Comparison_Exp>;\n  signatures?: InputMaybe<_Text_Comparison_Exp>;\n  signer_infos?: InputMaybe<Jsonb_Comparison_Exp>;\n  subject1?: InputMaybe<String_Comparison_Exp>;\n  subject2?: InputMaybe<String_Comparison_Exp>;\n  success?: InputMaybe<Boolean_Comparison_Exp>;\n  transaction_hash?: InputMaybe<String_Comparison_Exp>;\n  type?: InputMaybe<String_Comparison_Exp>;\n  value?: InputMaybe<Jsonb_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type _Transaction_Max_Fields = {\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  hash?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  index?: Maybe<Scalars['bigint']['output']>;\n  memo?: Maybe<Scalars['String']['output']>;\n  raw_log?: Maybe<Scalars['String']['output']>;\n  subject1?: Maybe<Scalars['String']['output']>;\n  subject2?: Maybe<Scalars['String']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type _Transaction_Min_Fields = {\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  hash?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  index?: Maybe<Scalars['bigint']['output']>;\n  memo?: Maybe<Scalars['String']['output']>;\n  raw_log?: Maybe<Scalars['String']['output']>;\n  subject1?: Maybe<Scalars['String']['output']>;\n  subject2?: Maybe<Scalars['String']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"_transaction\". */\nexport type _Transaction_Order_By = {\n  fee?: InputMaybe<Order_By>;\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  hash?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  index?: InputMaybe<Order_By>;\n  involved_accounts_addresses?: InputMaybe<Order_By>;\n  logs?: InputMaybe<Order_By>;\n  memo?: InputMaybe<Order_By>;\n  messages?: InputMaybe<Order_By>;\n  raw_log?: InputMaybe<Order_By>;\n  signatures?: InputMaybe<Order_By>;\n  signer_infos?: InputMaybe<Order_By>;\n  subject1?: InputMaybe<Order_By>;\n  subject2?: InputMaybe<Order_By>;\n  success?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n  value?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"_transaction\" */\nexport enum _Transaction_Select_Column {\n  /** column name */\n  Fee = 'fee',\n  /** column name */\n  GasUsed = 'gas_used',\n  /** column name */\n  GasWanted = 'gas_wanted',\n  /** column name */\n  Hash = 'hash',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Index = 'index',\n  /** column name */\n  InvolvedAccountsAddresses = 'involved_accounts_addresses',\n  /** column name */\n  Logs = 'logs',\n  /** column name */\n  Memo = 'memo',\n  /** column name */\n  Messages = 'messages',\n  /** column name */\n  RawLog = 'raw_log',\n  /** column name */\n  Signatures = 'signatures',\n  /** column name */\n  SignerInfos = 'signer_infos',\n  /** column name */\n  Subject1 = 'subject1',\n  /** column name */\n  Subject2 = 'subject2',\n  /** column name */\n  Success = 'success',\n  /** column name */\n  TransactionHash = 'transaction_hash',\n  /** column name */\n  Type = 'type',\n  /** column name */\n  Value = 'value'\n}\n\n/** aggregate stddev on columns */\nexport type _Transaction_Stddev_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type _Transaction_Stddev_Pop_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type _Transaction_Stddev_Samp_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type _Transaction_Sum_Fields = {\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  index?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type _Transaction_Var_Pop_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type _Transaction_Var_Samp_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type _Transaction_Variance_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"_uptime_temp\" */\nexport type _Uptime_Temp = {\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n  validator_address?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregated selection of \"_uptime_temp\" */\nexport type _Uptime_Temp_Aggregate = {\n  aggregate?: Maybe<_Uptime_Temp_Aggregate_Fields>;\n  nodes: Array<_Uptime_Temp>;\n};\n\n/** aggregate fields of \"_uptime_temp\" */\nexport type _Uptime_Temp_Aggregate_Fields = {\n  avg?: Maybe<_Uptime_Temp_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<_Uptime_Temp_Max_Fields>;\n  min?: Maybe<_Uptime_Temp_Min_Fields>;\n  stddev?: Maybe<_Uptime_Temp_Stddev_Fields>;\n  stddev_pop?: Maybe<_Uptime_Temp_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<_Uptime_Temp_Stddev_Samp_Fields>;\n  sum?: Maybe<_Uptime_Temp_Sum_Fields>;\n  var_pop?: Maybe<_Uptime_Temp_Var_Pop_Fields>;\n  var_samp?: Maybe<_Uptime_Temp_Var_Samp_Fields>;\n  variance?: Maybe<_Uptime_Temp_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"_uptime_temp\" */\nexport type _Uptime_Temp_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<_Uptime_Temp_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type _Uptime_Temp_Avg_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"_uptime_temp\". All fields are combined with a logical 'AND'. */\nexport type _Uptime_Temp_Bool_Exp = {\n  _and?: InputMaybe<Array<_Uptime_Temp_Bool_Exp>>;\n  _not?: InputMaybe<_Uptime_Temp_Bool_Exp>;\n  _or?: InputMaybe<Array<_Uptime_Temp_Bool_Exp>>;\n  pre_commits?: InputMaybe<Bigint_Comparison_Exp>;\n  validator_address?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type _Uptime_Temp_Max_Fields = {\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n  validator_address?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type _Uptime_Temp_Min_Fields = {\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n  validator_address?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"_uptime_temp\". */\nexport type _Uptime_Temp_Order_By = {\n  pre_commits?: InputMaybe<Order_By>;\n  validator_address?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"_uptime_temp\" */\nexport enum _Uptime_Temp_Select_Column {\n  /** column name */\n  PreCommits = 'pre_commits',\n  /** column name */\n  ValidatorAddress = 'validator_address'\n}\n\n/** aggregate stddev on columns */\nexport type _Uptime_Temp_Stddev_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type _Uptime_Temp_Stddev_Pop_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type _Uptime_Temp_Stddev_Samp_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type _Uptime_Temp_Sum_Fields = {\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type _Uptime_Temp_Var_Pop_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type _Uptime_Temp_Var_Samp_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type _Uptime_Temp_Variance_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"account\" */\nexport type Account = {\n  /** An object relationship */\n  account_balance?: Maybe<Account_Balance>;\n  address: Scalars['String']['output'];\n  /** fetch data from the table: \"cyberlinks\" */\n  cyberlinks: Array<Cyberlinks>;\n  /** An aggregate relationship */\n  cyberlinks_aggregate: Cyberlinks_Aggregate;\n  /** An array relationship */\n  investmints: Array<Investmints>;\n  /** An aggregate relationship */\n  investmints_aggregate: Investmints_Aggregate;\n  /** An array relationship */\n  particles: Array<Particles>;\n  /** An aggregate relationship */\n  particles_aggregate: Particles_Aggregate;\n  /** An array relationship */\n  routes: Array<Routes>;\n  /** An array relationship */\n  routesBySource: Array<Routes>;\n  /** An aggregate relationship */\n  routesBySource_aggregate: Routes_Aggregate;\n  /** An aggregate relationship */\n  routes_aggregate: Routes_Aggregate;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountCyberlinksArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountCyberlinks_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountInvestmintsArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountInvestmints_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountParticlesArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountParticles_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountRoutesArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountRoutesBySourceArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountRoutesBySource_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"account\" */\nexport type AccountRoutes_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n/** aggregated selection of \"account\" */\nexport type Account_Aggregate = {\n  aggregate?: Maybe<Account_Aggregate_Fields>;\n  nodes: Array<Account>;\n};\n\n/** aggregate fields of \"account\" */\nexport type Account_Aggregate_Fields = {\n  count: Scalars['Int']['output'];\n  max?: Maybe<Account_Max_Fields>;\n  min?: Maybe<Account_Min_Fields>;\n};\n\n\n/** aggregate fields of \"account\" */\nexport type Account_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Account_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** columns and relationships of \"account_balance\" */\nexport type Account_Balance = {\n  /** An object relationship */\n  account: Account;\n  address: Scalars['String']['output'];\n  coins: Scalars['_coin']['output'];\n  height: Scalars['bigint']['output'];\n};\n\n/** aggregated selection of \"account_balance\" */\nexport type Account_Balance_Aggregate = {\n  aggregate?: Maybe<Account_Balance_Aggregate_Fields>;\n  nodes: Array<Account_Balance>;\n};\n\n/** aggregate fields of \"account_balance\" */\nexport type Account_Balance_Aggregate_Fields = {\n  avg?: Maybe<Account_Balance_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Account_Balance_Max_Fields>;\n  min?: Maybe<Account_Balance_Min_Fields>;\n  stddev?: Maybe<Account_Balance_Stddev_Fields>;\n  stddev_pop?: Maybe<Account_Balance_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Account_Balance_Stddev_Samp_Fields>;\n  sum?: Maybe<Account_Balance_Sum_Fields>;\n  var_pop?: Maybe<Account_Balance_Var_Pop_Fields>;\n  var_samp?: Maybe<Account_Balance_Var_Samp_Fields>;\n  variance?: Maybe<Account_Balance_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"account_balance\" */\nexport type Account_Balance_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Account_Balance_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Account_Balance_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"account_balance\". All fields are combined with a logical 'AND'. */\nexport type Account_Balance_Bool_Exp = {\n  _and?: InputMaybe<Array<Account_Balance_Bool_Exp>>;\n  _not?: InputMaybe<Account_Balance_Bool_Exp>;\n  _or?: InputMaybe<Array<Account_Balance_Bool_Exp>>;\n  account?: InputMaybe<Account_Bool_Exp>;\n  address?: InputMaybe<String_Comparison_Exp>;\n  coins?: InputMaybe<_Coin_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Account_Balance_Max_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Account_Balance_Min_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** Ordering options when selecting data from \"account_balance\". */\nexport type Account_Balance_Order_By = {\n  account?: InputMaybe<Account_Order_By>;\n  address?: InputMaybe<Order_By>;\n  coins?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"account_balance\" */\nexport enum Account_Balance_Select_Column {\n  /** column name */\n  Address = 'address',\n  /** column name */\n  Coins = 'coins',\n  /** column name */\n  Height = 'height'\n}\n\n/** aggregate stddev on columns */\nexport type Account_Balance_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Account_Balance_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Account_Balance_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Account_Balance_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Account_Balance_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Account_Balance_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Account_Balance_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"account\". All fields are combined with a logical 'AND'. */\nexport type Account_Bool_Exp = {\n  _and?: InputMaybe<Array<Account_Bool_Exp>>;\n  _not?: InputMaybe<Account_Bool_Exp>;\n  _or?: InputMaybe<Array<Account_Bool_Exp>>;\n  account_balance?: InputMaybe<Account_Balance_Bool_Exp>;\n  address?: InputMaybe<String_Comparison_Exp>;\n  cyberlinks?: InputMaybe<Cyberlinks_Bool_Exp>;\n  investmints?: InputMaybe<Investmints_Bool_Exp>;\n  particles?: InputMaybe<Particles_Bool_Exp>;\n  routes?: InputMaybe<Routes_Bool_Exp>;\n  routesBySource?: InputMaybe<Routes_Bool_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Account_Max_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Account_Min_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"account\". */\nexport type Account_Order_By = {\n  account_balance?: InputMaybe<Account_Balance_Order_By>;\n  address?: InputMaybe<Order_By>;\n  cyberlinks_aggregate?: InputMaybe<Cyberlinks_Aggregate_Order_By>;\n  investmints_aggregate?: InputMaybe<Investmints_Aggregate_Order_By>;\n  particles_aggregate?: InputMaybe<Particles_Aggregate_Order_By>;\n  routesBySource_aggregate?: InputMaybe<Routes_Aggregate_Order_By>;\n  routes_aggregate?: InputMaybe<Routes_Aggregate_Order_By>;\n};\n\n/** select columns of table \"account\" */\nexport enum Account_Select_Column {\n  /** column name */\n  Address = 'address'\n}\n\n/** Boolean expression to compare columns of type \"bigint\". All fields are combined with logical 'AND'. */\nexport type Bigint_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['bigint']['input']>;\n  _gt?: InputMaybe<Scalars['bigint']['input']>;\n  _gte?: InputMaybe<Scalars['bigint']['input']>;\n  _in?: InputMaybe<Array<Scalars['bigint']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['bigint']['input']>;\n  _lte?: InputMaybe<Scalars['bigint']['input']>;\n  _neq?: InputMaybe<Scalars['bigint']['input']>;\n  _nin?: InputMaybe<Array<Scalars['bigint']['input']>>;\n};\n\n/** columns and relationships of \"block\" */\nexport type Block = {\n  /** fetch data from the table: \"cyberlinks\" */\n  cyberlinks: Array<Cyberlinks>;\n  /** An aggregate relationship */\n  cyberlinks_aggregate: Cyberlinks_Aggregate;\n  hash: Scalars['String']['output'];\n  height: Scalars['bigint']['output'];\n  /** An array relationship */\n  investmints: Array<Investmints>;\n  /** An aggregate relationship */\n  investmints_aggregate: Investmints_Aggregate;\n  num_txs?: Maybe<Scalars['Int']['output']>;\n  /** An array relationship */\n  particles: Array<Particles>;\n  /** An aggregate relationship */\n  particles_aggregate: Particles_Aggregate;\n  proposer_address?: Maybe<Scalars['String']['output']>;\n  /** An array relationship */\n  routes: Array<Routes>;\n  /** An aggregate relationship */\n  routes_aggregate: Routes_Aggregate;\n  timestamp: Scalars['timestamp']['output'];\n  total_gas?: Maybe<Scalars['bigint']['output']>;\n  /** An array relationship */\n  transactions: Array<Transaction>;\n  /** An aggregate relationship */\n  transactions_aggregate: Transaction_Aggregate;\n  /** An object relationship */\n  validator?: Maybe<Validator>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockCyberlinksArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockCyberlinks_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockInvestmintsArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockInvestmints_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockParticlesArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockParticles_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockRoutesArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockRoutes_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockTransactionsArgs = {\n  distinct_on?: InputMaybe<Array<Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Transaction_Order_By>>;\n  where?: InputMaybe<Transaction_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"block\" */\nexport type BlockTransactions_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Transaction_Order_By>>;\n  where?: InputMaybe<Transaction_Bool_Exp>;\n};\n\n/** aggregated selection of \"block\" */\nexport type Block_Aggregate = {\n  aggregate?: Maybe<Block_Aggregate_Fields>;\n  nodes: Array<Block>;\n};\n\n/** aggregate fields of \"block\" */\nexport type Block_Aggregate_Fields = {\n  avg?: Maybe<Block_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Block_Max_Fields>;\n  min?: Maybe<Block_Min_Fields>;\n  stddev?: Maybe<Block_Stddev_Fields>;\n  stddev_pop?: Maybe<Block_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Block_Stddev_Samp_Fields>;\n  sum?: Maybe<Block_Sum_Fields>;\n  var_pop?: Maybe<Block_Var_Pop_Fields>;\n  var_samp?: Maybe<Block_Var_Samp_Fields>;\n  variance?: Maybe<Block_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"block\" */\nexport type Block_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Block_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"block\" */\nexport type Block_Aggregate_Order_By = {\n  avg?: InputMaybe<Block_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Block_Max_Order_By>;\n  min?: InputMaybe<Block_Min_Order_By>;\n  stddev?: InputMaybe<Block_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Block_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Block_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Block_Sum_Order_By>;\n  var_pop?: InputMaybe<Block_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Block_Var_Samp_Order_By>;\n  variance?: InputMaybe<Block_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Block_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  num_txs?: Maybe<Scalars['Float']['output']>;\n  total_gas?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"block\" */\nexport type Block_Avg_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"block\". All fields are combined with a logical 'AND'. */\nexport type Block_Bool_Exp = {\n  _and?: InputMaybe<Array<Block_Bool_Exp>>;\n  _not?: InputMaybe<Block_Bool_Exp>;\n  _or?: InputMaybe<Array<Block_Bool_Exp>>;\n  cyberlinks?: InputMaybe<Cyberlinks_Bool_Exp>;\n  hash?: InputMaybe<String_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  investmints?: InputMaybe<Investmints_Bool_Exp>;\n  num_txs?: InputMaybe<Int_Comparison_Exp>;\n  particles?: InputMaybe<Particles_Bool_Exp>;\n  proposer_address?: InputMaybe<String_Comparison_Exp>;\n  routes?: InputMaybe<Routes_Bool_Exp>;\n  timestamp?: InputMaybe<Timestamp_Comparison_Exp>;\n  total_gas?: InputMaybe<Bigint_Comparison_Exp>;\n  transactions?: InputMaybe<Transaction_Bool_Exp>;\n  validator?: InputMaybe<Validator_Bool_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Block_Max_Fields = {\n  hash?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  num_txs?: Maybe<Scalars['Int']['output']>;\n  proposer_address?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  total_gas?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by max() on columns of table \"block\" */\nexport type Block_Max_Order_By = {\n  hash?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  proposer_address?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Block_Min_Fields = {\n  hash?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  num_txs?: Maybe<Scalars['Int']['output']>;\n  proposer_address?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  total_gas?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by min() on columns of table \"block\" */\nexport type Block_Min_Order_By = {\n  hash?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  proposer_address?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"block\". */\nexport type Block_Order_By = {\n  cyberlinks_aggregate?: InputMaybe<Cyberlinks_Aggregate_Order_By>;\n  hash?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  investmints_aggregate?: InputMaybe<Investmints_Aggregate_Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  particles_aggregate?: InputMaybe<Particles_Aggregate_Order_By>;\n  proposer_address?: InputMaybe<Order_By>;\n  routes_aggregate?: InputMaybe<Routes_Aggregate_Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n  transactions_aggregate?: InputMaybe<Transaction_Aggregate_Order_By>;\n  validator?: InputMaybe<Validator_Order_By>;\n};\n\n/** select columns of table \"block\" */\nexport enum Block_Select_Column {\n  /** column name */\n  Hash = 'hash',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  NumTxs = 'num_txs',\n  /** column name */\n  ProposerAddress = 'proposer_address',\n  /** column name */\n  Timestamp = 'timestamp',\n  /** column name */\n  TotalGas = 'total_gas'\n}\n\n/** aggregate stddev on columns */\nexport type Block_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  num_txs?: Maybe<Scalars['Float']['output']>;\n  total_gas?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"block\" */\nexport type Block_Stddev_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Block_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  num_txs?: Maybe<Scalars['Float']['output']>;\n  total_gas?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"block\" */\nexport type Block_Stddev_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Block_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  num_txs?: Maybe<Scalars['Float']['output']>;\n  total_gas?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"block\" */\nexport type Block_Stddev_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Block_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  num_txs?: Maybe<Scalars['Int']['output']>;\n  total_gas?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by sum() on columns of table \"block\" */\nexport type Block_Sum_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Block_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  num_txs?: Maybe<Scalars['Float']['output']>;\n  total_gas?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"block\" */\nexport type Block_Var_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Block_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  num_txs?: Maybe<Scalars['Float']['output']>;\n  total_gas?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"block\" */\nexport type Block_Var_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Block_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  num_txs?: Maybe<Scalars['Float']['output']>;\n  total_gas?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"block\" */\nexport type Block_Variance_Order_By = {\n  height?: InputMaybe<Order_By>;\n  num_txs?: InputMaybe<Order_By>;\n  total_gas?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to compare columns of type \"coin\". All fields are combined with logical 'AND'. */\nexport type Coin_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['coin']['input']>;\n  _gt?: InputMaybe<Scalars['coin']['input']>;\n  _gte?: InputMaybe<Scalars['coin']['input']>;\n  _in?: InputMaybe<Array<Scalars['coin']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['coin']['input']>;\n  _lte?: InputMaybe<Scalars['coin']['input']>;\n  _neq?: InputMaybe<Scalars['coin']['input']>;\n  _nin?: InputMaybe<Array<Scalars['coin']['input']>>;\n};\n\n/** columns and relationships of \"contracts\" */\nexport type Contracts = {\n  address: Scalars['String']['output'];\n  admin: Scalars['String']['output'];\n  code_id: Scalars['bigint']['output'];\n  creation_time: Scalars['String']['output'];\n  creator: Scalars['String']['output'];\n  fees: Scalars['bigint']['output'];\n  gas: Scalars['bigint']['output'];\n  height: Scalars['bigint']['output'];\n  label: Scalars['String']['output'];\n  tx: Scalars['bigint']['output'];\n};\n\n/** aggregated selection of \"contracts\" */\nexport type Contracts_Aggregate = {\n  aggregate?: Maybe<Contracts_Aggregate_Fields>;\n  nodes: Array<Contracts>;\n};\n\n/** aggregate fields of \"contracts\" */\nexport type Contracts_Aggregate_Fields = {\n  avg?: Maybe<Contracts_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Contracts_Max_Fields>;\n  min?: Maybe<Contracts_Min_Fields>;\n  stddev?: Maybe<Contracts_Stddev_Fields>;\n  stddev_pop?: Maybe<Contracts_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Contracts_Stddev_Samp_Fields>;\n  sum?: Maybe<Contracts_Sum_Fields>;\n  var_pop?: Maybe<Contracts_Var_Pop_Fields>;\n  var_samp?: Maybe<Contracts_Var_Samp_Fields>;\n  variance?: Maybe<Contracts_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"contracts\" */\nexport type Contracts_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Contracts_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Contracts_Avg_Fields = {\n  code_id?: Maybe<Scalars['Float']['output']>;\n  fees?: Maybe<Scalars['Float']['output']>;\n  gas?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  tx?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"contracts\". All fields are combined with a logical 'AND'. */\nexport type Contracts_Bool_Exp = {\n  _and?: InputMaybe<Array<Contracts_Bool_Exp>>;\n  _not?: InputMaybe<Contracts_Bool_Exp>;\n  _or?: InputMaybe<Array<Contracts_Bool_Exp>>;\n  address?: InputMaybe<String_Comparison_Exp>;\n  admin?: InputMaybe<String_Comparison_Exp>;\n  code_id?: InputMaybe<Bigint_Comparison_Exp>;\n  creation_time?: InputMaybe<String_Comparison_Exp>;\n  creator?: InputMaybe<String_Comparison_Exp>;\n  fees?: InputMaybe<Bigint_Comparison_Exp>;\n  gas?: InputMaybe<Bigint_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  label?: InputMaybe<String_Comparison_Exp>;\n  tx?: InputMaybe<Bigint_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Contracts_Max_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  admin?: Maybe<Scalars['String']['output']>;\n  code_id?: Maybe<Scalars['bigint']['output']>;\n  creation_time?: Maybe<Scalars['String']['output']>;\n  creator?: Maybe<Scalars['String']['output']>;\n  fees?: Maybe<Scalars['bigint']['output']>;\n  gas?: Maybe<Scalars['bigint']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  label?: Maybe<Scalars['String']['output']>;\n  tx?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Contracts_Min_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  admin?: Maybe<Scalars['String']['output']>;\n  code_id?: Maybe<Scalars['bigint']['output']>;\n  creation_time?: Maybe<Scalars['String']['output']>;\n  creator?: Maybe<Scalars['String']['output']>;\n  fees?: Maybe<Scalars['bigint']['output']>;\n  gas?: Maybe<Scalars['bigint']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  label?: Maybe<Scalars['String']['output']>;\n  tx?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** Ordering options when selecting data from \"contracts\". */\nexport type Contracts_Order_By = {\n  address?: InputMaybe<Order_By>;\n  admin?: InputMaybe<Order_By>;\n  code_id?: InputMaybe<Order_By>;\n  creation_time?: InputMaybe<Order_By>;\n  creator?: InputMaybe<Order_By>;\n  fees?: InputMaybe<Order_By>;\n  gas?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  label?: InputMaybe<Order_By>;\n  tx?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"contracts\" */\nexport enum Contracts_Select_Column {\n  /** column name */\n  Address = 'address',\n  /** column name */\n  Admin = 'admin',\n  /** column name */\n  CodeId = 'code_id',\n  /** column name */\n  CreationTime = 'creation_time',\n  /** column name */\n  Creator = 'creator',\n  /** column name */\n  Fees = 'fees',\n  /** column name */\n  Gas = 'gas',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Label = 'label',\n  /** column name */\n  Tx = 'tx'\n}\n\n/** aggregate stddev on columns */\nexport type Contracts_Stddev_Fields = {\n  code_id?: Maybe<Scalars['Float']['output']>;\n  fees?: Maybe<Scalars['Float']['output']>;\n  gas?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  tx?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Contracts_Stddev_Pop_Fields = {\n  code_id?: Maybe<Scalars['Float']['output']>;\n  fees?: Maybe<Scalars['Float']['output']>;\n  gas?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  tx?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Contracts_Stddev_Samp_Fields = {\n  code_id?: Maybe<Scalars['Float']['output']>;\n  fees?: Maybe<Scalars['Float']['output']>;\n  gas?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  tx?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Contracts_Sum_Fields = {\n  code_id?: Maybe<Scalars['bigint']['output']>;\n  fees?: Maybe<Scalars['bigint']['output']>;\n  gas?: Maybe<Scalars['bigint']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  tx?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Contracts_Var_Pop_Fields = {\n  code_id?: Maybe<Scalars['Float']['output']>;\n  fees?: Maybe<Scalars['Float']['output']>;\n  gas?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  tx?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Contracts_Var_Samp_Fields = {\n  code_id?: Maybe<Scalars['Float']['output']>;\n  fees?: Maybe<Scalars['Float']['output']>;\n  gas?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  tx?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Contracts_Variance_Fields = {\n  code_id?: Maybe<Scalars['Float']['output']>;\n  fees?: Maybe<Scalars['Float']['output']>;\n  gas?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n  tx?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"cyb_cohort\" */\nexport type Cyb_Cohort = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neurons_activated?: Maybe<Scalars['bigint']['output']>;\n  redelegation_percent?: Maybe<Scalars['float8']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n  undelegation_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregated selection of \"cyb_cohort\" */\nexport type Cyb_Cohort_Aggregate = {\n  aggregate?: Maybe<Cyb_Cohort_Aggregate_Fields>;\n  nodes: Array<Cyb_Cohort>;\n};\n\n/** aggregate fields of \"cyb_cohort\" */\nexport type Cyb_Cohort_Aggregate_Fields = {\n  avg?: Maybe<Cyb_Cohort_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Cyb_Cohort_Max_Fields>;\n  min?: Maybe<Cyb_Cohort_Min_Fields>;\n  stddev?: Maybe<Cyb_Cohort_Stddev_Fields>;\n  stddev_pop?: Maybe<Cyb_Cohort_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Cyb_Cohort_Stddev_Samp_Fields>;\n  sum?: Maybe<Cyb_Cohort_Sum_Fields>;\n  var_pop?: Maybe<Cyb_Cohort_Var_Pop_Fields>;\n  var_samp?: Maybe<Cyb_Cohort_Var_Samp_Fields>;\n  variance?: Maybe<Cyb_Cohort_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"cyb_cohort\" */\nexport type Cyb_Cohort_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Cyb_Cohort_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Cyb_Cohort_Avg_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neurons_activated?: Maybe<Scalars['Float']['output']>;\n  redelegation_percent?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n  undelegation_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"cyb_cohort\". All fields are combined with a logical 'AND'. */\nexport type Cyb_Cohort_Bool_Exp = {\n  _and?: InputMaybe<Array<Cyb_Cohort_Bool_Exp>>;\n  _not?: InputMaybe<Cyb_Cohort_Bool_Exp>;\n  _or?: InputMaybe<Array<Cyb_Cohort_Bool_Exp>>;\n  cyberlink_10_percent?: InputMaybe<Float8_Comparison_Exp>;\n  cyberlink_100_percent?: InputMaybe<Float8_Comparison_Exp>;\n  cyberlink_percent?: InputMaybe<Float8_Comparison_Exp>;\n  hero_hired_percent?: InputMaybe<Float8_Comparison_Exp>;\n  investmint_percent?: InputMaybe<Float8_Comparison_Exp>;\n  neurons_activated?: InputMaybe<Bigint_Comparison_Exp>;\n  redelegation_percent?: InputMaybe<Float8_Comparison_Exp>;\n  swap_percent?: InputMaybe<Float8_Comparison_Exp>;\n  undelegation_percent?: InputMaybe<Float8_Comparison_Exp>;\n  week?: InputMaybe<Date_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Cyb_Cohort_Max_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neurons_activated?: Maybe<Scalars['bigint']['output']>;\n  redelegation_percent?: Maybe<Scalars['float8']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n  undelegation_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Cyb_Cohort_Min_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neurons_activated?: Maybe<Scalars['bigint']['output']>;\n  redelegation_percent?: Maybe<Scalars['float8']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n  undelegation_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** Ordering options when selecting data from \"cyb_cohort\". */\nexport type Cyb_Cohort_Order_By = {\n  cyberlink_10_percent?: InputMaybe<Order_By>;\n  cyberlink_100_percent?: InputMaybe<Order_By>;\n  cyberlink_percent?: InputMaybe<Order_By>;\n  hero_hired_percent?: InputMaybe<Order_By>;\n  investmint_percent?: InputMaybe<Order_By>;\n  neurons_activated?: InputMaybe<Order_By>;\n  redelegation_percent?: InputMaybe<Order_By>;\n  swap_percent?: InputMaybe<Order_By>;\n  undelegation_percent?: InputMaybe<Order_By>;\n  week?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"cyb_cohort\" */\nexport enum Cyb_Cohort_Select_Column {\n  /** column name */\n  Cyberlink_10Percent = 'cyberlink_10_percent',\n  /** column name */\n  Cyberlink_100Percent = 'cyberlink_100_percent',\n  /** column name */\n  CyberlinkPercent = 'cyberlink_percent',\n  /** column name */\n  HeroHiredPercent = 'hero_hired_percent',\n  /** column name */\n  InvestmintPercent = 'investmint_percent',\n  /** column name */\n  NeuronsActivated = 'neurons_activated',\n  /** column name */\n  RedelegationPercent = 'redelegation_percent',\n  /** column name */\n  SwapPercent = 'swap_percent',\n  /** column name */\n  UndelegationPercent = 'undelegation_percent',\n  /** column name */\n  Week = 'week'\n}\n\n/** aggregate stddev on columns */\nexport type Cyb_Cohort_Stddev_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neurons_activated?: Maybe<Scalars['Float']['output']>;\n  redelegation_percent?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n  undelegation_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Cyb_Cohort_Stddev_Pop_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neurons_activated?: Maybe<Scalars['Float']['output']>;\n  redelegation_percent?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n  undelegation_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Cyb_Cohort_Stddev_Samp_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neurons_activated?: Maybe<Scalars['Float']['output']>;\n  redelegation_percent?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n  undelegation_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Cyb_Cohort_Sum_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neurons_activated?: Maybe<Scalars['bigint']['output']>;\n  redelegation_percent?: Maybe<Scalars['float8']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n  undelegation_percent?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Cyb_Cohort_Var_Pop_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neurons_activated?: Maybe<Scalars['Float']['output']>;\n  redelegation_percent?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n  undelegation_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Cyb_Cohort_Var_Samp_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neurons_activated?: Maybe<Scalars['Float']['output']>;\n  redelegation_percent?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n  undelegation_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Cyb_Cohort_Variance_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neurons_activated?: Maybe<Scalars['Float']['output']>;\n  redelegation_percent?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n  undelegation_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"cyb_new_cohort\" */\nexport type Cyb_New_Cohort = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activation?: Maybe<Scalars['numeric']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregated selection of \"cyb_new_cohort\" */\nexport type Cyb_New_Cohort_Aggregate = {\n  aggregate?: Maybe<Cyb_New_Cohort_Aggregate_Fields>;\n  nodes: Array<Cyb_New_Cohort>;\n};\n\n/** aggregate fields of \"cyb_new_cohort\" */\nexport type Cyb_New_Cohort_Aggregate_Fields = {\n  avg?: Maybe<Cyb_New_Cohort_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Cyb_New_Cohort_Max_Fields>;\n  min?: Maybe<Cyb_New_Cohort_Min_Fields>;\n  stddev?: Maybe<Cyb_New_Cohort_Stddev_Fields>;\n  stddev_pop?: Maybe<Cyb_New_Cohort_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Cyb_New_Cohort_Stddev_Samp_Fields>;\n  sum?: Maybe<Cyb_New_Cohort_Sum_Fields>;\n  var_pop?: Maybe<Cyb_New_Cohort_Var_Pop_Fields>;\n  var_samp?: Maybe<Cyb_New_Cohort_Var_Samp_Fields>;\n  variance?: Maybe<Cyb_New_Cohort_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"cyb_new_cohort\" */\nexport type Cyb_New_Cohort_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Cyb_New_Cohort_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Cyb_New_Cohort_Avg_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activation?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"cyb_new_cohort\". All fields are combined with a logical 'AND'. */\nexport type Cyb_New_Cohort_Bool_Exp = {\n  _and?: InputMaybe<Array<Cyb_New_Cohort_Bool_Exp>>;\n  _not?: InputMaybe<Cyb_New_Cohort_Bool_Exp>;\n  _or?: InputMaybe<Array<Cyb_New_Cohort_Bool_Exp>>;\n  cyberlink_10_percent?: InputMaybe<Float8_Comparison_Exp>;\n  cyberlink_100_percent?: InputMaybe<Float8_Comparison_Exp>;\n  cyberlink_percent?: InputMaybe<Float8_Comparison_Exp>;\n  hero_hired_percent?: InputMaybe<Float8_Comparison_Exp>;\n  investmint_percent?: InputMaybe<Float8_Comparison_Exp>;\n  neuron_activation?: InputMaybe<Numeric_Comparison_Exp>;\n  swap_percent?: InputMaybe<Float8_Comparison_Exp>;\n  week?: InputMaybe<Date_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Cyb_New_Cohort_Max_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activation?: Maybe<Scalars['numeric']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Cyb_New_Cohort_Min_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activation?: Maybe<Scalars['numeric']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** Ordering options when selecting data from \"cyb_new_cohort\". */\nexport type Cyb_New_Cohort_Order_By = {\n  cyberlink_10_percent?: InputMaybe<Order_By>;\n  cyberlink_100_percent?: InputMaybe<Order_By>;\n  cyberlink_percent?: InputMaybe<Order_By>;\n  hero_hired_percent?: InputMaybe<Order_By>;\n  investmint_percent?: InputMaybe<Order_By>;\n  neuron_activation?: InputMaybe<Order_By>;\n  swap_percent?: InputMaybe<Order_By>;\n  week?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"cyb_new_cohort\" */\nexport enum Cyb_New_Cohort_Select_Column {\n  /** column name */\n  Cyberlink_10Percent = 'cyberlink_10_percent',\n  /** column name */\n  Cyberlink_100Percent = 'cyberlink_100_percent',\n  /** column name */\n  CyberlinkPercent = 'cyberlink_percent',\n  /** column name */\n  HeroHiredPercent = 'hero_hired_percent',\n  /** column name */\n  InvestmintPercent = 'investmint_percent',\n  /** column name */\n  NeuronActivation = 'neuron_activation',\n  /** column name */\n  SwapPercent = 'swap_percent',\n  /** column name */\n  Week = 'week'\n}\n\n/** aggregate stddev on columns */\nexport type Cyb_New_Cohort_Stddev_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activation?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Cyb_New_Cohort_Stddev_Pop_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activation?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Cyb_New_Cohort_Stddev_Samp_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activation?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Cyb_New_Cohort_Sum_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['float8']['output']>;\n  cyberlink_percent?: Maybe<Scalars['float8']['output']>;\n  hero_hired_percent?: Maybe<Scalars['float8']['output']>;\n  investmint_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activation?: Maybe<Scalars['numeric']['output']>;\n  swap_percent?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Cyb_New_Cohort_Var_Pop_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activation?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Cyb_New_Cohort_Var_Samp_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activation?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Cyb_New_Cohort_Variance_Fields = {\n  cyberlink_10_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_100_percent?: Maybe<Scalars['Float']['output']>;\n  cyberlink_percent?: Maybe<Scalars['Float']['output']>;\n  hero_hired_percent?: Maybe<Scalars['Float']['output']>;\n  investmint_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activation?: Maybe<Scalars['Float']['output']>;\n  swap_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"cyber_gift\" */\nexport type Cyber_Gift = {\n  address: Scalars['String']['output'];\n  audience: Scalars['String']['output'];\n  gift: Scalars['numeric']['output'];\n  grade: Scalars['Int']['output'];\n  segment: Scalars['String']['output'];\n};\n\n/** aggregated selection of \"cyber_gift\" */\nexport type Cyber_Gift_Aggregate = {\n  aggregate?: Maybe<Cyber_Gift_Aggregate_Fields>;\n  nodes: Array<Cyber_Gift>;\n};\n\n/** aggregate fields of \"cyber_gift\" */\nexport type Cyber_Gift_Aggregate_Fields = {\n  avg?: Maybe<Cyber_Gift_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Cyber_Gift_Max_Fields>;\n  min?: Maybe<Cyber_Gift_Min_Fields>;\n  stddev?: Maybe<Cyber_Gift_Stddev_Fields>;\n  stddev_pop?: Maybe<Cyber_Gift_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Cyber_Gift_Stddev_Samp_Fields>;\n  sum?: Maybe<Cyber_Gift_Sum_Fields>;\n  var_pop?: Maybe<Cyber_Gift_Var_Pop_Fields>;\n  var_samp?: Maybe<Cyber_Gift_Var_Samp_Fields>;\n  variance?: Maybe<Cyber_Gift_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"cyber_gift\" */\nexport type Cyber_Gift_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Cyber_Gift_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Cyber_Gift_Avg_Fields = {\n  gift?: Maybe<Scalars['Float']['output']>;\n  grade?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"cyber_gift\". All fields are combined with a logical 'AND'. */\nexport type Cyber_Gift_Bool_Exp = {\n  _and?: InputMaybe<Array<Cyber_Gift_Bool_Exp>>;\n  _not?: InputMaybe<Cyber_Gift_Bool_Exp>;\n  _or?: InputMaybe<Array<Cyber_Gift_Bool_Exp>>;\n  address?: InputMaybe<String_Comparison_Exp>;\n  audience?: InputMaybe<String_Comparison_Exp>;\n  gift?: InputMaybe<Numeric_Comparison_Exp>;\n  grade?: InputMaybe<Int_Comparison_Exp>;\n  segment?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Cyber_Gift_Max_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  audience?: Maybe<Scalars['String']['output']>;\n  gift?: Maybe<Scalars['numeric']['output']>;\n  grade?: Maybe<Scalars['Int']['output']>;\n  segment?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Cyber_Gift_Min_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  audience?: Maybe<Scalars['String']['output']>;\n  gift?: Maybe<Scalars['numeric']['output']>;\n  grade?: Maybe<Scalars['Int']['output']>;\n  segment?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"cyber_gift\". */\nexport type Cyber_Gift_Order_By = {\n  address?: InputMaybe<Order_By>;\n  audience?: InputMaybe<Order_By>;\n  gift?: InputMaybe<Order_By>;\n  grade?: InputMaybe<Order_By>;\n  segment?: InputMaybe<Order_By>;\n};\n\n/** columns and relationships of \"cyber_gift_proofs\" */\nexport type Cyber_Gift_Proofs = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  details?: Maybe<Scalars['json']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n\n/** columns and relationships of \"cyber_gift_proofs\" */\nexport type Cyber_Gift_ProofsDetailsArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n/** aggregated selection of \"cyber_gift_proofs\" */\nexport type Cyber_Gift_Proofs_Aggregate = {\n  aggregate?: Maybe<Cyber_Gift_Proofs_Aggregate_Fields>;\n  nodes: Array<Cyber_Gift_Proofs>;\n};\n\n/** aggregate fields of \"cyber_gift_proofs\" */\nexport type Cyber_Gift_Proofs_Aggregate_Fields = {\n  avg?: Maybe<Cyber_Gift_Proofs_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Cyber_Gift_Proofs_Max_Fields>;\n  min?: Maybe<Cyber_Gift_Proofs_Min_Fields>;\n  stddev?: Maybe<Cyber_Gift_Proofs_Stddev_Fields>;\n  stddev_pop?: Maybe<Cyber_Gift_Proofs_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Cyber_Gift_Proofs_Stddev_Samp_Fields>;\n  sum?: Maybe<Cyber_Gift_Proofs_Sum_Fields>;\n  var_pop?: Maybe<Cyber_Gift_Proofs_Var_Pop_Fields>;\n  var_samp?: Maybe<Cyber_Gift_Proofs_Var_Samp_Fields>;\n  variance?: Maybe<Cyber_Gift_Proofs_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"cyber_gift_proofs\" */\nexport type Cyber_Gift_Proofs_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Cyber_Gift_Proofs_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Cyber_Gift_Proofs_Avg_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"cyber_gift_proofs\". All fields are combined with a logical 'AND'. */\nexport type Cyber_Gift_Proofs_Bool_Exp = {\n  _and?: InputMaybe<Array<Cyber_Gift_Proofs_Bool_Exp>>;\n  _not?: InputMaybe<Cyber_Gift_Proofs_Bool_Exp>;\n  _or?: InputMaybe<Array<Cyber_Gift_Proofs_Bool_Exp>>;\n  address?: InputMaybe<String_Comparison_Exp>;\n  amount?: InputMaybe<Bigint_Comparison_Exp>;\n  details?: InputMaybe<Json_Comparison_Exp>;\n  proof?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Cyber_Gift_Proofs_Max_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Cyber_Gift_Proofs_Min_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"cyber_gift_proofs\". */\nexport type Cyber_Gift_Proofs_Order_By = {\n  address?: InputMaybe<Order_By>;\n  amount?: InputMaybe<Order_By>;\n  details?: InputMaybe<Order_By>;\n  proof?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"cyber_gift_proofs\" */\nexport enum Cyber_Gift_Proofs_Select_Column {\n  /** column name */\n  Address = 'address',\n  /** column name */\n  Amount = 'amount',\n  /** column name */\n  Details = 'details',\n  /** column name */\n  Proof = 'proof'\n}\n\n/** aggregate stddev on columns */\nexport type Cyber_Gift_Proofs_Stddev_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Cyber_Gift_Proofs_Stddev_Pop_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Cyber_Gift_Proofs_Stddev_Samp_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Cyber_Gift_Proofs_Sum_Fields = {\n  amount?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Cyber_Gift_Proofs_Var_Pop_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Cyber_Gift_Proofs_Var_Samp_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Cyber_Gift_Proofs_Variance_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** select columns of table \"cyber_gift\" */\nexport enum Cyber_Gift_Select_Column {\n  /** column name */\n  Address = 'address',\n  /** column name */\n  Audience = 'audience',\n  /** column name */\n  Gift = 'gift',\n  /** column name */\n  Grade = 'grade',\n  /** column name */\n  Segment = 'segment'\n}\n\n/** aggregate stddev on columns */\nexport type Cyber_Gift_Stddev_Fields = {\n  gift?: Maybe<Scalars['Float']['output']>;\n  grade?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Cyber_Gift_Stddev_Pop_Fields = {\n  gift?: Maybe<Scalars['Float']['output']>;\n  grade?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Cyber_Gift_Stddev_Samp_Fields = {\n  gift?: Maybe<Scalars['Float']['output']>;\n  grade?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Cyber_Gift_Sum_Fields = {\n  gift?: Maybe<Scalars['numeric']['output']>;\n  grade?: Maybe<Scalars['Int']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Cyber_Gift_Var_Pop_Fields = {\n  gift?: Maybe<Scalars['Float']['output']>;\n  grade?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Cyber_Gift_Var_Samp_Fields = {\n  gift?: Maybe<Scalars['Float']['output']>;\n  grade?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Cyber_Gift_Variance_Fields = {\n  gift?: Maybe<Scalars['Float']['output']>;\n  grade?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"cyberlinks\" */\nexport type Cyberlinks = {\n  /** An object relationship */\n  account: Account;\n  /** An object relationship */\n  block: Block;\n  /** An object relationship */\n  from?: Maybe<Particles>;\n  height: Scalars['bigint']['output'];\n  id: Scalars['Int']['output'];\n  neuron: Scalars['String']['output'];\n  particle_from: Scalars['String']['output'];\n  particle_to: Scalars['String']['output'];\n  timestamp: Scalars['timestamp']['output'];\n  /** An object relationship */\n  to?: Maybe<Particles>;\n  /** An object relationship */\n  transaction: Transaction;\n  transaction_hash: Scalars['String']['output'];\n};\n\n/** aggregated selection of \"cyberlinks\" */\nexport type Cyberlinks_Aggregate = {\n  aggregate?: Maybe<Cyberlinks_Aggregate_Fields>;\n  nodes: Array<Cyberlinks>;\n};\n\n/** aggregate fields of \"cyberlinks\" */\nexport type Cyberlinks_Aggregate_Fields = {\n  avg?: Maybe<Cyberlinks_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Cyberlinks_Max_Fields>;\n  min?: Maybe<Cyberlinks_Min_Fields>;\n  stddev?: Maybe<Cyberlinks_Stddev_Fields>;\n  stddev_pop?: Maybe<Cyberlinks_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Cyberlinks_Stddev_Samp_Fields>;\n  sum?: Maybe<Cyberlinks_Sum_Fields>;\n  var_pop?: Maybe<Cyberlinks_Var_Pop_Fields>;\n  var_samp?: Maybe<Cyberlinks_Var_Samp_Fields>;\n  variance?: Maybe<Cyberlinks_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"cyberlinks\" */\nexport type Cyberlinks_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"cyberlinks\" */\nexport type Cyberlinks_Aggregate_Order_By = {\n  avg?: InputMaybe<Cyberlinks_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Cyberlinks_Max_Order_By>;\n  min?: InputMaybe<Cyberlinks_Min_Order_By>;\n  stddev?: InputMaybe<Cyberlinks_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Cyberlinks_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Cyberlinks_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Cyberlinks_Sum_Order_By>;\n  var_pop?: InputMaybe<Cyberlinks_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Cyberlinks_Var_Samp_Order_By>;\n  variance?: InputMaybe<Cyberlinks_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Cyberlinks_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Avg_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"cyberlinks\". All fields are combined with a logical 'AND'. */\nexport type Cyberlinks_Bool_Exp = {\n  _and?: InputMaybe<Array<Cyberlinks_Bool_Exp>>;\n  _not?: InputMaybe<Cyberlinks_Bool_Exp>;\n  _or?: InputMaybe<Array<Cyberlinks_Bool_Exp>>;\n  account?: InputMaybe<Account_Bool_Exp>;\n  block?: InputMaybe<Block_Bool_Exp>;\n  from?: InputMaybe<Particles_Bool_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  id?: InputMaybe<Int_Comparison_Exp>;\n  neuron?: InputMaybe<String_Comparison_Exp>;\n  particle_from?: InputMaybe<String_Comparison_Exp>;\n  particle_to?: InputMaybe<String_Comparison_Exp>;\n  timestamp?: InputMaybe<Timestamp_Comparison_Exp>;\n  to?: InputMaybe<Particles_Bool_Exp>;\n  transaction?: InputMaybe<Transaction_Bool_Exp>;\n  transaction_hash?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Cyberlinks_Max_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  particle_from?: Maybe<Scalars['String']['output']>;\n  particle_to?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by max() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Max_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  particle_from?: InputMaybe<Order_By>;\n  particle_to?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Cyberlinks_Min_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  particle_from?: Maybe<Scalars['String']['output']>;\n  particle_to?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by min() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Min_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  particle_from?: InputMaybe<Order_By>;\n  particle_to?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"cyberlinks\". */\nexport type Cyberlinks_Order_By = {\n  account?: InputMaybe<Account_Order_By>;\n  block?: InputMaybe<Block_Order_By>;\n  from?: InputMaybe<Particles_Order_By>;\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  particle_from?: InputMaybe<Order_By>;\n  particle_to?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  to?: InputMaybe<Particles_Order_By>;\n  transaction?: InputMaybe<Transaction_Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"cyberlinks\" */\nexport enum Cyberlinks_Select_Column {\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Id = 'id',\n  /** column name */\n  Neuron = 'neuron',\n  /** column name */\n  ParticleFrom = 'particle_from',\n  /** column name */\n  ParticleTo = 'particle_to',\n  /** column name */\n  Timestamp = 'timestamp',\n  /** column name */\n  TransactionHash = 'transaction_hash'\n}\n\n/** columns and relationships of \"cyberlinks_stats\" */\nexport type Cyberlinks_Stats = {\n  cyberlinks?: Maybe<Scalars['numeric']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregated selection of \"cyberlinks_stats\" */\nexport type Cyberlinks_Stats_Aggregate = {\n  aggregate?: Maybe<Cyberlinks_Stats_Aggregate_Fields>;\n  nodes: Array<Cyberlinks_Stats>;\n};\n\n/** aggregate fields of \"cyberlinks_stats\" */\nexport type Cyberlinks_Stats_Aggregate_Fields = {\n  avg?: Maybe<Cyberlinks_Stats_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Cyberlinks_Stats_Max_Fields>;\n  min?: Maybe<Cyberlinks_Stats_Min_Fields>;\n  stddev?: Maybe<Cyberlinks_Stats_Stddev_Fields>;\n  stddev_pop?: Maybe<Cyberlinks_Stats_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Cyberlinks_Stats_Stddev_Samp_Fields>;\n  sum?: Maybe<Cyberlinks_Stats_Sum_Fields>;\n  var_pop?: Maybe<Cyberlinks_Stats_Var_Pop_Fields>;\n  var_samp?: Maybe<Cyberlinks_Stats_Var_Samp_Fields>;\n  variance?: Maybe<Cyberlinks_Stats_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"cyberlinks_stats\" */\nexport type Cyberlinks_Stats_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Cyberlinks_Stats_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Cyberlinks_Stats_Avg_Fields = {\n  cyberlinks?: Maybe<Scalars['Float']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"cyberlinks_stats\". All fields are combined with a logical 'AND'. */\nexport type Cyberlinks_Stats_Bool_Exp = {\n  _and?: InputMaybe<Array<Cyberlinks_Stats_Bool_Exp>>;\n  _not?: InputMaybe<Cyberlinks_Stats_Bool_Exp>;\n  _or?: InputMaybe<Array<Cyberlinks_Stats_Bool_Exp>>;\n  cyberlinks?: InputMaybe<Numeric_Comparison_Exp>;\n  cyberlinks_per_day?: InputMaybe<Bigint_Comparison_Exp>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Cyberlinks_Stats_Max_Fields = {\n  cyberlinks?: Maybe<Scalars['numeric']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Cyberlinks_Stats_Min_Fields = {\n  cyberlinks?: Maybe<Scalars['numeric']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n};\n\n/** Ordering options when selecting data from \"cyberlinks_stats\". */\nexport type Cyberlinks_Stats_Order_By = {\n  cyberlinks?: InputMaybe<Order_By>;\n  cyberlinks_per_day?: InputMaybe<Order_By>;\n  date?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"cyberlinks_stats\" */\nexport enum Cyberlinks_Stats_Select_Column {\n  /** column name */\n  Cyberlinks = 'cyberlinks',\n  /** column name */\n  CyberlinksPerDay = 'cyberlinks_per_day',\n  /** column name */\n  Date = 'date'\n}\n\n/** aggregate stddev on columns */\nexport type Cyberlinks_Stats_Stddev_Fields = {\n  cyberlinks?: Maybe<Scalars['Float']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Cyberlinks_Stats_Stddev_Pop_Fields = {\n  cyberlinks?: Maybe<Scalars['Float']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Cyberlinks_Stats_Stddev_Samp_Fields = {\n  cyberlinks?: Maybe<Scalars['Float']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Cyberlinks_Stats_Sum_Fields = {\n  cyberlinks?: Maybe<Scalars['numeric']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Cyberlinks_Stats_Var_Pop_Fields = {\n  cyberlinks?: Maybe<Scalars['Float']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Cyberlinks_Stats_Var_Samp_Fields = {\n  cyberlinks?: Maybe<Scalars['Float']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Cyberlinks_Stats_Variance_Fields = {\n  cyberlinks?: Maybe<Scalars['Float']['output']>;\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev on columns */\nexport type Cyberlinks_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Stddev_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Cyberlinks_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Stddev_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Cyberlinks_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Stddev_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Cyberlinks_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n};\n\n/** order by sum() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Sum_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Cyberlinks_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Var_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Cyberlinks_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Var_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Cyberlinks_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"cyberlinks\" */\nexport type Cyberlinks_Variance_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** columns and relationships of \"daily_amount_of_active_neurons\" */\nexport type Daily_Amount_Of_Active_Neurons = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregated selection of \"daily_amount_of_active_neurons\" */\nexport type Daily_Amount_Of_Active_Neurons_Aggregate = {\n  aggregate?: Maybe<Daily_Amount_Of_Active_Neurons_Aggregate_Fields>;\n  nodes: Array<Daily_Amount_Of_Active_Neurons>;\n};\n\n/** aggregate fields of \"daily_amount_of_active_neurons\" */\nexport type Daily_Amount_Of_Active_Neurons_Aggregate_Fields = {\n  avg?: Maybe<Daily_Amount_Of_Active_Neurons_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Daily_Amount_Of_Active_Neurons_Max_Fields>;\n  min?: Maybe<Daily_Amount_Of_Active_Neurons_Min_Fields>;\n  stddev?: Maybe<Daily_Amount_Of_Active_Neurons_Stddev_Fields>;\n  stddev_pop?: Maybe<Daily_Amount_Of_Active_Neurons_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Daily_Amount_Of_Active_Neurons_Stddev_Samp_Fields>;\n  sum?: Maybe<Daily_Amount_Of_Active_Neurons_Sum_Fields>;\n  var_pop?: Maybe<Daily_Amount_Of_Active_Neurons_Var_Pop_Fields>;\n  var_samp?: Maybe<Daily_Amount_Of_Active_Neurons_Var_Samp_Fields>;\n  variance?: Maybe<Daily_Amount_Of_Active_Neurons_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"daily_amount_of_active_neurons\" */\nexport type Daily_Amount_Of_Active_Neurons_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Daily_Amount_Of_Active_Neurons_Avg_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"daily_amount_of_active_neurons\". All fields are combined with a logical 'AND'. */\nexport type Daily_Amount_Of_Active_Neurons_Bool_Exp = {\n  _and?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Bool_Exp>>;\n  _not?: InputMaybe<Daily_Amount_Of_Active_Neurons_Bool_Exp>;\n  _or?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Bool_Exp>>;\n  count?: InputMaybe<Bigint_Comparison_Exp>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Daily_Amount_Of_Active_Neurons_Max_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Daily_Amount_Of_Active_Neurons_Min_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n};\n\n/** Ordering options when selecting data from \"daily_amount_of_active_neurons\". */\nexport type Daily_Amount_Of_Active_Neurons_Order_By = {\n  count?: InputMaybe<Order_By>;\n  date?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"daily_amount_of_active_neurons\" */\nexport enum Daily_Amount_Of_Active_Neurons_Select_Column {\n  /** column name */\n  Count = 'count',\n  /** column name */\n  Date = 'date'\n}\n\n/** aggregate stddev on columns */\nexport type Daily_Amount_Of_Active_Neurons_Stddev_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Daily_Amount_Of_Active_Neurons_Stddev_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Daily_Amount_Of_Active_Neurons_Stddev_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Daily_Amount_Of_Active_Neurons_Sum_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Daily_Amount_Of_Active_Neurons_Var_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Daily_Amount_Of_Active_Neurons_Var_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Daily_Amount_Of_Active_Neurons_Variance_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"daily_amount_of_used_gas\" */\nexport type Daily_Amount_Of_Used_Gas = {\n  daily_gas?: Maybe<Scalars['numeric']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n  gas_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"daily_amount_of_used_gas\" */\nexport type Daily_Amount_Of_Used_Gas_Aggregate = {\n  aggregate?: Maybe<Daily_Amount_Of_Used_Gas_Aggregate_Fields>;\n  nodes: Array<Daily_Amount_Of_Used_Gas>;\n};\n\n/** aggregate fields of \"daily_amount_of_used_gas\" */\nexport type Daily_Amount_Of_Used_Gas_Aggregate_Fields = {\n  avg?: Maybe<Daily_Amount_Of_Used_Gas_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Daily_Amount_Of_Used_Gas_Max_Fields>;\n  min?: Maybe<Daily_Amount_Of_Used_Gas_Min_Fields>;\n  stddev?: Maybe<Daily_Amount_Of_Used_Gas_Stddev_Fields>;\n  stddev_pop?: Maybe<Daily_Amount_Of_Used_Gas_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Daily_Amount_Of_Used_Gas_Stddev_Samp_Fields>;\n  sum?: Maybe<Daily_Amount_Of_Used_Gas_Sum_Fields>;\n  var_pop?: Maybe<Daily_Amount_Of_Used_Gas_Var_Pop_Fields>;\n  var_samp?: Maybe<Daily_Amount_Of_Used_Gas_Var_Samp_Fields>;\n  variance?: Maybe<Daily_Amount_Of_Used_Gas_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"daily_amount_of_used_gas\" */\nexport type Daily_Amount_Of_Used_Gas_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Daily_Amount_Of_Used_Gas_Avg_Fields = {\n  daily_gas?: Maybe<Scalars['Float']['output']>;\n  gas_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"daily_amount_of_used_gas\". All fields are combined with a logical 'AND'. */\nexport type Daily_Amount_Of_Used_Gas_Bool_Exp = {\n  _and?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Bool_Exp>>;\n  _not?: InputMaybe<Daily_Amount_Of_Used_Gas_Bool_Exp>;\n  _or?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Bool_Exp>>;\n  daily_gas?: InputMaybe<Numeric_Comparison_Exp>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  gas_total?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Daily_Amount_Of_Used_Gas_Max_Fields = {\n  daily_gas?: Maybe<Scalars['numeric']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n  gas_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Daily_Amount_Of_Used_Gas_Min_Fields = {\n  daily_gas?: Maybe<Scalars['numeric']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n  gas_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"daily_amount_of_used_gas\". */\nexport type Daily_Amount_Of_Used_Gas_Order_By = {\n  daily_gas?: InputMaybe<Order_By>;\n  date?: InputMaybe<Order_By>;\n  gas_total?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"daily_amount_of_used_gas\" */\nexport enum Daily_Amount_Of_Used_Gas_Select_Column {\n  /** column name */\n  DailyGas = 'daily_gas',\n  /** column name */\n  Date = 'date',\n  /** column name */\n  GasTotal = 'gas_total'\n}\n\n/** aggregate stddev on columns */\nexport type Daily_Amount_Of_Used_Gas_Stddev_Fields = {\n  daily_gas?: Maybe<Scalars['Float']['output']>;\n  gas_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Daily_Amount_Of_Used_Gas_Stddev_Pop_Fields = {\n  daily_gas?: Maybe<Scalars['Float']['output']>;\n  gas_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Daily_Amount_Of_Used_Gas_Stddev_Samp_Fields = {\n  daily_gas?: Maybe<Scalars['Float']['output']>;\n  gas_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Daily_Amount_Of_Used_Gas_Sum_Fields = {\n  daily_gas?: Maybe<Scalars['numeric']['output']>;\n  gas_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Daily_Amount_Of_Used_Gas_Var_Pop_Fields = {\n  daily_gas?: Maybe<Scalars['Float']['output']>;\n  gas_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Daily_Amount_Of_Used_Gas_Var_Samp_Fields = {\n  daily_gas?: Maybe<Scalars['Float']['output']>;\n  gas_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Daily_Amount_Of_Used_Gas_Variance_Fields = {\n  daily_gas?: Maybe<Scalars['Float']['output']>;\n  gas_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"daily_number_of_transactions\" */\nexport type Daily_Number_Of_Transactions = {\n  date?: Maybe<Scalars['date']['output']>;\n  txs_per_day?: Maybe<Scalars['bigint']['output']>;\n  txs_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"daily_number_of_transactions\" */\nexport type Daily_Number_Of_Transactions_Aggregate = {\n  aggregate?: Maybe<Daily_Number_Of_Transactions_Aggregate_Fields>;\n  nodes: Array<Daily_Number_Of_Transactions>;\n};\n\n/** aggregate fields of \"daily_number_of_transactions\" */\nexport type Daily_Number_Of_Transactions_Aggregate_Fields = {\n  avg?: Maybe<Daily_Number_Of_Transactions_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Daily_Number_Of_Transactions_Max_Fields>;\n  min?: Maybe<Daily_Number_Of_Transactions_Min_Fields>;\n  stddev?: Maybe<Daily_Number_Of_Transactions_Stddev_Fields>;\n  stddev_pop?: Maybe<Daily_Number_Of_Transactions_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Daily_Number_Of_Transactions_Stddev_Samp_Fields>;\n  sum?: Maybe<Daily_Number_Of_Transactions_Sum_Fields>;\n  var_pop?: Maybe<Daily_Number_Of_Transactions_Var_Pop_Fields>;\n  var_samp?: Maybe<Daily_Number_Of_Transactions_Var_Samp_Fields>;\n  variance?: Maybe<Daily_Number_Of_Transactions_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"daily_number_of_transactions\" */\nexport type Daily_Number_Of_Transactions_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Daily_Number_Of_Transactions_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Daily_Number_Of_Transactions_Avg_Fields = {\n  txs_per_day?: Maybe<Scalars['Float']['output']>;\n  txs_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"daily_number_of_transactions\". All fields are combined with a logical 'AND'. */\nexport type Daily_Number_Of_Transactions_Bool_Exp = {\n  _and?: InputMaybe<Array<Daily_Number_Of_Transactions_Bool_Exp>>;\n  _not?: InputMaybe<Daily_Number_Of_Transactions_Bool_Exp>;\n  _or?: InputMaybe<Array<Daily_Number_Of_Transactions_Bool_Exp>>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  txs_per_day?: InputMaybe<Bigint_Comparison_Exp>;\n  txs_total?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Daily_Number_Of_Transactions_Max_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  txs_per_day?: Maybe<Scalars['bigint']['output']>;\n  txs_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Daily_Number_Of_Transactions_Min_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  txs_per_day?: Maybe<Scalars['bigint']['output']>;\n  txs_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"daily_number_of_transactions\". */\nexport type Daily_Number_Of_Transactions_Order_By = {\n  date?: InputMaybe<Order_By>;\n  txs_per_day?: InputMaybe<Order_By>;\n  txs_total?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"daily_number_of_transactions\" */\nexport enum Daily_Number_Of_Transactions_Select_Column {\n  /** column name */\n  Date = 'date',\n  /** column name */\n  TxsPerDay = 'txs_per_day',\n  /** column name */\n  TxsTotal = 'txs_total'\n}\n\n/** aggregate stddev on columns */\nexport type Daily_Number_Of_Transactions_Stddev_Fields = {\n  txs_per_day?: Maybe<Scalars['Float']['output']>;\n  txs_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Daily_Number_Of_Transactions_Stddev_Pop_Fields = {\n  txs_per_day?: Maybe<Scalars['Float']['output']>;\n  txs_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Daily_Number_Of_Transactions_Stddev_Samp_Fields = {\n  txs_per_day?: Maybe<Scalars['Float']['output']>;\n  txs_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Daily_Number_Of_Transactions_Sum_Fields = {\n  txs_per_day?: Maybe<Scalars['bigint']['output']>;\n  txs_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Daily_Number_Of_Transactions_Var_Pop_Fields = {\n  txs_per_day?: Maybe<Scalars['Float']['output']>;\n  txs_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Daily_Number_Of_Transactions_Var_Samp_Fields = {\n  txs_per_day?: Maybe<Scalars['Float']['output']>;\n  txs_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Daily_Number_Of_Transactions_Variance_Fields = {\n  txs_per_day?: Maybe<Scalars['Float']['output']>;\n  txs_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to compare columns of type \"date\". All fields are combined with logical 'AND'. */\nexport type Date_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['date']['input']>;\n  _gt?: InputMaybe<Scalars['date']['input']>;\n  _gte?: InputMaybe<Scalars['date']['input']>;\n  _in?: InputMaybe<Array<Scalars['date']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['date']['input']>;\n  _lte?: InputMaybe<Scalars['date']['input']>;\n  _neq?: InputMaybe<Scalars['date']['input']>;\n  _nin?: InputMaybe<Array<Scalars['date']['input']>>;\n};\n\n/** Boolean expression to compare columns of type \"float8\". All fields are combined with logical 'AND'. */\nexport type Float8_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['float8']['input']>;\n  _gt?: InputMaybe<Scalars['float8']['input']>;\n  _gte?: InputMaybe<Scalars['float8']['input']>;\n  _in?: InputMaybe<Array<Scalars['float8']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['float8']['input']>;\n  _lte?: InputMaybe<Scalars['float8']['input']>;\n  _neq?: InputMaybe<Scalars['float8']['input']>;\n  _nin?: InputMaybe<Array<Scalars['float8']['input']>>;\n};\n\n/** columns and relationships of \"follow_stats\" */\nexport type Follow_Stats = {\n  date?: Maybe<Scalars['date']['output']>;\n  follow_total?: Maybe<Scalars['numeric']['output']>;\n  follows_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregated selection of \"follow_stats\" */\nexport type Follow_Stats_Aggregate = {\n  aggregate?: Maybe<Follow_Stats_Aggregate_Fields>;\n  nodes: Array<Follow_Stats>;\n};\n\n/** aggregate fields of \"follow_stats\" */\nexport type Follow_Stats_Aggregate_Fields = {\n  avg?: Maybe<Follow_Stats_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Follow_Stats_Max_Fields>;\n  min?: Maybe<Follow_Stats_Min_Fields>;\n  stddev?: Maybe<Follow_Stats_Stddev_Fields>;\n  stddev_pop?: Maybe<Follow_Stats_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Follow_Stats_Stddev_Samp_Fields>;\n  sum?: Maybe<Follow_Stats_Sum_Fields>;\n  var_pop?: Maybe<Follow_Stats_Var_Pop_Fields>;\n  var_samp?: Maybe<Follow_Stats_Var_Samp_Fields>;\n  variance?: Maybe<Follow_Stats_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"follow_stats\" */\nexport type Follow_Stats_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Follow_Stats_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Follow_Stats_Avg_Fields = {\n  follow_total?: Maybe<Scalars['Float']['output']>;\n  follows_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"follow_stats\". All fields are combined with a logical 'AND'. */\nexport type Follow_Stats_Bool_Exp = {\n  _and?: InputMaybe<Array<Follow_Stats_Bool_Exp>>;\n  _not?: InputMaybe<Follow_Stats_Bool_Exp>;\n  _or?: InputMaybe<Array<Follow_Stats_Bool_Exp>>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  follow_total?: InputMaybe<Numeric_Comparison_Exp>;\n  follows_per_day?: InputMaybe<Bigint_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Follow_Stats_Max_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  follow_total?: Maybe<Scalars['numeric']['output']>;\n  follows_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Follow_Stats_Min_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  follow_total?: Maybe<Scalars['numeric']['output']>;\n  follows_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** Ordering options when selecting data from \"follow_stats\". */\nexport type Follow_Stats_Order_By = {\n  date?: InputMaybe<Order_By>;\n  follow_total?: InputMaybe<Order_By>;\n  follows_per_day?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"follow_stats\" */\nexport enum Follow_Stats_Select_Column {\n  /** column name */\n  Date = 'date',\n  /** column name */\n  FollowTotal = 'follow_total',\n  /** column name */\n  FollowsPerDay = 'follows_per_day'\n}\n\n/** aggregate stddev on columns */\nexport type Follow_Stats_Stddev_Fields = {\n  follow_total?: Maybe<Scalars['Float']['output']>;\n  follows_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Follow_Stats_Stddev_Pop_Fields = {\n  follow_total?: Maybe<Scalars['Float']['output']>;\n  follows_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Follow_Stats_Stddev_Samp_Fields = {\n  follow_total?: Maybe<Scalars['Float']['output']>;\n  follows_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Follow_Stats_Sum_Fields = {\n  follow_total?: Maybe<Scalars['numeric']['output']>;\n  follows_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Follow_Stats_Var_Pop_Fields = {\n  follow_total?: Maybe<Scalars['Float']['output']>;\n  follows_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Follow_Stats_Var_Samp_Fields = {\n  follow_total?: Maybe<Scalars['Float']['output']>;\n  follows_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Follow_Stats_Variance_Fields = {\n  follow_total?: Maybe<Scalars['Float']['output']>;\n  follows_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"genesis_neurons_activation\" */\nexport type Genesis_Neurons_Activation = {\n  count?: Maybe<Scalars['float8']['output']>;\n  neurons?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregated selection of \"genesis_neurons_activation\" */\nexport type Genesis_Neurons_Activation_Aggregate = {\n  aggregate?: Maybe<Genesis_Neurons_Activation_Aggregate_Fields>;\n  nodes: Array<Genesis_Neurons_Activation>;\n};\n\n/** aggregate fields of \"genesis_neurons_activation\" */\nexport type Genesis_Neurons_Activation_Aggregate_Fields = {\n  avg?: Maybe<Genesis_Neurons_Activation_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Genesis_Neurons_Activation_Max_Fields>;\n  min?: Maybe<Genesis_Neurons_Activation_Min_Fields>;\n  stddev?: Maybe<Genesis_Neurons_Activation_Stddev_Fields>;\n  stddev_pop?: Maybe<Genesis_Neurons_Activation_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Genesis_Neurons_Activation_Stddev_Samp_Fields>;\n  sum?: Maybe<Genesis_Neurons_Activation_Sum_Fields>;\n  var_pop?: Maybe<Genesis_Neurons_Activation_Var_Pop_Fields>;\n  var_samp?: Maybe<Genesis_Neurons_Activation_Var_Samp_Fields>;\n  variance?: Maybe<Genesis_Neurons_Activation_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"genesis_neurons_activation\" */\nexport type Genesis_Neurons_Activation_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Genesis_Neurons_Activation_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Genesis_Neurons_Activation_Avg_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"genesis_neurons_activation\". All fields are combined with a logical 'AND'. */\nexport type Genesis_Neurons_Activation_Bool_Exp = {\n  _and?: InputMaybe<Array<Genesis_Neurons_Activation_Bool_Exp>>;\n  _not?: InputMaybe<Genesis_Neurons_Activation_Bool_Exp>;\n  _or?: InputMaybe<Array<Genesis_Neurons_Activation_Bool_Exp>>;\n  count?: InputMaybe<Float8_Comparison_Exp>;\n  neurons?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Genesis_Neurons_Activation_Max_Fields = {\n  count?: Maybe<Scalars['float8']['output']>;\n  neurons?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Genesis_Neurons_Activation_Min_Fields = {\n  count?: Maybe<Scalars['float8']['output']>;\n  neurons?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"genesis_neurons_activation\". */\nexport type Genesis_Neurons_Activation_Order_By = {\n  count?: InputMaybe<Order_By>;\n  neurons?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"genesis_neurons_activation\" */\nexport enum Genesis_Neurons_Activation_Select_Column {\n  /** column name */\n  Count = 'count',\n  /** column name */\n  Neurons = 'neurons'\n}\n\n/** aggregate stddev on columns */\nexport type Genesis_Neurons_Activation_Stddev_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Genesis_Neurons_Activation_Stddev_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Genesis_Neurons_Activation_Stddev_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Genesis_Neurons_Activation_Sum_Fields = {\n  count?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Genesis_Neurons_Activation_Var_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Genesis_Neurons_Activation_Var_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Genesis_Neurons_Activation_Variance_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"investmints\" */\nexport type Investmints = {\n  /** An object relationship */\n  account: Account;\n  amount: Scalars['coin']['output'];\n  /** An object relationship */\n  block: Block;\n  height: Scalars['bigint']['output'];\n  id: Scalars['Int']['output'];\n  length: Scalars['bigint']['output'];\n  neuron: Scalars['String']['output'];\n  resource: Scalars['String']['output'];\n  timestamp: Scalars['timestamp']['output'];\n  /** An object relationship */\n  transaction: Transaction;\n  transaction_hash: Scalars['String']['output'];\n};\n\n/** aggregated selection of \"investmints\" */\nexport type Investmints_Aggregate = {\n  aggregate?: Maybe<Investmints_Aggregate_Fields>;\n  nodes: Array<Investmints>;\n};\n\n/** aggregate fields of \"investmints\" */\nexport type Investmints_Aggregate_Fields = {\n  avg?: Maybe<Investmints_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Investmints_Max_Fields>;\n  min?: Maybe<Investmints_Min_Fields>;\n  stddev?: Maybe<Investmints_Stddev_Fields>;\n  stddev_pop?: Maybe<Investmints_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Investmints_Stddev_Samp_Fields>;\n  sum?: Maybe<Investmints_Sum_Fields>;\n  var_pop?: Maybe<Investmints_Var_Pop_Fields>;\n  var_samp?: Maybe<Investmints_Var_Samp_Fields>;\n  variance?: Maybe<Investmints_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"investmints\" */\nexport type Investmints_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Investmints_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"investmints\" */\nexport type Investmints_Aggregate_Order_By = {\n  avg?: InputMaybe<Investmints_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Investmints_Max_Order_By>;\n  min?: InputMaybe<Investmints_Min_Order_By>;\n  stddev?: InputMaybe<Investmints_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Investmints_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Investmints_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Investmints_Sum_Order_By>;\n  var_pop?: InputMaybe<Investmints_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Investmints_Var_Samp_Order_By>;\n  variance?: InputMaybe<Investmints_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Investmints_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n  length?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"investmints\" */\nexport type Investmints_Avg_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"investmints\". All fields are combined with a logical 'AND'. */\nexport type Investmints_Bool_Exp = {\n  _and?: InputMaybe<Array<Investmints_Bool_Exp>>;\n  _not?: InputMaybe<Investmints_Bool_Exp>;\n  _or?: InputMaybe<Array<Investmints_Bool_Exp>>;\n  account?: InputMaybe<Account_Bool_Exp>;\n  amount?: InputMaybe<Coin_Comparison_Exp>;\n  block?: InputMaybe<Block_Bool_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  id?: InputMaybe<Int_Comparison_Exp>;\n  length?: InputMaybe<Bigint_Comparison_Exp>;\n  neuron?: InputMaybe<String_Comparison_Exp>;\n  resource?: InputMaybe<String_Comparison_Exp>;\n  timestamp?: InputMaybe<Timestamp_Comparison_Exp>;\n  transaction?: InputMaybe<Transaction_Bool_Exp>;\n  transaction_hash?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Investmints_Max_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  length?: Maybe<Scalars['bigint']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  resource?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by max() on columns of table \"investmints\" */\nexport type Investmints_Max_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  resource?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Investmints_Min_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  length?: Maybe<Scalars['bigint']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  resource?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by min() on columns of table \"investmints\" */\nexport type Investmints_Min_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  resource?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"investmints\". */\nexport type Investmints_Order_By = {\n  account?: InputMaybe<Account_Order_By>;\n  amount?: InputMaybe<Order_By>;\n  block?: InputMaybe<Block_Order_By>;\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  resource?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction?: InputMaybe<Transaction_Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"investmints\" */\nexport enum Investmints_Select_Column {\n  /** column name */\n  Amount = 'amount',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Id = 'id',\n  /** column name */\n  Length = 'length',\n  /** column name */\n  Neuron = 'neuron',\n  /** column name */\n  Resource = 'resource',\n  /** column name */\n  Timestamp = 'timestamp',\n  /** column name */\n  TransactionHash = 'transaction_hash'\n}\n\n/** aggregate stddev on columns */\nexport type Investmints_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n  length?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"investmints\" */\nexport type Investmints_Stddev_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Investmints_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n  length?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"investmints\" */\nexport type Investmints_Stddev_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Investmints_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n  length?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"investmints\" */\nexport type Investmints_Stddev_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Investmints_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  length?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by sum() on columns of table \"investmints\" */\nexport type Investmints_Sum_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Investmints_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n  length?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"investmints\" */\nexport type Investmints_Var_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Investmints_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n  length?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"investmints\" */\nexport type Investmints_Var_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Investmints_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n  length?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"investmints\" */\nexport type Investmints_Variance_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  length?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to compare columns of type \"json\". All fields are combined with logical 'AND'. */\nexport type Json_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['json']['input']>;\n  _gt?: InputMaybe<Scalars['json']['input']>;\n  _gte?: InputMaybe<Scalars['json']['input']>;\n  _in?: InputMaybe<Array<Scalars['json']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['json']['input']>;\n  _lte?: InputMaybe<Scalars['json']['input']>;\n  _neq?: InputMaybe<Scalars['json']['input']>;\n  _nin?: InputMaybe<Array<Scalars['json']['input']>>;\n};\n\n/** Boolean expression to compare columns of type \"jsonb\". All fields are combined with logical 'AND'. */\nexport type Jsonb_Comparison_Exp = {\n  /** is the column contained in the given json value */\n  _contained_in?: InputMaybe<Scalars['jsonb']['input']>;\n  /** does the column contain the given json value at the top level */\n  _contains?: InputMaybe<Scalars['jsonb']['input']>;\n  _eq?: InputMaybe<Scalars['jsonb']['input']>;\n  _gt?: InputMaybe<Scalars['jsonb']['input']>;\n  _gte?: InputMaybe<Scalars['jsonb']['input']>;\n  /** does the string exist as a top-level key in the column */\n  _has_key?: InputMaybe<Scalars['String']['input']>;\n  /** do all of these strings exist as top-level keys in the column */\n  _has_keys_all?: InputMaybe<Array<Scalars['String']['input']>>;\n  /** do any of these strings exist as top-level keys in the column */\n  _has_keys_any?: InputMaybe<Array<Scalars['String']['input']>>;\n  _in?: InputMaybe<Array<Scalars['jsonb']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['jsonb']['input']>;\n  _lte?: InputMaybe<Scalars['jsonb']['input']>;\n  _neq?: InputMaybe<Scalars['jsonb']['input']>;\n  _nin?: InputMaybe<Array<Scalars['jsonb']['input']>>;\n};\n\n/** columns and relationships of \"message\" */\nexport type Message = {\n  index: Scalars['bigint']['output'];\n  involved_accounts_addresses?: Maybe<Scalars['_text']['output']>;\n  /** An object relationship */\n  transaction: Transaction;\n  transaction_hash: Scalars['String']['output'];\n  type: Scalars['String']['output'];\n  value: Scalars['jsonb']['output'];\n};\n\n\n/** columns and relationships of \"message\" */\nexport type MessageValueArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n/** aggregated selection of \"message\" */\nexport type Message_Aggregate = {\n  aggregate?: Maybe<Message_Aggregate_Fields>;\n  nodes: Array<Message>;\n};\n\n/** aggregate fields of \"message\" */\nexport type Message_Aggregate_Fields = {\n  avg?: Maybe<Message_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Message_Max_Fields>;\n  min?: Maybe<Message_Min_Fields>;\n  stddev?: Maybe<Message_Stddev_Fields>;\n  stddev_pop?: Maybe<Message_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Message_Stddev_Samp_Fields>;\n  sum?: Maybe<Message_Sum_Fields>;\n  var_pop?: Maybe<Message_Var_Pop_Fields>;\n  var_samp?: Maybe<Message_Var_Samp_Fields>;\n  variance?: Maybe<Message_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"message\" */\nexport type Message_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Message_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"message\" */\nexport type Message_Aggregate_Order_By = {\n  avg?: InputMaybe<Message_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Message_Max_Order_By>;\n  min?: InputMaybe<Message_Min_Order_By>;\n  stddev?: InputMaybe<Message_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Message_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Message_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Message_Sum_Order_By>;\n  var_pop?: InputMaybe<Message_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Message_Var_Samp_Order_By>;\n  variance?: InputMaybe<Message_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Message_Avg_Fields = {\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"message\" */\nexport type Message_Avg_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"message\". All fields are combined with a logical 'AND'. */\nexport type Message_Bool_Exp = {\n  _and?: InputMaybe<Array<Message_Bool_Exp>>;\n  _not?: InputMaybe<Message_Bool_Exp>;\n  _or?: InputMaybe<Array<Message_Bool_Exp>>;\n  index?: InputMaybe<Bigint_Comparison_Exp>;\n  involved_accounts_addresses?: InputMaybe<_Text_Comparison_Exp>;\n  transaction?: InputMaybe<Transaction_Bool_Exp>;\n  transaction_hash?: InputMaybe<String_Comparison_Exp>;\n  type?: InputMaybe<String_Comparison_Exp>;\n  value?: InputMaybe<Jsonb_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Message_Max_Fields = {\n  index?: Maybe<Scalars['bigint']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by max() on columns of table \"message\" */\nexport type Message_Max_Order_By = {\n  index?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Message_Min_Fields = {\n  index?: Maybe<Scalars['bigint']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by min() on columns of table \"message\" */\nexport type Message_Min_Order_By = {\n  index?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"message\". */\nexport type Message_Order_By = {\n  index?: InputMaybe<Order_By>;\n  involved_accounts_addresses?: InputMaybe<Order_By>;\n  transaction?: InputMaybe<Transaction_Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n  value?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"message\" */\nexport enum Message_Select_Column {\n  /** column name */\n  Index = 'index',\n  /** column name */\n  InvolvedAccountsAddresses = 'involved_accounts_addresses',\n  /** column name */\n  TransactionHash = 'transaction_hash',\n  /** column name */\n  Type = 'type',\n  /** column name */\n  Value = 'value'\n}\n\n/** aggregate stddev on columns */\nexport type Message_Stddev_Fields = {\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"message\" */\nexport type Message_Stddev_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Message_Stddev_Pop_Fields = {\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"message\" */\nexport type Message_Stddev_Pop_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Message_Stddev_Samp_Fields = {\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"message\" */\nexport type Message_Stddev_Samp_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Message_Sum_Fields = {\n  index?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by sum() on columns of table \"message\" */\nexport type Message_Sum_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Message_Var_Pop_Fields = {\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"message\" */\nexport type Message_Var_Pop_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Message_Var_Samp_Fields = {\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"message\" */\nexport type Message_Var_Samp_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Message_Variance_Fields = {\n  index?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"message\" */\nexport type Message_Variance_Order_By = {\n  index?: InputMaybe<Order_By>;\n};\n\nexport type Messages_By_Address_Args = {\n  addresses?: InputMaybe<Scalars['_text']['input']>;\n  limit?: InputMaybe<Scalars['bigint']['input']>;\n  offset?: InputMaybe<Scalars['bigint']['input']>;\n  types?: InputMaybe<Scalars['_text']['input']>;\n};\n\n/** columns and relationships of \"modules\" */\nexport type Modules = {\n  module_name: Scalars['String']['output'];\n};\n\n/** aggregated selection of \"modules\" */\nexport type Modules_Aggregate = {\n  aggregate?: Maybe<Modules_Aggregate_Fields>;\n  nodes: Array<Modules>;\n};\n\n/** aggregate fields of \"modules\" */\nexport type Modules_Aggregate_Fields = {\n  count: Scalars['Int']['output'];\n  max?: Maybe<Modules_Max_Fields>;\n  min?: Maybe<Modules_Min_Fields>;\n};\n\n\n/** aggregate fields of \"modules\" */\nexport type Modules_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Modules_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** Boolean expression to filter rows from the table \"modules\". All fields are combined with a logical 'AND'. */\nexport type Modules_Bool_Exp = {\n  _and?: InputMaybe<Array<Modules_Bool_Exp>>;\n  _not?: InputMaybe<Modules_Bool_Exp>;\n  _or?: InputMaybe<Array<Modules_Bool_Exp>>;\n  module_name?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Modules_Max_Fields = {\n  module_name?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Modules_Min_Fields = {\n  module_name?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"modules\". */\nexport type Modules_Order_By = {\n  module_name?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"modules\" */\nexport enum Modules_Select_Column {\n  /** column name */\n  ModuleName = 'module_name'\n}\n\n/** columns and relationships of \"neuron_activation_source\" */\nexport type Neuron_Activation_Source = {\n  genesis_percent?: Maybe<Scalars['float8']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activated?: Maybe<Scalars['bigint']['output']>;\n  recieve_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregated selection of \"neuron_activation_source\" */\nexport type Neuron_Activation_Source_Aggregate = {\n  aggregate?: Maybe<Neuron_Activation_Source_Aggregate_Fields>;\n  nodes: Array<Neuron_Activation_Source>;\n};\n\n/** aggregate fields of \"neuron_activation_source\" */\nexport type Neuron_Activation_Source_Aggregate_Fields = {\n  avg?: Maybe<Neuron_Activation_Source_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Neuron_Activation_Source_Max_Fields>;\n  min?: Maybe<Neuron_Activation_Source_Min_Fields>;\n  stddev?: Maybe<Neuron_Activation_Source_Stddev_Fields>;\n  stddev_pop?: Maybe<Neuron_Activation_Source_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Neuron_Activation_Source_Stddev_Samp_Fields>;\n  sum?: Maybe<Neuron_Activation_Source_Sum_Fields>;\n  var_pop?: Maybe<Neuron_Activation_Source_Var_Pop_Fields>;\n  var_samp?: Maybe<Neuron_Activation_Source_Var_Samp_Fields>;\n  variance?: Maybe<Neuron_Activation_Source_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"neuron_activation_source\" */\nexport type Neuron_Activation_Source_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Neuron_Activation_Source_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Neuron_Activation_Source_Avg_Fields = {\n  genesis_percent?: Maybe<Scalars['Float']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activated?: Maybe<Scalars['Float']['output']>;\n  recieve_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"neuron_activation_source\". All fields are combined with a logical 'AND'. */\nexport type Neuron_Activation_Source_Bool_Exp = {\n  _and?: InputMaybe<Array<Neuron_Activation_Source_Bool_Exp>>;\n  _not?: InputMaybe<Neuron_Activation_Source_Bool_Exp>;\n  _or?: InputMaybe<Array<Neuron_Activation_Source_Bool_Exp>>;\n  genesis_percent?: InputMaybe<Float8_Comparison_Exp>;\n  ibc_receive_percent?: InputMaybe<Float8_Comparison_Exp>;\n  neuron_activated?: InputMaybe<Bigint_Comparison_Exp>;\n  recieve_percent?: InputMaybe<Float8_Comparison_Exp>;\n  week?: InputMaybe<Date_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Neuron_Activation_Source_Max_Fields = {\n  genesis_percent?: Maybe<Scalars['float8']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activated?: Maybe<Scalars['bigint']['output']>;\n  recieve_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Neuron_Activation_Source_Min_Fields = {\n  genesis_percent?: Maybe<Scalars['float8']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activated?: Maybe<Scalars['bigint']['output']>;\n  recieve_percent?: Maybe<Scalars['float8']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** Ordering options when selecting data from \"neuron_activation_source\". */\nexport type Neuron_Activation_Source_Order_By = {\n  genesis_percent?: InputMaybe<Order_By>;\n  ibc_receive_percent?: InputMaybe<Order_By>;\n  neuron_activated?: InputMaybe<Order_By>;\n  recieve_percent?: InputMaybe<Order_By>;\n  week?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"neuron_activation_source\" */\nexport enum Neuron_Activation_Source_Select_Column {\n  /** column name */\n  GenesisPercent = 'genesis_percent',\n  /** column name */\n  IbcReceivePercent = 'ibc_receive_percent',\n  /** column name */\n  NeuronActivated = 'neuron_activated',\n  /** column name */\n  RecievePercent = 'recieve_percent',\n  /** column name */\n  Week = 'week'\n}\n\n/** aggregate stddev on columns */\nexport type Neuron_Activation_Source_Stddev_Fields = {\n  genesis_percent?: Maybe<Scalars['Float']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activated?: Maybe<Scalars['Float']['output']>;\n  recieve_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Neuron_Activation_Source_Stddev_Pop_Fields = {\n  genesis_percent?: Maybe<Scalars['Float']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activated?: Maybe<Scalars['Float']['output']>;\n  recieve_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Neuron_Activation_Source_Stddev_Samp_Fields = {\n  genesis_percent?: Maybe<Scalars['Float']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activated?: Maybe<Scalars['Float']['output']>;\n  recieve_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Neuron_Activation_Source_Sum_Fields = {\n  genesis_percent?: Maybe<Scalars['float8']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['float8']['output']>;\n  neuron_activated?: Maybe<Scalars['bigint']['output']>;\n  recieve_percent?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Neuron_Activation_Source_Var_Pop_Fields = {\n  genesis_percent?: Maybe<Scalars['Float']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activated?: Maybe<Scalars['Float']['output']>;\n  recieve_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Neuron_Activation_Source_Var_Samp_Fields = {\n  genesis_percent?: Maybe<Scalars['Float']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activated?: Maybe<Scalars['Float']['output']>;\n  recieve_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Neuron_Activation_Source_Variance_Fields = {\n  genesis_percent?: Maybe<Scalars['Float']['output']>;\n  ibc_receive_percent?: Maybe<Scalars['Float']['output']>;\n  neuron_activated?: Maybe<Scalars['Float']['output']>;\n  recieve_percent?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"number_of_new_neurons\" */\nexport type Number_Of_New_Neurons = {\n  date?: Maybe<Scalars['date']['output']>;\n  new_neurons_daily?: Maybe<Scalars['bigint']['output']>;\n  new_neurons_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"number_of_new_neurons\" */\nexport type Number_Of_New_Neurons_Aggregate = {\n  aggregate?: Maybe<Number_Of_New_Neurons_Aggregate_Fields>;\n  nodes: Array<Number_Of_New_Neurons>;\n};\n\n/** aggregate fields of \"number_of_new_neurons\" */\nexport type Number_Of_New_Neurons_Aggregate_Fields = {\n  avg?: Maybe<Number_Of_New_Neurons_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Number_Of_New_Neurons_Max_Fields>;\n  min?: Maybe<Number_Of_New_Neurons_Min_Fields>;\n  stddev?: Maybe<Number_Of_New_Neurons_Stddev_Fields>;\n  stddev_pop?: Maybe<Number_Of_New_Neurons_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Number_Of_New_Neurons_Stddev_Samp_Fields>;\n  sum?: Maybe<Number_Of_New_Neurons_Sum_Fields>;\n  var_pop?: Maybe<Number_Of_New_Neurons_Var_Pop_Fields>;\n  var_samp?: Maybe<Number_Of_New_Neurons_Var_Samp_Fields>;\n  variance?: Maybe<Number_Of_New_Neurons_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"number_of_new_neurons\" */\nexport type Number_Of_New_Neurons_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Number_Of_New_Neurons_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Number_Of_New_Neurons_Avg_Fields = {\n  new_neurons_daily?: Maybe<Scalars['Float']['output']>;\n  new_neurons_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"number_of_new_neurons\". All fields are combined with a logical 'AND'. */\nexport type Number_Of_New_Neurons_Bool_Exp = {\n  _and?: InputMaybe<Array<Number_Of_New_Neurons_Bool_Exp>>;\n  _not?: InputMaybe<Number_Of_New_Neurons_Bool_Exp>;\n  _or?: InputMaybe<Array<Number_Of_New_Neurons_Bool_Exp>>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  new_neurons_daily?: InputMaybe<Bigint_Comparison_Exp>;\n  new_neurons_total?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Number_Of_New_Neurons_Max_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  new_neurons_daily?: Maybe<Scalars['bigint']['output']>;\n  new_neurons_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Number_Of_New_Neurons_Min_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  new_neurons_daily?: Maybe<Scalars['bigint']['output']>;\n  new_neurons_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"number_of_new_neurons\". */\nexport type Number_Of_New_Neurons_Order_By = {\n  date?: InputMaybe<Order_By>;\n  new_neurons_daily?: InputMaybe<Order_By>;\n  new_neurons_total?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"number_of_new_neurons\" */\nexport enum Number_Of_New_Neurons_Select_Column {\n  /** column name */\n  Date = 'date',\n  /** column name */\n  NewNeuronsDaily = 'new_neurons_daily',\n  /** column name */\n  NewNeuronsTotal = 'new_neurons_total'\n}\n\n/** aggregate stddev on columns */\nexport type Number_Of_New_Neurons_Stddev_Fields = {\n  new_neurons_daily?: Maybe<Scalars['Float']['output']>;\n  new_neurons_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Number_Of_New_Neurons_Stddev_Pop_Fields = {\n  new_neurons_daily?: Maybe<Scalars['Float']['output']>;\n  new_neurons_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Number_Of_New_Neurons_Stddev_Samp_Fields = {\n  new_neurons_daily?: Maybe<Scalars['Float']['output']>;\n  new_neurons_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Number_Of_New_Neurons_Sum_Fields = {\n  new_neurons_daily?: Maybe<Scalars['bigint']['output']>;\n  new_neurons_total?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Number_Of_New_Neurons_Var_Pop_Fields = {\n  new_neurons_daily?: Maybe<Scalars['Float']['output']>;\n  new_neurons_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Number_Of_New_Neurons_Var_Samp_Fields = {\n  new_neurons_daily?: Maybe<Scalars['Float']['output']>;\n  new_neurons_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Number_Of_New_Neurons_Variance_Fields = {\n  new_neurons_daily?: Maybe<Scalars['Float']['output']>;\n  new_neurons_total?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to compare columns of type \"numeric\". All fields are combined with logical 'AND'. */\nexport type Numeric_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['numeric']['input']>;\n  _gt?: InputMaybe<Scalars['numeric']['input']>;\n  _gte?: InputMaybe<Scalars['numeric']['input']>;\n  _in?: InputMaybe<Array<Scalars['numeric']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['numeric']['input']>;\n  _lte?: InputMaybe<Scalars['numeric']['input']>;\n  _neq?: InputMaybe<Scalars['numeric']['input']>;\n  _nin?: InputMaybe<Array<Scalars['numeric']['input']>>;\n};\n\n/** columns and relationships of \"old_precommits\" */\nexport type Old_Precommits = {\n  consensus_address: Scalars['String']['output'];\n  consensus_pubkey: Scalars['String']['output'];\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"old_precommits\" */\nexport type Old_Precommits_Aggregate = {\n  aggregate?: Maybe<Old_Precommits_Aggregate_Fields>;\n  nodes: Array<Old_Precommits>;\n};\n\n/** aggregate fields of \"old_precommits\" */\nexport type Old_Precommits_Aggregate_Fields = {\n  avg?: Maybe<Old_Precommits_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Old_Precommits_Max_Fields>;\n  min?: Maybe<Old_Precommits_Min_Fields>;\n  stddev?: Maybe<Old_Precommits_Stddev_Fields>;\n  stddev_pop?: Maybe<Old_Precommits_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Old_Precommits_Stddev_Samp_Fields>;\n  sum?: Maybe<Old_Precommits_Sum_Fields>;\n  var_pop?: Maybe<Old_Precommits_Var_Pop_Fields>;\n  var_samp?: Maybe<Old_Precommits_Var_Samp_Fields>;\n  variance?: Maybe<Old_Precommits_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"old_precommits\" */\nexport type Old_Precommits_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Old_Precommits_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Old_Precommits_Avg_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"old_precommits\". All fields are combined with a logical 'AND'. */\nexport type Old_Precommits_Bool_Exp = {\n  _and?: InputMaybe<Array<Old_Precommits_Bool_Exp>>;\n  _not?: InputMaybe<Old_Precommits_Bool_Exp>;\n  _or?: InputMaybe<Array<Old_Precommits_Bool_Exp>>;\n  consensus_address?: InputMaybe<String_Comparison_Exp>;\n  consensus_pubkey?: InputMaybe<String_Comparison_Exp>;\n  precommits?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Old_Precommits_Max_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Old_Precommits_Min_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"old_precommits\". */\nexport type Old_Precommits_Order_By = {\n  consensus_address?: InputMaybe<Order_By>;\n  consensus_pubkey?: InputMaybe<Order_By>;\n  precommits?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"old_precommits\" */\nexport enum Old_Precommits_Select_Column {\n  /** column name */\n  ConsensusAddress = 'consensus_address',\n  /** column name */\n  ConsensusPubkey = 'consensus_pubkey',\n  /** column name */\n  Precommits = 'precommits'\n}\n\n/** aggregate stddev on columns */\nexport type Old_Precommits_Stddev_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Old_Precommits_Stddev_Pop_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Old_Precommits_Stddev_Samp_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Old_Precommits_Sum_Fields = {\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Old_Precommits_Var_Pop_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Old_Precommits_Var_Samp_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Old_Precommits_Variance_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** column ordering options */\nexport enum Order_By {\n  /** in ascending order, nulls last */\n  Asc = 'asc',\n  /** in ascending order, nulls first */\n  AscNullsFirst = 'asc_nulls_first',\n  /** in ascending order, nulls last */\n  AscNullsLast = 'asc_nulls_last',\n  /** in descending order, nulls first */\n  Desc = 'desc',\n  /** in descending order, nulls first */\n  DescNullsFirst = 'desc_nulls_first',\n  /** in descending order, nulls last */\n  DescNullsLast = 'desc_nulls_last'\n}\n\n/** columns and relationships of \"particles\" */\nexport type Particles = {\n  /** An object relationship */\n  account: Account;\n  /** An object relationship */\n  block: Block;\n  height: Scalars['bigint']['output'];\n  id: Scalars['Int']['output'];\n  /** An array relationship */\n  in: Array<Cyberlinks>;\n  /** An aggregate relationship */\n  in_aggregate: Cyberlinks_Aggregate;\n  neuron: Scalars['String']['output'];\n  /** An array relationship */\n  out: Array<Cyberlinks>;\n  /** An aggregate relationship */\n  out_aggregate: Cyberlinks_Aggregate;\n  particle: Scalars['String']['output'];\n  timestamp: Scalars['timestamp']['output'];\n  /** An object relationship */\n  transaction: Transaction;\n  transaction_hash: Scalars['String']['output'];\n};\n\n\n/** columns and relationships of \"particles\" */\nexport type ParticlesInArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"particles\" */\nexport type ParticlesIn_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"particles\" */\nexport type ParticlesOutArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"particles\" */\nexport type ParticlesOut_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n/** aggregated selection of \"particles\" */\nexport type Particles_Aggregate = {\n  aggregate?: Maybe<Particles_Aggregate_Fields>;\n  nodes: Array<Particles>;\n};\n\n/** aggregate fields of \"particles\" */\nexport type Particles_Aggregate_Fields = {\n  avg?: Maybe<Particles_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Particles_Max_Fields>;\n  min?: Maybe<Particles_Min_Fields>;\n  stddev?: Maybe<Particles_Stddev_Fields>;\n  stddev_pop?: Maybe<Particles_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Particles_Stddev_Samp_Fields>;\n  sum?: Maybe<Particles_Sum_Fields>;\n  var_pop?: Maybe<Particles_Var_Pop_Fields>;\n  var_samp?: Maybe<Particles_Var_Samp_Fields>;\n  variance?: Maybe<Particles_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"particles\" */\nexport type Particles_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Particles_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"particles\" */\nexport type Particles_Aggregate_Order_By = {\n  avg?: InputMaybe<Particles_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Particles_Max_Order_By>;\n  min?: InputMaybe<Particles_Min_Order_By>;\n  stddev?: InputMaybe<Particles_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Particles_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Particles_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Particles_Sum_Order_By>;\n  var_pop?: InputMaybe<Particles_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Particles_Var_Samp_Order_By>;\n  variance?: InputMaybe<Particles_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Particles_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"particles\" */\nexport type Particles_Avg_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"particles\". All fields are combined with a logical 'AND'. */\nexport type Particles_Bool_Exp = {\n  _and?: InputMaybe<Array<Particles_Bool_Exp>>;\n  _not?: InputMaybe<Particles_Bool_Exp>;\n  _or?: InputMaybe<Array<Particles_Bool_Exp>>;\n  account?: InputMaybe<Account_Bool_Exp>;\n  block?: InputMaybe<Block_Bool_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  id?: InputMaybe<Int_Comparison_Exp>;\n  in?: InputMaybe<Cyberlinks_Bool_Exp>;\n  neuron?: InputMaybe<String_Comparison_Exp>;\n  out?: InputMaybe<Cyberlinks_Bool_Exp>;\n  particle?: InputMaybe<String_Comparison_Exp>;\n  timestamp?: InputMaybe<Timestamp_Comparison_Exp>;\n  transaction?: InputMaybe<Transaction_Bool_Exp>;\n  transaction_hash?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Particles_Max_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  particle?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by max() on columns of table \"particles\" */\nexport type Particles_Max_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  particle?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Particles_Min_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  particle?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by min() on columns of table \"particles\" */\nexport type Particles_Min_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  particle?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"particles\". */\nexport type Particles_Order_By = {\n  account?: InputMaybe<Account_Order_By>;\n  block?: InputMaybe<Block_Order_By>;\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  in_aggregate?: InputMaybe<Cyberlinks_Aggregate_Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  out_aggregate?: InputMaybe<Cyberlinks_Aggregate_Order_By>;\n  particle?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction?: InputMaybe<Transaction_Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"particles\" */\nexport enum Particles_Select_Column {\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Id = 'id',\n  /** column name */\n  Neuron = 'neuron',\n  /** column name */\n  Particle = 'particle',\n  /** column name */\n  Timestamp = 'timestamp',\n  /** column name */\n  TransactionHash = 'transaction_hash'\n}\n\n/** aggregate stddev on columns */\nexport type Particles_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"particles\" */\nexport type Particles_Stddev_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Particles_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"particles\" */\nexport type Particles_Stddev_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Particles_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"particles\" */\nexport type Particles_Stddev_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Particles_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n};\n\n/** order by sum() on columns of table \"particles\" */\nexport type Particles_Sum_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Particles_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"particles\" */\nexport type Particles_Var_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Particles_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"particles\" */\nexport type Particles_Var_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Particles_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"particles\" */\nexport type Particles_Variance_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** columns and relationships of \"pre_commit\" */\nexport type Pre_Commit = {\n  height: Scalars['bigint']['output'];\n  proposer_priority: Scalars['bigint']['output'];\n  timestamp: Scalars['timestamp']['output'];\n  /** An object relationship */\n  validator: Validator;\n  validator_address: Scalars['String']['output'];\n  voting_power: Scalars['bigint']['output'];\n};\n\n/** aggregated selection of \"pre_commit\" */\nexport type Pre_Commit_Aggregate = {\n  aggregate?: Maybe<Pre_Commit_Aggregate_Fields>;\n  nodes: Array<Pre_Commit>;\n};\n\n/** aggregate fields of \"pre_commit\" */\nexport type Pre_Commit_Aggregate_Fields = {\n  avg?: Maybe<Pre_Commit_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Pre_Commit_Max_Fields>;\n  min?: Maybe<Pre_Commit_Min_Fields>;\n  stddev?: Maybe<Pre_Commit_Stddev_Fields>;\n  stddev_pop?: Maybe<Pre_Commit_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Pre_Commit_Stddev_Samp_Fields>;\n  sum?: Maybe<Pre_Commit_Sum_Fields>;\n  var_pop?: Maybe<Pre_Commit_Var_Pop_Fields>;\n  var_samp?: Maybe<Pre_Commit_Var_Samp_Fields>;\n  variance?: Maybe<Pre_Commit_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"pre_commit\" */\nexport type Pre_Commit_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Pre_Commit_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"pre_commit\" */\nexport type Pre_Commit_Aggregate_Order_By = {\n  avg?: InputMaybe<Pre_Commit_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Pre_Commit_Max_Order_By>;\n  min?: InputMaybe<Pre_Commit_Min_Order_By>;\n  stddev?: InputMaybe<Pre_Commit_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Pre_Commit_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Pre_Commit_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Pre_Commit_Sum_Order_By>;\n  var_pop?: InputMaybe<Pre_Commit_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Pre_Commit_Var_Samp_Order_By>;\n  variance?: InputMaybe<Pre_Commit_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Pre_Commit_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  proposer_priority?: Maybe<Scalars['Float']['output']>;\n  voting_power?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Avg_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"pre_commit\". All fields are combined with a logical 'AND'. */\nexport type Pre_Commit_Bool_Exp = {\n  _and?: InputMaybe<Array<Pre_Commit_Bool_Exp>>;\n  _not?: InputMaybe<Pre_Commit_Bool_Exp>;\n  _or?: InputMaybe<Array<Pre_Commit_Bool_Exp>>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  proposer_priority?: InputMaybe<Bigint_Comparison_Exp>;\n  timestamp?: InputMaybe<Timestamp_Comparison_Exp>;\n  validator?: InputMaybe<Validator_Bool_Exp>;\n  validator_address?: InputMaybe<String_Comparison_Exp>;\n  voting_power?: InputMaybe<Bigint_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Pre_Commit_Max_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  proposer_priority?: Maybe<Scalars['bigint']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  validator_address?: Maybe<Scalars['String']['output']>;\n  voting_power?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by max() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Max_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  validator_address?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Pre_Commit_Min_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  proposer_priority?: Maybe<Scalars['bigint']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  validator_address?: Maybe<Scalars['String']['output']>;\n  voting_power?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by min() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Min_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  validator_address?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"pre_commit\". */\nexport type Pre_Commit_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  validator?: InputMaybe<Validator_Order_By>;\n  validator_address?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"pre_commit\" */\nexport enum Pre_Commit_Select_Column {\n  /** column name */\n  Height = 'height',\n  /** column name */\n  ProposerPriority = 'proposer_priority',\n  /** column name */\n  Timestamp = 'timestamp',\n  /** column name */\n  ValidatorAddress = 'validator_address',\n  /** column name */\n  VotingPower = 'voting_power'\n}\n\n/** aggregate stddev on columns */\nexport type Pre_Commit_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  proposer_priority?: Maybe<Scalars['Float']['output']>;\n  voting_power?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Stddev_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Pre_Commit_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  proposer_priority?: Maybe<Scalars['Float']['output']>;\n  voting_power?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Stddev_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Pre_Commit_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  proposer_priority?: Maybe<Scalars['Float']['output']>;\n  voting_power?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Stddev_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Pre_Commit_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  proposer_priority?: Maybe<Scalars['bigint']['output']>;\n  voting_power?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by sum() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Sum_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Pre_Commit_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  proposer_priority?: Maybe<Scalars['Float']['output']>;\n  voting_power?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Var_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Pre_Commit_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  proposer_priority?: Maybe<Scalars['Float']['output']>;\n  voting_power?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Var_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Pre_Commit_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  proposer_priority?: Maybe<Scalars['Float']['output']>;\n  voting_power?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"pre_commit\" */\nexport type Pre_Commit_Variance_Order_By = {\n  height?: InputMaybe<Order_By>;\n  proposer_priority?: InputMaybe<Order_By>;\n  voting_power?: InputMaybe<Order_By>;\n};\n\n/** columns and relationships of \"pre_commits_rewards_view\" */\nexport type Pre_Commits_Rewards_View = {\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  max_block?: Maybe<Scalars['bigint']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['numeric']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n  sum_precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"pre_commits_rewards_view\" */\nexport type Pre_Commits_Rewards_View_Aggregate = {\n  aggregate?: Maybe<Pre_Commits_Rewards_View_Aggregate_Fields>;\n  nodes: Array<Pre_Commits_Rewards_View>;\n};\n\n/** aggregate fields of \"pre_commits_rewards_view\" */\nexport type Pre_Commits_Rewards_View_Aggregate_Fields = {\n  avg?: Maybe<Pre_Commits_Rewards_View_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Pre_Commits_Rewards_View_Max_Fields>;\n  min?: Maybe<Pre_Commits_Rewards_View_Min_Fields>;\n  stddev?: Maybe<Pre_Commits_Rewards_View_Stddev_Fields>;\n  stddev_pop?: Maybe<Pre_Commits_Rewards_View_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Pre_Commits_Rewards_View_Stddev_Samp_Fields>;\n  sum?: Maybe<Pre_Commits_Rewards_View_Sum_Fields>;\n  var_pop?: Maybe<Pre_Commits_Rewards_View_Var_Pop_Fields>;\n  var_samp?: Maybe<Pre_Commits_Rewards_View_Var_Samp_Fields>;\n  variance?: Maybe<Pre_Commits_Rewards_View_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"pre_commits_rewards_view\" */\nexport type Pre_Commits_Rewards_View_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Pre_Commits_Rewards_View_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Pre_Commits_Rewards_View_Avg_Fields = {\n  max_block?: Maybe<Scalars['Float']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['Float']['output']>;\n  precommits?: Maybe<Scalars['Float']['output']>;\n  sum_precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"pre_commits_rewards_view\". All fields are combined with a logical 'AND'. */\nexport type Pre_Commits_Rewards_View_Bool_Exp = {\n  _and?: InputMaybe<Array<Pre_Commits_Rewards_View_Bool_Exp>>;\n  _not?: InputMaybe<Pre_Commits_Rewards_View_Bool_Exp>;\n  _or?: InputMaybe<Array<Pre_Commits_Rewards_View_Bool_Exp>>;\n  consensus_pubkey?: InputMaybe<String_Comparison_Exp>;\n  max_block?: InputMaybe<Bigint_Comparison_Exp>;\n  pre_commit_rewards?: InputMaybe<Numeric_Comparison_Exp>;\n  precommits?: InputMaybe<Numeric_Comparison_Exp>;\n  sum_precommits?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Pre_Commits_Rewards_View_Max_Fields = {\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  max_block?: Maybe<Scalars['bigint']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['numeric']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n  sum_precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Pre_Commits_Rewards_View_Min_Fields = {\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  max_block?: Maybe<Scalars['bigint']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['numeric']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n  sum_precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"pre_commits_rewards_view\". */\nexport type Pre_Commits_Rewards_View_Order_By = {\n  consensus_pubkey?: InputMaybe<Order_By>;\n  max_block?: InputMaybe<Order_By>;\n  pre_commit_rewards?: InputMaybe<Order_By>;\n  precommits?: InputMaybe<Order_By>;\n  sum_precommits?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"pre_commits_rewards_view\" */\nexport enum Pre_Commits_Rewards_View_Select_Column {\n  /** column name */\n  ConsensusPubkey = 'consensus_pubkey',\n  /** column name */\n  MaxBlock = 'max_block',\n  /** column name */\n  PreCommitRewards = 'pre_commit_rewards',\n  /** column name */\n  Precommits = 'precommits',\n  /** column name */\n  SumPrecommits = 'sum_precommits'\n}\n\n/** aggregate stddev on columns */\nexport type Pre_Commits_Rewards_View_Stddev_Fields = {\n  max_block?: Maybe<Scalars['Float']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['Float']['output']>;\n  precommits?: Maybe<Scalars['Float']['output']>;\n  sum_precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Pre_Commits_Rewards_View_Stddev_Pop_Fields = {\n  max_block?: Maybe<Scalars['Float']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['Float']['output']>;\n  precommits?: Maybe<Scalars['Float']['output']>;\n  sum_precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Pre_Commits_Rewards_View_Stddev_Samp_Fields = {\n  max_block?: Maybe<Scalars['Float']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['Float']['output']>;\n  precommits?: Maybe<Scalars['Float']['output']>;\n  sum_precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Pre_Commits_Rewards_View_Sum_Fields = {\n  max_block?: Maybe<Scalars['bigint']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['numeric']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n  sum_precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Pre_Commits_Rewards_View_Var_Pop_Fields = {\n  max_block?: Maybe<Scalars['Float']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['Float']['output']>;\n  precommits?: Maybe<Scalars['Float']['output']>;\n  sum_precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Pre_Commits_Rewards_View_Var_Samp_Fields = {\n  max_block?: Maybe<Scalars['Float']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['Float']['output']>;\n  precommits?: Maybe<Scalars['Float']['output']>;\n  sum_precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Pre_Commits_Rewards_View_Variance_Fields = {\n  max_block?: Maybe<Scalars['Float']['output']>;\n  pre_commit_rewards?: Maybe<Scalars['Float']['output']>;\n  precommits?: Maybe<Scalars['Float']['output']>;\n  sum_precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"pre_commits_total\" */\nexport type Pre_Commits_Total = {\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  pre_commits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"pre_commits_total\" */\nexport type Pre_Commits_Total_Aggregate = {\n  aggregate?: Maybe<Pre_Commits_Total_Aggregate_Fields>;\n  nodes: Array<Pre_Commits_Total>;\n};\n\n/** aggregate fields of \"pre_commits_total\" */\nexport type Pre_Commits_Total_Aggregate_Fields = {\n  avg?: Maybe<Pre_Commits_Total_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Pre_Commits_Total_Max_Fields>;\n  min?: Maybe<Pre_Commits_Total_Min_Fields>;\n  stddev?: Maybe<Pre_Commits_Total_Stddev_Fields>;\n  stddev_pop?: Maybe<Pre_Commits_Total_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Pre_Commits_Total_Stddev_Samp_Fields>;\n  sum?: Maybe<Pre_Commits_Total_Sum_Fields>;\n  var_pop?: Maybe<Pre_Commits_Total_Var_Pop_Fields>;\n  var_samp?: Maybe<Pre_Commits_Total_Var_Samp_Fields>;\n  variance?: Maybe<Pre_Commits_Total_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"pre_commits_total\" */\nexport type Pre_Commits_Total_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Pre_Commits_Total_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Pre_Commits_Total_Avg_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"pre_commits_total\". All fields are combined with a logical 'AND'. */\nexport type Pre_Commits_Total_Bool_Exp = {\n  _and?: InputMaybe<Array<Pre_Commits_Total_Bool_Exp>>;\n  _not?: InputMaybe<Pre_Commits_Total_Bool_Exp>;\n  _or?: InputMaybe<Array<Pre_Commits_Total_Bool_Exp>>;\n  consensus_pubkey?: InputMaybe<String_Comparison_Exp>;\n  pre_commits?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Pre_Commits_Total_Max_Fields = {\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  pre_commits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Pre_Commits_Total_Min_Fields = {\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  pre_commits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"pre_commits_total\". */\nexport type Pre_Commits_Total_Order_By = {\n  consensus_pubkey?: InputMaybe<Order_By>;\n  pre_commits?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"pre_commits_total\" */\nexport enum Pre_Commits_Total_Select_Column {\n  /** column name */\n  ConsensusPubkey = 'consensus_pubkey',\n  /** column name */\n  PreCommits = 'pre_commits'\n}\n\n/** aggregate stddev on columns */\nexport type Pre_Commits_Total_Stddev_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Pre_Commits_Total_Stddev_Pop_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Pre_Commits_Total_Stddev_Samp_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Pre_Commits_Total_Sum_Fields = {\n  pre_commits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Pre_Commits_Total_Var_Pop_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Pre_Commits_Total_Var_Samp_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Pre_Commits_Total_Variance_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"pre_commits_view\" */\nexport type Pre_Commits_View = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"pre_commits_view\" */\nexport type Pre_Commits_View_Aggregate = {\n  aggregate?: Maybe<Pre_Commits_View_Aggregate_Fields>;\n  nodes: Array<Pre_Commits_View>;\n};\n\n/** aggregate fields of \"pre_commits_view\" */\nexport type Pre_Commits_View_Aggregate_Fields = {\n  avg?: Maybe<Pre_Commits_View_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Pre_Commits_View_Max_Fields>;\n  min?: Maybe<Pre_Commits_View_Min_Fields>;\n  stddev?: Maybe<Pre_Commits_View_Stddev_Fields>;\n  stddev_pop?: Maybe<Pre_Commits_View_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Pre_Commits_View_Stddev_Samp_Fields>;\n  sum?: Maybe<Pre_Commits_View_Sum_Fields>;\n  var_pop?: Maybe<Pre_Commits_View_Var_Pop_Fields>;\n  var_samp?: Maybe<Pre_Commits_View_Var_Samp_Fields>;\n  variance?: Maybe<Pre_Commits_View_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"pre_commits_view\" */\nexport type Pre_Commits_View_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Pre_Commits_View_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Pre_Commits_View_Avg_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"pre_commits_view\". All fields are combined with a logical 'AND'. */\nexport type Pre_Commits_View_Bool_Exp = {\n  _and?: InputMaybe<Array<Pre_Commits_View_Bool_Exp>>;\n  _not?: InputMaybe<Pre_Commits_View_Bool_Exp>;\n  _or?: InputMaybe<Array<Pre_Commits_View_Bool_Exp>>;\n  consensus_address?: InputMaybe<String_Comparison_Exp>;\n  consensus_pubkey?: InputMaybe<String_Comparison_Exp>;\n  precommits?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Pre_Commits_View_Max_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Pre_Commits_View_Min_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"pre_commits_view\". */\nexport type Pre_Commits_View_Order_By = {\n  consensus_address?: InputMaybe<Order_By>;\n  consensus_pubkey?: InputMaybe<Order_By>;\n  precommits?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"pre_commits_view\" */\nexport enum Pre_Commits_View_Select_Column {\n  /** column name */\n  ConsensusAddress = 'consensus_address',\n  /** column name */\n  ConsensusPubkey = 'consensus_pubkey',\n  /** column name */\n  Precommits = 'precommits'\n}\n\n/** aggregate stddev on columns */\nexport type Pre_Commits_View_Stddev_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Pre_Commits_View_Stddev_Pop_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Pre_Commits_View_Stddev_Samp_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Pre_Commits_View_Sum_Fields = {\n  precommits?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Pre_Commits_View_Var_Pop_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Pre_Commits_View_Var_Samp_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Pre_Commits_View_Variance_Fields = {\n  precommits?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"pruning\" */\nexport type Pruning = {\n  last_pruned_height: Scalars['bigint']['output'];\n};\n\n/** aggregated selection of \"pruning\" */\nexport type Pruning_Aggregate = {\n  aggregate?: Maybe<Pruning_Aggregate_Fields>;\n  nodes: Array<Pruning>;\n};\n\n/** aggregate fields of \"pruning\" */\nexport type Pruning_Aggregate_Fields = {\n  avg?: Maybe<Pruning_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Pruning_Max_Fields>;\n  min?: Maybe<Pruning_Min_Fields>;\n  stddev?: Maybe<Pruning_Stddev_Fields>;\n  stddev_pop?: Maybe<Pruning_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Pruning_Stddev_Samp_Fields>;\n  sum?: Maybe<Pruning_Sum_Fields>;\n  var_pop?: Maybe<Pruning_Var_Pop_Fields>;\n  var_samp?: Maybe<Pruning_Var_Samp_Fields>;\n  variance?: Maybe<Pruning_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"pruning\" */\nexport type Pruning_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Pruning_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Pruning_Avg_Fields = {\n  last_pruned_height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"pruning\". All fields are combined with a logical 'AND'. */\nexport type Pruning_Bool_Exp = {\n  _and?: InputMaybe<Array<Pruning_Bool_Exp>>;\n  _not?: InputMaybe<Pruning_Bool_Exp>;\n  _or?: InputMaybe<Array<Pruning_Bool_Exp>>;\n  last_pruned_height?: InputMaybe<Bigint_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Pruning_Max_Fields = {\n  last_pruned_height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Pruning_Min_Fields = {\n  last_pruned_height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** Ordering options when selecting data from \"pruning\". */\nexport type Pruning_Order_By = {\n  last_pruned_height?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"pruning\" */\nexport enum Pruning_Select_Column {\n  /** column name */\n  LastPrunedHeight = 'last_pruned_height'\n}\n\n/** aggregate stddev on columns */\nexport type Pruning_Stddev_Fields = {\n  last_pruned_height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Pruning_Stddev_Pop_Fields = {\n  last_pruned_height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Pruning_Stddev_Samp_Fields = {\n  last_pruned_height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Pruning_Sum_Fields = {\n  last_pruned_height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Pruning_Var_Pop_Fields = {\n  last_pruned_height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Pruning_Var_Samp_Fields = {\n  last_pruned_height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Pruning_Variance_Fields = {\n  last_pruned_height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"pussy_gift_proofs\" */\nexport type Pussy_Gift_Proofs = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  details?: Maybe<Scalars['String']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregated selection of \"pussy_gift_proofs\" */\nexport type Pussy_Gift_Proofs_Aggregate = {\n  aggregate?: Maybe<Pussy_Gift_Proofs_Aggregate_Fields>;\n  nodes: Array<Pussy_Gift_Proofs>;\n};\n\n/** aggregate fields of \"pussy_gift_proofs\" */\nexport type Pussy_Gift_Proofs_Aggregate_Fields = {\n  avg?: Maybe<Pussy_Gift_Proofs_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Pussy_Gift_Proofs_Max_Fields>;\n  min?: Maybe<Pussy_Gift_Proofs_Min_Fields>;\n  stddev?: Maybe<Pussy_Gift_Proofs_Stddev_Fields>;\n  stddev_pop?: Maybe<Pussy_Gift_Proofs_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Pussy_Gift_Proofs_Stddev_Samp_Fields>;\n  sum?: Maybe<Pussy_Gift_Proofs_Sum_Fields>;\n  var_pop?: Maybe<Pussy_Gift_Proofs_Var_Pop_Fields>;\n  var_samp?: Maybe<Pussy_Gift_Proofs_Var_Samp_Fields>;\n  variance?: Maybe<Pussy_Gift_Proofs_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"pussy_gift_proofs\" */\nexport type Pussy_Gift_Proofs_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Pussy_Gift_Proofs_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Pussy_Gift_Proofs_Avg_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"pussy_gift_proofs\". All fields are combined with a logical 'AND'. */\nexport type Pussy_Gift_Proofs_Bool_Exp = {\n  _and?: InputMaybe<Array<Pussy_Gift_Proofs_Bool_Exp>>;\n  _not?: InputMaybe<Pussy_Gift_Proofs_Bool_Exp>;\n  _or?: InputMaybe<Array<Pussy_Gift_Proofs_Bool_Exp>>;\n  address?: InputMaybe<String_Comparison_Exp>;\n  amount?: InputMaybe<Bigint_Comparison_Exp>;\n  details?: InputMaybe<String_Comparison_Exp>;\n  proof?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Pussy_Gift_Proofs_Max_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  details?: Maybe<Scalars['String']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Pussy_Gift_Proofs_Min_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  details?: Maybe<Scalars['String']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"pussy_gift_proofs\". */\nexport type Pussy_Gift_Proofs_Order_By = {\n  address?: InputMaybe<Order_By>;\n  amount?: InputMaybe<Order_By>;\n  details?: InputMaybe<Order_By>;\n  proof?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"pussy_gift_proofs\" */\nexport enum Pussy_Gift_Proofs_Select_Column {\n  /** column name */\n  Address = 'address',\n  /** column name */\n  Amount = 'amount',\n  /** column name */\n  Details = 'details',\n  /** column name */\n  Proof = 'proof'\n}\n\n/** aggregate stddev on columns */\nexport type Pussy_Gift_Proofs_Stddev_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Pussy_Gift_Proofs_Stddev_Pop_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Pussy_Gift_Proofs_Stddev_Samp_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Pussy_Gift_Proofs_Sum_Fields = {\n  amount?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Pussy_Gift_Proofs_Var_Pop_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Pussy_Gift_Proofs_Var_Samp_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Pussy_Gift_Proofs_Variance_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\nexport type Query_Root = {\n  /** fetch data from the table: \"_transaction\" */\n  _transaction: Array<_Transaction>;\n  /** fetch aggregated fields from the table: \"_transaction\" */\n  _transaction_aggregate: _Transaction_Aggregate;\n  /** fetch data from the table: \"_uptime_temp\" */\n  _uptime_temp: Array<_Uptime_Temp>;\n  /** fetch aggregated fields from the table: \"_uptime_temp\" */\n  _uptime_temp_aggregate: _Uptime_Temp_Aggregate;\n  /** fetch data from the table: \"account\" */\n  account: Array<Account>;\n  /** fetch aggregated fields from the table: \"account\" */\n  account_aggregate: Account_Aggregate;\n  /** fetch data from the table: \"account_balance\" */\n  account_balance: Array<Account_Balance>;\n  /** fetch aggregated fields from the table: \"account_balance\" */\n  account_balance_aggregate: Account_Balance_Aggregate;\n  /** fetch data from the table: \"account_balance\" using primary key columns */\n  account_balance_by_pk?: Maybe<Account_Balance>;\n  /** fetch data from the table: \"account\" using primary key columns */\n  account_by_pk?: Maybe<Account>;\n  /** fetch data from the table: \"block\" */\n  block: Array<Block>;\n  /** fetch aggregated fields from the table: \"block\" */\n  block_aggregate: Block_Aggregate;\n  /** fetch data from the table: \"block\" using primary key columns */\n  block_by_pk?: Maybe<Block>;\n  /** fetch data from the table: \"contracts\" */\n  contracts: Array<Contracts>;\n  /** fetch aggregated fields from the table: \"contracts\" */\n  contracts_aggregate: Contracts_Aggregate;\n  /** fetch data from the table: \"contracts\" using primary key columns */\n  contracts_by_pk?: Maybe<Contracts>;\n  /** fetch data from the table: \"cyb_cohort\" */\n  cyb_cohort: Array<Cyb_Cohort>;\n  /** fetch aggregated fields from the table: \"cyb_cohort\" */\n  cyb_cohort_aggregate: Cyb_Cohort_Aggregate;\n  /** fetch data from the table: \"cyb_new_cohort\" */\n  cyb_new_cohort: Array<Cyb_New_Cohort>;\n  /** fetch aggregated fields from the table: \"cyb_new_cohort\" */\n  cyb_new_cohort_aggregate: Cyb_New_Cohort_Aggregate;\n  /** fetch data from the table: \"cyber_gift\" */\n  cyber_gift: Array<Cyber_Gift>;\n  /** fetch aggregated fields from the table: \"cyber_gift\" */\n  cyber_gift_aggregate: Cyber_Gift_Aggregate;\n  /** fetch data from the table: \"cyber_gift_proofs\" */\n  cyber_gift_proofs: Array<Cyber_Gift_Proofs>;\n  /** fetch aggregated fields from the table: \"cyber_gift_proofs\" */\n  cyber_gift_proofs_aggregate: Cyber_Gift_Proofs_Aggregate;\n  /** fetch data from the table: \"cyberlinks\" */\n  cyberlinks: Array<Cyberlinks>;\n  /** An aggregate relationship */\n  cyberlinks_aggregate: Cyberlinks_Aggregate;\n  /** fetch data from the table: \"cyberlinks\" using primary key columns */\n  cyberlinks_by_pk?: Maybe<Cyberlinks>;\n  /** fetch data from the table: \"cyberlinks_stats\" */\n  cyberlinks_stats: Array<Cyberlinks_Stats>;\n  /** fetch aggregated fields from the table: \"cyberlinks_stats\" */\n  cyberlinks_stats_aggregate: Cyberlinks_Stats_Aggregate;\n  /** fetch data from the table: \"daily_amount_of_active_neurons\" */\n  daily_amount_of_active_neurons: Array<Daily_Amount_Of_Active_Neurons>;\n  /** fetch aggregated fields from the table: \"daily_amount_of_active_neurons\" */\n  daily_amount_of_active_neurons_aggregate: Daily_Amount_Of_Active_Neurons_Aggregate;\n  /** fetch data from the table: \"daily_amount_of_used_gas\" */\n  daily_amount_of_used_gas: Array<Daily_Amount_Of_Used_Gas>;\n  /** fetch aggregated fields from the table: \"daily_amount_of_used_gas\" */\n  daily_amount_of_used_gas_aggregate: Daily_Amount_Of_Used_Gas_Aggregate;\n  /** fetch data from the table: \"daily_number_of_transactions\" */\n  daily_number_of_transactions: Array<Daily_Number_Of_Transactions>;\n  /** fetch aggregated fields from the table: \"daily_number_of_transactions\" */\n  daily_number_of_transactions_aggregate: Daily_Number_Of_Transactions_Aggregate;\n  /** fetch data from the table: \"follow_stats\" */\n  follow_stats: Array<Follow_Stats>;\n  /** fetch aggregated fields from the table: \"follow_stats\" */\n  follow_stats_aggregate: Follow_Stats_Aggregate;\n  /** fetch data from the table: \"genesis_neurons_activation\" */\n  genesis_neurons_activation: Array<Genesis_Neurons_Activation>;\n  /** fetch aggregated fields from the table: \"genesis_neurons_activation\" */\n  genesis_neurons_activation_aggregate: Genesis_Neurons_Activation_Aggregate;\n  /** An array relationship */\n  investmints: Array<Investmints>;\n  /** An aggregate relationship */\n  investmints_aggregate: Investmints_Aggregate;\n  /** fetch data from the table: \"investmints\" using primary key columns */\n  investmints_by_pk?: Maybe<Investmints>;\n  /** fetch data from the table: \"message\" */\n  message: Array<Message>;\n  /** fetch aggregated fields from the table: \"message\" */\n  message_aggregate: Message_Aggregate;\n  /** execute function \"messages_by_address\" which returns \"message\" */\n  messages_by_address: Array<Message>;\n  /** execute function \"messages_by_address\" and query aggregates on result of table type \"message\" */\n  messages_by_address_aggregate: Message_Aggregate;\n  /** fetch data from the table: \"modules\" */\n  modules: Array<Modules>;\n  /** fetch aggregated fields from the table: \"modules\" */\n  modules_aggregate: Modules_Aggregate;\n  /** fetch data from the table: \"modules\" using primary key columns */\n  modules_by_pk?: Maybe<Modules>;\n  /** fetch data from the table: \"neuron_activation_source\" */\n  neuron_activation_source: Array<Neuron_Activation_Source>;\n  /** fetch aggregated fields from the table: \"neuron_activation_source\" */\n  neuron_activation_source_aggregate: Neuron_Activation_Source_Aggregate;\n  /** fetch data from the table: \"number_of_new_neurons\" */\n  number_of_new_neurons: Array<Number_Of_New_Neurons>;\n  /** fetch aggregated fields from the table: \"number_of_new_neurons\" */\n  number_of_new_neurons_aggregate: Number_Of_New_Neurons_Aggregate;\n  /** fetch data from the table: \"old_precommits\" */\n  old_precommits: Array<Old_Precommits>;\n  /** fetch aggregated fields from the table: \"old_precommits\" */\n  old_precommits_aggregate: Old_Precommits_Aggregate;\n  /** fetch data from the table: \"old_precommits\" using primary key columns */\n  old_precommits_by_pk?: Maybe<Old_Precommits>;\n  /** An array relationship */\n  particles: Array<Particles>;\n  /** An aggregate relationship */\n  particles_aggregate: Particles_Aggregate;\n  /** fetch data from the table: \"particles\" using primary key columns */\n  particles_by_pk?: Maybe<Particles>;\n  /** fetch data from the table: \"pre_commit\" */\n  pre_commit: Array<Pre_Commit>;\n  /** fetch aggregated fields from the table: \"pre_commit\" */\n  pre_commit_aggregate: Pre_Commit_Aggregate;\n  /** fetch data from the table: \"pre_commits_rewards_view\" */\n  pre_commits_rewards_view: Array<Pre_Commits_Rewards_View>;\n  /** fetch aggregated fields from the table: \"pre_commits_rewards_view\" */\n  pre_commits_rewards_view_aggregate: Pre_Commits_Rewards_View_Aggregate;\n  /** fetch data from the table: \"pre_commits_total\" */\n  pre_commits_total: Array<Pre_Commits_Total>;\n  /** fetch aggregated fields from the table: \"pre_commits_total\" */\n  pre_commits_total_aggregate: Pre_Commits_Total_Aggregate;\n  /** fetch data from the table: \"pre_commits_view\" */\n  pre_commits_view: Array<Pre_Commits_View>;\n  /** fetch aggregated fields from the table: \"pre_commits_view\" */\n  pre_commits_view_aggregate: Pre_Commits_View_Aggregate;\n  /** fetch data from the table: \"pruning\" */\n  pruning: Array<Pruning>;\n  /** fetch aggregated fields from the table: \"pruning\" */\n  pruning_aggregate: Pruning_Aggregate;\n  /** fetch data from the table: \"pussy_gift_proofs\" */\n  pussy_gift_proofs: Array<Pussy_Gift_Proofs>;\n  /** fetch aggregated fields from the table: \"pussy_gift_proofs\" */\n  pussy_gift_proofs_aggregate: Pussy_Gift_Proofs_Aggregate;\n  /** An array relationship */\n  routes: Array<Routes>;\n  /** An aggregate relationship */\n  routes_aggregate: Routes_Aggregate;\n  /** fetch data from the table: \"routes\" using primary key columns */\n  routes_by_pk?: Maybe<Routes>;\n  /** fetch data from the table: \"supply\" */\n  supply: Array<Supply>;\n  /** fetch aggregated fields from the table: \"supply\" */\n  supply_aggregate: Supply_Aggregate;\n  /** fetch data from the table: \"supply\" using primary key columns */\n  supply_by_pk?: Maybe<Supply>;\n  /** fetch data from the table: \"test_gift\" */\n  test_gift: Array<Test_Gift>;\n  /** fetch aggregated fields from the table: \"test_gift\" */\n  test_gift_aggregate: Test_Gift_Aggregate;\n  /** fetch data from the table: \"today_top_txs\" */\n  today_top_txs: Array<Today_Top_Txs>;\n  /** fetch aggregated fields from the table: \"today_top_txs\" */\n  today_top_txs_aggregate: Today_Top_Txs_Aggregate;\n  /** fetch data from the table: \"top_10_of_active_neurons_week\" */\n  top_10_of_active_neurons_week: Array<Top_10_Of_Active_Neurons_Week>;\n  /** fetch aggregated fields from the table: \"top_10_of_active_neurons_week\" */\n  top_10_of_active_neurons_week_aggregate: Top_10_Of_Active_Neurons_Week_Aggregate;\n  /** fetch data from the table: \"top_first_txs\" */\n  top_first_txs: Array<Top_First_Txs>;\n  /** fetch aggregated fields from the table: \"top_first_txs\" */\n  top_first_txs_aggregate: Top_First_Txs_Aggregate;\n  /** fetch data from the table: \"top_leaders\" */\n  top_leaders: Array<Top_Leaders>;\n  /** fetch data from the table: \"top_txs\" */\n  top_txs: Array<Top_Txs>;\n  /** fetch aggregated fields from the table: \"top_txs\" */\n  top_txs_aggregate: Top_Txs_Aggregate;\n  /** fetch data from the table: \"transaction\" */\n  transaction: Array<Transaction>;\n  /** fetch aggregated fields from the table: \"transaction\" */\n  transaction_aggregate: Transaction_Aggregate;\n  /** fetch data from the table: \"transaction\" using primary key columns */\n  transaction_by_pk?: Maybe<Transaction>;\n  /** fetch data from the table: \"tweets_stats\" */\n  tweets_stats: Array<Tweets_Stats>;\n  /** fetch aggregated fields from the table: \"tweets_stats\" */\n  tweets_stats_aggregate: Tweets_Stats_Aggregate;\n  /** fetch data from the table: \"txs_ranked\" */\n  txs_ranked: Array<Txs_Ranked>;\n  /** fetch aggregated fields from the table: \"txs_ranked\" */\n  txs_ranked_aggregate: Txs_Ranked_Aggregate;\n  /** fetch data from the table: \"txs_stats\" */\n  txs_stats: Array<Txs_Stats>;\n  /** fetch aggregated fields from the table: \"txs_stats\" */\n  txs_stats_aggregate: Txs_Stats_Aggregate;\n  /** fetch data from the table: \"uptime\" */\n  uptime: Array<Uptime>;\n  /** fetch aggregated fields from the table: \"uptime\" */\n  uptime_aggregate: Uptime_Aggregate;\n  /** fetch data from the table: \"validator\" */\n  validator: Array<Validator>;\n  /** fetch aggregated fields from the table: \"validator\" */\n  validator_aggregate: Validator_Aggregate;\n  /** fetch data from the table: \"validator\" using primary key columns */\n  validator_by_pk?: Maybe<Validator>;\n  /** fetch data from the table: \"volts_demand\" */\n  volts_demand: Array<Volts_Demand>;\n  /** fetch aggregated fields from the table: \"volts_demand\" */\n  volts_demand_aggregate: Volts_Demand_Aggregate;\n  /** fetch data from the table: \"volts_stats\" */\n  volts_stats: Array<Volts_Stats>;\n  /** fetch aggregated fields from the table: \"volts_stats\" */\n  volts_stats_aggregate: Volts_Stats_Aggregate;\n};\n\n\nexport type Query_Root_TransactionArgs = {\n  distinct_on?: InputMaybe<Array<_Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Transaction_Order_By>>;\n  where?: InputMaybe<_Transaction_Bool_Exp>;\n};\n\n\nexport type Query_Root_Transaction_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<_Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Transaction_Order_By>>;\n  where?: InputMaybe<_Transaction_Bool_Exp>;\n};\n\n\nexport type Query_Root_Uptime_TempArgs = {\n  distinct_on?: InputMaybe<Array<_Uptime_Temp_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Uptime_Temp_Order_By>>;\n  where?: InputMaybe<_Uptime_Temp_Bool_Exp>;\n};\n\n\nexport type Query_Root_Uptime_Temp_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<_Uptime_Temp_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Uptime_Temp_Order_By>>;\n  where?: InputMaybe<_Uptime_Temp_Bool_Exp>;\n};\n\n\nexport type Query_RootAccountArgs = {\n  distinct_on?: InputMaybe<Array<Account_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Order_By>>;\n  where?: InputMaybe<Account_Bool_Exp>;\n};\n\n\nexport type Query_RootAccount_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Account_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Order_By>>;\n  where?: InputMaybe<Account_Bool_Exp>;\n};\n\n\nexport type Query_RootAccount_BalanceArgs = {\n  distinct_on?: InputMaybe<Array<Account_Balance_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Balance_Order_By>>;\n  where?: InputMaybe<Account_Balance_Bool_Exp>;\n};\n\n\nexport type Query_RootAccount_Balance_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Account_Balance_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Balance_Order_By>>;\n  where?: InputMaybe<Account_Balance_Bool_Exp>;\n};\n\n\nexport type Query_RootAccount_Balance_By_PkArgs = {\n  address: Scalars['String']['input'];\n};\n\n\nexport type Query_RootAccount_By_PkArgs = {\n  address: Scalars['String']['input'];\n};\n\n\nexport type Query_RootBlockArgs = {\n  distinct_on?: InputMaybe<Array<Block_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Block_Order_By>>;\n  where?: InputMaybe<Block_Bool_Exp>;\n};\n\n\nexport type Query_RootBlock_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Block_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Block_Order_By>>;\n  where?: InputMaybe<Block_Bool_Exp>;\n};\n\n\nexport type Query_RootBlock_By_PkArgs = {\n  height: Scalars['bigint']['input'];\n};\n\n\nexport type Query_RootContractsArgs = {\n  distinct_on?: InputMaybe<Array<Contracts_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Contracts_Order_By>>;\n  where?: InputMaybe<Contracts_Bool_Exp>;\n};\n\n\nexport type Query_RootContracts_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Contracts_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Contracts_Order_By>>;\n  where?: InputMaybe<Contracts_Bool_Exp>;\n};\n\n\nexport type Query_RootContracts_By_PkArgs = {\n  address: Scalars['String']['input'];\n};\n\n\nexport type Query_RootCyb_CohortArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_Cohort_Bool_Exp>;\n};\n\n\nexport type Query_RootCyb_Cohort_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_Cohort_Bool_Exp>;\n};\n\n\nexport type Query_RootCyb_New_CohortArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_New_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_New_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_New_Cohort_Bool_Exp>;\n};\n\n\nexport type Query_RootCyb_New_Cohort_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_New_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_New_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_New_Cohort_Bool_Exp>;\n};\n\n\nexport type Query_RootCyber_GiftArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Bool_Exp>;\n};\n\n\nexport type Query_RootCyber_Gift_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Bool_Exp>;\n};\n\n\nexport type Query_RootCyber_Gift_ProofsArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Query_RootCyber_Gift_Proofs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Query_RootCyberlinksArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\nexport type Query_RootCyberlinks_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\nexport type Query_RootCyberlinks_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Query_RootCyberlinks_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Stats_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootCyberlinks_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Stats_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootDaily_Amount_Of_Active_NeuronsArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Active_Neurons_Bool_Exp>;\n};\n\n\nexport type Query_RootDaily_Amount_Of_Active_Neurons_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Active_Neurons_Bool_Exp>;\n};\n\n\nexport type Query_RootDaily_Amount_Of_Used_GasArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Used_Gas_Bool_Exp>;\n};\n\n\nexport type Query_RootDaily_Amount_Of_Used_Gas_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Used_Gas_Bool_Exp>;\n};\n\n\nexport type Query_RootDaily_Number_Of_TransactionsArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Number_Of_Transactions_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Number_Of_Transactions_Order_By>>;\n  where?: InputMaybe<Daily_Number_Of_Transactions_Bool_Exp>;\n};\n\n\nexport type Query_RootDaily_Number_Of_Transactions_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Number_Of_Transactions_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Number_Of_Transactions_Order_By>>;\n  where?: InputMaybe<Daily_Number_Of_Transactions_Bool_Exp>;\n};\n\n\nexport type Query_RootFollow_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Follow_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Follow_Stats_Order_By>>;\n  where?: InputMaybe<Follow_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootFollow_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Follow_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Follow_Stats_Order_By>>;\n  where?: InputMaybe<Follow_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootGenesis_Neurons_ActivationArgs = {\n  distinct_on?: InputMaybe<Array<Genesis_Neurons_Activation_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Genesis_Neurons_Activation_Order_By>>;\n  where?: InputMaybe<Genesis_Neurons_Activation_Bool_Exp>;\n};\n\n\nexport type Query_RootGenesis_Neurons_Activation_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Genesis_Neurons_Activation_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Genesis_Neurons_Activation_Order_By>>;\n  where?: InputMaybe<Genesis_Neurons_Activation_Bool_Exp>;\n};\n\n\nexport type Query_RootInvestmintsArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\nexport type Query_RootInvestmints_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\nexport type Query_RootInvestmints_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Query_RootMessageArgs = {\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Query_RootMessage_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Query_RootMessages_By_AddressArgs = {\n  args: Messages_By_Address_Args;\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Query_RootMessages_By_Address_AggregateArgs = {\n  args: Messages_By_Address_Args;\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Query_RootModulesArgs = {\n  distinct_on?: InputMaybe<Array<Modules_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Modules_Order_By>>;\n  where?: InputMaybe<Modules_Bool_Exp>;\n};\n\n\nexport type Query_RootModules_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Modules_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Modules_Order_By>>;\n  where?: InputMaybe<Modules_Bool_Exp>;\n};\n\n\nexport type Query_RootModules_By_PkArgs = {\n  module_name: Scalars['String']['input'];\n};\n\n\nexport type Query_RootNeuron_Activation_SourceArgs = {\n  distinct_on?: InputMaybe<Array<Neuron_Activation_Source_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Neuron_Activation_Source_Order_By>>;\n  where?: InputMaybe<Neuron_Activation_Source_Bool_Exp>;\n};\n\n\nexport type Query_RootNeuron_Activation_Source_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Neuron_Activation_Source_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Neuron_Activation_Source_Order_By>>;\n  where?: InputMaybe<Neuron_Activation_Source_Bool_Exp>;\n};\n\n\nexport type Query_RootNumber_Of_New_NeuronsArgs = {\n  distinct_on?: InputMaybe<Array<Number_Of_New_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Number_Of_New_Neurons_Order_By>>;\n  where?: InputMaybe<Number_Of_New_Neurons_Bool_Exp>;\n};\n\n\nexport type Query_RootNumber_Of_New_Neurons_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Number_Of_New_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Number_Of_New_Neurons_Order_By>>;\n  where?: InputMaybe<Number_Of_New_Neurons_Bool_Exp>;\n};\n\n\nexport type Query_RootOld_PrecommitsArgs = {\n  distinct_on?: InputMaybe<Array<Old_Precommits_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Old_Precommits_Order_By>>;\n  where?: InputMaybe<Old_Precommits_Bool_Exp>;\n};\n\n\nexport type Query_RootOld_Precommits_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Old_Precommits_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Old_Precommits_Order_By>>;\n  where?: InputMaybe<Old_Precommits_Bool_Exp>;\n};\n\n\nexport type Query_RootOld_Precommits_By_PkArgs = {\n  consensus_address: Scalars['String']['input'];\n};\n\n\nexport type Query_RootParticlesArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\nexport type Query_RootParticles_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\nexport type Query_RootParticles_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Query_RootPre_CommitArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commit_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commit_Order_By>>;\n  where?: InputMaybe<Pre_Commit_Bool_Exp>;\n};\n\n\nexport type Query_RootPre_Commit_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commit_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commit_Order_By>>;\n  where?: InputMaybe<Pre_Commit_Bool_Exp>;\n};\n\n\nexport type Query_RootPre_Commits_Rewards_ViewArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Rewards_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Rewards_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Rewards_View_Bool_Exp>;\n};\n\n\nexport type Query_RootPre_Commits_Rewards_View_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Rewards_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Rewards_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Rewards_View_Bool_Exp>;\n};\n\n\nexport type Query_RootPre_Commits_TotalArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Total_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Total_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Total_Bool_Exp>;\n};\n\n\nexport type Query_RootPre_Commits_Total_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Total_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Total_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Total_Bool_Exp>;\n};\n\n\nexport type Query_RootPre_Commits_ViewArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_View_Bool_Exp>;\n};\n\n\nexport type Query_RootPre_Commits_View_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_View_Bool_Exp>;\n};\n\n\nexport type Query_RootPruningArgs = {\n  distinct_on?: InputMaybe<Array<Pruning_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pruning_Order_By>>;\n  where?: InputMaybe<Pruning_Bool_Exp>;\n};\n\n\nexport type Query_RootPruning_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pruning_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pruning_Order_By>>;\n  where?: InputMaybe<Pruning_Bool_Exp>;\n};\n\n\nexport type Query_RootPussy_Gift_ProofsArgs = {\n  distinct_on?: InputMaybe<Array<Pussy_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pussy_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Pussy_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Query_RootPussy_Gift_Proofs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pussy_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pussy_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Pussy_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Query_RootRoutesArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\nexport type Query_RootRoutes_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\nexport type Query_RootRoutes_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Query_RootSupplyArgs = {\n  distinct_on?: InputMaybe<Array<Supply_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Supply_Order_By>>;\n  where?: InputMaybe<Supply_Bool_Exp>;\n};\n\n\nexport type Query_RootSupply_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Supply_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Supply_Order_By>>;\n  where?: InputMaybe<Supply_Bool_Exp>;\n};\n\n\nexport type Query_RootSupply_By_PkArgs = {\n  one_row_id: Scalars['Boolean']['input'];\n};\n\n\nexport type Query_RootTest_GiftArgs = {\n  distinct_on?: InputMaybe<Array<Test_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Test_Gift_Order_By>>;\n  where?: InputMaybe<Test_Gift_Bool_Exp>;\n};\n\n\nexport type Query_RootTest_Gift_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Test_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Test_Gift_Order_By>>;\n  where?: InputMaybe<Test_Gift_Bool_Exp>;\n};\n\n\nexport type Query_RootToday_Top_TxsArgs = {\n  distinct_on?: InputMaybe<Array<Today_Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Today_Top_Txs_Order_By>>;\n  where?: InputMaybe<Today_Top_Txs_Bool_Exp>;\n};\n\n\nexport type Query_RootToday_Top_Txs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Today_Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Today_Top_Txs_Order_By>>;\n  where?: InputMaybe<Today_Top_Txs_Bool_Exp>;\n};\n\n\nexport type Query_RootTop_10_Of_Active_Neurons_WeekArgs = {\n  distinct_on?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Order_By>>;\n  where?: InputMaybe<Top_10_Of_Active_Neurons_Week_Bool_Exp>;\n};\n\n\nexport type Query_RootTop_10_Of_Active_Neurons_Week_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Order_By>>;\n  where?: InputMaybe<Top_10_Of_Active_Neurons_Week_Bool_Exp>;\n};\n\n\nexport type Query_RootTop_First_TxsArgs = {\n  distinct_on?: InputMaybe<Array<Top_First_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_First_Txs_Order_By>>;\n  where?: InputMaybe<Top_First_Txs_Bool_Exp>;\n};\n\n\nexport type Query_RootTop_First_Txs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Top_First_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_First_Txs_Order_By>>;\n  where?: InputMaybe<Top_First_Txs_Bool_Exp>;\n};\n\n\nexport type Query_RootTop_LeadersArgs = {\n  distinct_on?: InputMaybe<Array<Top_Leaders_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_Leaders_Order_By>>;\n  where?: InputMaybe<Top_Leaders_Bool_Exp>;\n};\n\n\nexport type Query_RootTop_TxsArgs = {\n  distinct_on?: InputMaybe<Array<Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_Txs_Order_By>>;\n  where?: InputMaybe<Top_Txs_Bool_Exp>;\n};\n\n\nexport type Query_RootTop_Txs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_Txs_Order_By>>;\n  where?: InputMaybe<Top_Txs_Bool_Exp>;\n};\n\n\nexport type Query_RootTransactionArgs = {\n  distinct_on?: InputMaybe<Array<Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Transaction_Order_By>>;\n  where?: InputMaybe<Transaction_Bool_Exp>;\n};\n\n\nexport type Query_RootTransaction_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Transaction_Order_By>>;\n  where?: InputMaybe<Transaction_Bool_Exp>;\n};\n\n\nexport type Query_RootTransaction_By_PkArgs = {\n  hash: Scalars['String']['input'];\n};\n\n\nexport type Query_RootTweets_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Tweets_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Tweets_Stats_Order_By>>;\n  where?: InputMaybe<Tweets_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootTweets_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Tweets_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Tweets_Stats_Order_By>>;\n  where?: InputMaybe<Tweets_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootTxs_RankedArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Ranked_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Ranked_Order_By>>;\n  where?: InputMaybe<Txs_Ranked_Bool_Exp>;\n};\n\n\nexport type Query_RootTxs_Ranked_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Ranked_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Ranked_Order_By>>;\n  where?: InputMaybe<Txs_Ranked_Bool_Exp>;\n};\n\n\nexport type Query_RootTxs_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Stats_Order_By>>;\n  where?: InputMaybe<Txs_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootTxs_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Stats_Order_By>>;\n  where?: InputMaybe<Txs_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootUptimeArgs = {\n  distinct_on?: InputMaybe<Array<Uptime_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Uptime_Order_By>>;\n  where?: InputMaybe<Uptime_Bool_Exp>;\n};\n\n\nexport type Query_RootUptime_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Uptime_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Uptime_Order_By>>;\n  where?: InputMaybe<Uptime_Bool_Exp>;\n};\n\n\nexport type Query_RootValidatorArgs = {\n  distinct_on?: InputMaybe<Array<Validator_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Validator_Order_By>>;\n  where?: InputMaybe<Validator_Bool_Exp>;\n};\n\n\nexport type Query_RootValidator_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Validator_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Validator_Order_By>>;\n  where?: InputMaybe<Validator_Bool_Exp>;\n};\n\n\nexport type Query_RootValidator_By_PkArgs = {\n  consensus_address: Scalars['String']['input'];\n};\n\n\nexport type Query_RootVolts_DemandArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Demand_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Demand_Order_By>>;\n  where?: InputMaybe<Volts_Demand_Bool_Exp>;\n};\n\n\nexport type Query_RootVolts_Demand_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Demand_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Demand_Order_By>>;\n  where?: InputMaybe<Volts_Demand_Bool_Exp>;\n};\n\n\nexport type Query_RootVolts_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Stats_Order_By>>;\n  where?: InputMaybe<Volts_Stats_Bool_Exp>;\n};\n\n\nexport type Query_RootVolts_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Stats_Order_By>>;\n  where?: InputMaybe<Volts_Stats_Bool_Exp>;\n};\n\n/** columns and relationships of \"routes\" */\nexport type Routes = {\n  /** An object relationship */\n  account: Account;\n  /** An object relationship */\n  accountBySource: Account;\n  alias: Scalars['String']['output'];\n  /** An object relationship */\n  block: Block;\n  destination: Scalars['String']['output'];\n  height: Scalars['bigint']['output'];\n  id: Scalars['Int']['output'];\n  source: Scalars['String']['output'];\n  timestamp: Scalars['timestamp']['output'];\n  /** An object relationship */\n  transaction: Transaction;\n  transaction_hash: Scalars['String']['output'];\n  value: Scalars['_coin']['output'];\n};\n\n/** aggregated selection of \"routes\" */\nexport type Routes_Aggregate = {\n  aggregate?: Maybe<Routes_Aggregate_Fields>;\n  nodes: Array<Routes>;\n};\n\n/** aggregate fields of \"routes\" */\nexport type Routes_Aggregate_Fields = {\n  avg?: Maybe<Routes_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Routes_Max_Fields>;\n  min?: Maybe<Routes_Min_Fields>;\n  stddev?: Maybe<Routes_Stddev_Fields>;\n  stddev_pop?: Maybe<Routes_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Routes_Stddev_Samp_Fields>;\n  sum?: Maybe<Routes_Sum_Fields>;\n  var_pop?: Maybe<Routes_Var_Pop_Fields>;\n  var_samp?: Maybe<Routes_Var_Samp_Fields>;\n  variance?: Maybe<Routes_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"routes\" */\nexport type Routes_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Routes_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"routes\" */\nexport type Routes_Aggregate_Order_By = {\n  avg?: InputMaybe<Routes_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Routes_Max_Order_By>;\n  min?: InputMaybe<Routes_Min_Order_By>;\n  stddev?: InputMaybe<Routes_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Routes_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Routes_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Routes_Sum_Order_By>;\n  var_pop?: InputMaybe<Routes_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Routes_Var_Samp_Order_By>;\n  variance?: InputMaybe<Routes_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Routes_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"routes\" */\nexport type Routes_Avg_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"routes\". All fields are combined with a logical 'AND'. */\nexport type Routes_Bool_Exp = {\n  _and?: InputMaybe<Array<Routes_Bool_Exp>>;\n  _not?: InputMaybe<Routes_Bool_Exp>;\n  _or?: InputMaybe<Array<Routes_Bool_Exp>>;\n  account?: InputMaybe<Account_Bool_Exp>;\n  accountBySource?: InputMaybe<Account_Bool_Exp>;\n  alias?: InputMaybe<String_Comparison_Exp>;\n  block?: InputMaybe<Block_Bool_Exp>;\n  destination?: InputMaybe<String_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  id?: InputMaybe<Int_Comparison_Exp>;\n  source?: InputMaybe<String_Comparison_Exp>;\n  timestamp?: InputMaybe<Timestamp_Comparison_Exp>;\n  transaction?: InputMaybe<Transaction_Bool_Exp>;\n  transaction_hash?: InputMaybe<String_Comparison_Exp>;\n  value?: InputMaybe<_Coin_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Routes_Max_Fields = {\n  alias?: Maybe<Scalars['String']['output']>;\n  destination?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  source?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by max() on columns of table \"routes\" */\nexport type Routes_Max_Order_By = {\n  alias?: InputMaybe<Order_By>;\n  destination?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  source?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Routes_Min_Fields = {\n  alias?: Maybe<Scalars['String']['output']>;\n  destination?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n  source?: Maybe<Scalars['String']['output']>;\n  timestamp?: Maybe<Scalars['timestamp']['output']>;\n  transaction_hash?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by min() on columns of table \"routes\" */\nexport type Routes_Min_Order_By = {\n  alias?: InputMaybe<Order_By>;\n  destination?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  source?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"routes\". */\nexport type Routes_Order_By = {\n  account?: InputMaybe<Account_Order_By>;\n  accountBySource?: InputMaybe<Account_Order_By>;\n  alias?: InputMaybe<Order_By>;\n  block?: InputMaybe<Block_Order_By>;\n  destination?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n  source?: InputMaybe<Order_By>;\n  timestamp?: InputMaybe<Order_By>;\n  transaction?: InputMaybe<Transaction_Order_By>;\n  transaction_hash?: InputMaybe<Order_By>;\n  value?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"routes\" */\nexport enum Routes_Select_Column {\n  /** column name */\n  Alias = 'alias',\n  /** column name */\n  Destination = 'destination',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Id = 'id',\n  /** column name */\n  Source = 'source',\n  /** column name */\n  Timestamp = 'timestamp',\n  /** column name */\n  TransactionHash = 'transaction_hash',\n  /** column name */\n  Value = 'value'\n}\n\n/** aggregate stddev on columns */\nexport type Routes_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"routes\" */\nexport type Routes_Stddev_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Routes_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"routes\" */\nexport type Routes_Stddev_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Routes_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"routes\" */\nexport type Routes_Stddev_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Routes_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  id?: Maybe<Scalars['Int']['output']>;\n};\n\n/** order by sum() on columns of table \"routes\" */\nexport type Routes_Sum_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Routes_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"routes\" */\nexport type Routes_Var_Pop_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Routes_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"routes\" */\nexport type Routes_Var_Samp_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Routes_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  id?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"routes\" */\nexport type Routes_Variance_Order_By = {\n  height?: InputMaybe<Order_By>;\n  id?: InputMaybe<Order_By>;\n};\n\nexport type Subscription_Root = {\n  /** fetch data from the table: \"_transaction\" */\n  _transaction: Array<_Transaction>;\n  /** fetch aggregated fields from the table: \"_transaction\" */\n  _transaction_aggregate: _Transaction_Aggregate;\n  /** fetch data from the table: \"_uptime_temp\" */\n  _uptime_temp: Array<_Uptime_Temp>;\n  /** fetch aggregated fields from the table: \"_uptime_temp\" */\n  _uptime_temp_aggregate: _Uptime_Temp_Aggregate;\n  /** fetch data from the table: \"account\" */\n  account: Array<Account>;\n  /** fetch aggregated fields from the table: \"account\" */\n  account_aggregate: Account_Aggregate;\n  /** fetch data from the table: \"account_balance\" */\n  account_balance: Array<Account_Balance>;\n  /** fetch aggregated fields from the table: \"account_balance\" */\n  account_balance_aggregate: Account_Balance_Aggregate;\n  /** fetch data from the table: \"account_balance\" using primary key columns */\n  account_balance_by_pk?: Maybe<Account_Balance>;\n  /** fetch data from the table: \"account\" using primary key columns */\n  account_by_pk?: Maybe<Account>;\n  /** fetch data from the table: \"block\" */\n  block: Array<Block>;\n  /** fetch aggregated fields from the table: \"block\" */\n  block_aggregate: Block_Aggregate;\n  /** fetch data from the table: \"block\" using primary key columns */\n  block_by_pk?: Maybe<Block>;\n  /** fetch data from the table: \"contracts\" */\n  contracts: Array<Contracts>;\n  /** fetch aggregated fields from the table: \"contracts\" */\n  contracts_aggregate: Contracts_Aggregate;\n  /** fetch data from the table: \"contracts\" using primary key columns */\n  contracts_by_pk?: Maybe<Contracts>;\n  /** fetch data from the table: \"cyb_cohort\" */\n  cyb_cohort: Array<Cyb_Cohort>;\n  /** fetch aggregated fields from the table: \"cyb_cohort\" */\n  cyb_cohort_aggregate: Cyb_Cohort_Aggregate;\n  /** fetch data from the table: \"cyb_new_cohort\" */\n  cyb_new_cohort: Array<Cyb_New_Cohort>;\n  /** fetch aggregated fields from the table: \"cyb_new_cohort\" */\n  cyb_new_cohort_aggregate: Cyb_New_Cohort_Aggregate;\n  /** fetch data from the table: \"cyber_gift\" */\n  cyber_gift: Array<Cyber_Gift>;\n  /** fetch aggregated fields from the table: \"cyber_gift\" */\n  cyber_gift_aggregate: Cyber_Gift_Aggregate;\n  /** fetch data from the table: \"cyber_gift_proofs\" */\n  cyber_gift_proofs: Array<Cyber_Gift_Proofs>;\n  /** fetch aggregated fields from the table: \"cyber_gift_proofs\" */\n  cyber_gift_proofs_aggregate: Cyber_Gift_Proofs_Aggregate;\n  /** fetch data from the table: \"cyberlinks\" */\n  cyberlinks: Array<Cyberlinks>;\n  /** An aggregate relationship */\n  cyberlinks_aggregate: Cyberlinks_Aggregate;\n  /** fetch data from the table: \"cyberlinks\" using primary key columns */\n  cyberlinks_by_pk?: Maybe<Cyberlinks>;\n  /** fetch data from the table: \"cyberlinks_stats\" */\n  cyberlinks_stats: Array<Cyberlinks_Stats>;\n  /** fetch aggregated fields from the table: \"cyberlinks_stats\" */\n  cyberlinks_stats_aggregate: Cyberlinks_Stats_Aggregate;\n  /** fetch data from the table: \"daily_amount_of_active_neurons\" */\n  daily_amount_of_active_neurons: Array<Daily_Amount_Of_Active_Neurons>;\n  /** fetch aggregated fields from the table: \"daily_amount_of_active_neurons\" */\n  daily_amount_of_active_neurons_aggregate: Daily_Amount_Of_Active_Neurons_Aggregate;\n  /** fetch data from the table: \"daily_amount_of_used_gas\" */\n  daily_amount_of_used_gas: Array<Daily_Amount_Of_Used_Gas>;\n  /** fetch aggregated fields from the table: \"daily_amount_of_used_gas\" */\n  daily_amount_of_used_gas_aggregate: Daily_Amount_Of_Used_Gas_Aggregate;\n  /** fetch data from the table: \"daily_number_of_transactions\" */\n  daily_number_of_transactions: Array<Daily_Number_Of_Transactions>;\n  /** fetch aggregated fields from the table: \"daily_number_of_transactions\" */\n  daily_number_of_transactions_aggregate: Daily_Number_Of_Transactions_Aggregate;\n  /** fetch data from the table: \"follow_stats\" */\n  follow_stats: Array<Follow_Stats>;\n  /** fetch aggregated fields from the table: \"follow_stats\" */\n  follow_stats_aggregate: Follow_Stats_Aggregate;\n  /** fetch data from the table: \"genesis_neurons_activation\" */\n  genesis_neurons_activation: Array<Genesis_Neurons_Activation>;\n  /** fetch aggregated fields from the table: \"genesis_neurons_activation\" */\n  genesis_neurons_activation_aggregate: Genesis_Neurons_Activation_Aggregate;\n  /** An array relationship */\n  investmints: Array<Investmints>;\n  /** An aggregate relationship */\n  investmints_aggregate: Investmints_Aggregate;\n  /** fetch data from the table: \"investmints\" using primary key columns */\n  investmints_by_pk?: Maybe<Investmints>;\n  /** fetch data from the table: \"message\" */\n  message: Array<Message>;\n  /** fetch aggregated fields from the table: \"message\" */\n  message_aggregate: Message_Aggregate;\n  /** execute function \"messages_by_address\" which returns \"message\" */\n  messages_by_address: Array<Message>;\n  /** execute function \"messages_by_address\" and query aggregates on result of table type \"message\" */\n  messages_by_address_aggregate: Message_Aggregate;\n  /** fetch data from the table: \"modules\" */\n  modules: Array<Modules>;\n  /** fetch aggregated fields from the table: \"modules\" */\n  modules_aggregate: Modules_Aggregate;\n  /** fetch data from the table: \"modules\" using primary key columns */\n  modules_by_pk?: Maybe<Modules>;\n  /** fetch data from the table: \"neuron_activation_source\" */\n  neuron_activation_source: Array<Neuron_Activation_Source>;\n  /** fetch aggregated fields from the table: \"neuron_activation_source\" */\n  neuron_activation_source_aggregate: Neuron_Activation_Source_Aggregate;\n  /** fetch data from the table: \"number_of_new_neurons\" */\n  number_of_new_neurons: Array<Number_Of_New_Neurons>;\n  /** fetch aggregated fields from the table: \"number_of_new_neurons\" */\n  number_of_new_neurons_aggregate: Number_Of_New_Neurons_Aggregate;\n  /** fetch data from the table: \"old_precommits\" */\n  old_precommits: Array<Old_Precommits>;\n  /** fetch aggregated fields from the table: \"old_precommits\" */\n  old_precommits_aggregate: Old_Precommits_Aggregate;\n  /** fetch data from the table: \"old_precommits\" using primary key columns */\n  old_precommits_by_pk?: Maybe<Old_Precommits>;\n  /** An array relationship */\n  particles: Array<Particles>;\n  /** An aggregate relationship */\n  particles_aggregate: Particles_Aggregate;\n  /** fetch data from the table: \"particles\" using primary key columns */\n  particles_by_pk?: Maybe<Particles>;\n  /** fetch data from the table: \"pre_commit\" */\n  pre_commit: Array<Pre_Commit>;\n  /** fetch aggregated fields from the table: \"pre_commit\" */\n  pre_commit_aggregate: Pre_Commit_Aggregate;\n  /** fetch data from the table: \"pre_commits_rewards_view\" */\n  pre_commits_rewards_view: Array<Pre_Commits_Rewards_View>;\n  /** fetch aggregated fields from the table: \"pre_commits_rewards_view\" */\n  pre_commits_rewards_view_aggregate: Pre_Commits_Rewards_View_Aggregate;\n  /** fetch data from the table: \"pre_commits_total\" */\n  pre_commits_total: Array<Pre_Commits_Total>;\n  /** fetch aggregated fields from the table: \"pre_commits_total\" */\n  pre_commits_total_aggregate: Pre_Commits_Total_Aggregate;\n  /** fetch data from the table: \"pre_commits_view\" */\n  pre_commits_view: Array<Pre_Commits_View>;\n  /** fetch aggregated fields from the table: \"pre_commits_view\" */\n  pre_commits_view_aggregate: Pre_Commits_View_Aggregate;\n  /** fetch data from the table: \"pruning\" */\n  pruning: Array<Pruning>;\n  /** fetch aggregated fields from the table: \"pruning\" */\n  pruning_aggregate: Pruning_Aggregate;\n  /** fetch data from the table: \"pussy_gift_proofs\" */\n  pussy_gift_proofs: Array<Pussy_Gift_Proofs>;\n  /** fetch aggregated fields from the table: \"pussy_gift_proofs\" */\n  pussy_gift_proofs_aggregate: Pussy_Gift_Proofs_Aggregate;\n  /** An array relationship */\n  routes: Array<Routes>;\n  /** An aggregate relationship */\n  routes_aggregate: Routes_Aggregate;\n  /** fetch data from the table: \"routes\" using primary key columns */\n  routes_by_pk?: Maybe<Routes>;\n  /** fetch data from the table: \"supply\" */\n  supply: Array<Supply>;\n  /** fetch aggregated fields from the table: \"supply\" */\n  supply_aggregate: Supply_Aggregate;\n  /** fetch data from the table: \"supply\" using primary key columns */\n  supply_by_pk?: Maybe<Supply>;\n  /** fetch data from the table: \"test_gift\" */\n  test_gift: Array<Test_Gift>;\n  /** fetch aggregated fields from the table: \"test_gift\" */\n  test_gift_aggregate: Test_Gift_Aggregate;\n  /** fetch data from the table: \"today_top_txs\" */\n  today_top_txs: Array<Today_Top_Txs>;\n  /** fetch aggregated fields from the table: \"today_top_txs\" */\n  today_top_txs_aggregate: Today_Top_Txs_Aggregate;\n  /** fetch data from the table: \"top_10_of_active_neurons_week\" */\n  top_10_of_active_neurons_week: Array<Top_10_Of_Active_Neurons_Week>;\n  /** fetch aggregated fields from the table: \"top_10_of_active_neurons_week\" */\n  top_10_of_active_neurons_week_aggregate: Top_10_Of_Active_Neurons_Week_Aggregate;\n  /** fetch data from the table: \"top_first_txs\" */\n  top_first_txs: Array<Top_First_Txs>;\n  /** fetch aggregated fields from the table: \"top_first_txs\" */\n  top_first_txs_aggregate: Top_First_Txs_Aggregate;\n  /** fetch data from the table: \"top_leaders\" */\n  top_leaders: Array<Top_Leaders>;\n  /** fetch data from the table: \"top_txs\" */\n  top_txs: Array<Top_Txs>;\n  /** fetch aggregated fields from the table: \"top_txs\" */\n  top_txs_aggregate: Top_Txs_Aggregate;\n  /** fetch data from the table: \"transaction\" */\n  transaction: Array<Transaction>;\n  /** fetch aggregated fields from the table: \"transaction\" */\n  transaction_aggregate: Transaction_Aggregate;\n  /** fetch data from the table: \"transaction\" using primary key columns */\n  transaction_by_pk?: Maybe<Transaction>;\n  /** fetch data from the table: \"tweets_stats\" */\n  tweets_stats: Array<Tweets_Stats>;\n  /** fetch aggregated fields from the table: \"tweets_stats\" */\n  tweets_stats_aggregate: Tweets_Stats_Aggregate;\n  /** fetch data from the table: \"txs_ranked\" */\n  txs_ranked: Array<Txs_Ranked>;\n  /** fetch aggregated fields from the table: \"txs_ranked\" */\n  txs_ranked_aggregate: Txs_Ranked_Aggregate;\n  /** fetch data from the table: \"txs_stats\" */\n  txs_stats: Array<Txs_Stats>;\n  /** fetch aggregated fields from the table: \"txs_stats\" */\n  txs_stats_aggregate: Txs_Stats_Aggregate;\n  /** fetch data from the table: \"uptime\" */\n  uptime: Array<Uptime>;\n  /** fetch aggregated fields from the table: \"uptime\" */\n  uptime_aggregate: Uptime_Aggregate;\n  /** fetch data from the table: \"validator\" */\n  validator: Array<Validator>;\n  /** fetch aggregated fields from the table: \"validator\" */\n  validator_aggregate: Validator_Aggregate;\n  /** fetch data from the table: \"validator\" using primary key columns */\n  validator_by_pk?: Maybe<Validator>;\n  /** fetch data from the table: \"volts_demand\" */\n  volts_demand: Array<Volts_Demand>;\n  /** fetch aggregated fields from the table: \"volts_demand\" */\n  volts_demand_aggregate: Volts_Demand_Aggregate;\n  /** fetch data from the table: \"volts_stats\" */\n  volts_stats: Array<Volts_Stats>;\n  /** fetch aggregated fields from the table: \"volts_stats\" */\n  volts_stats_aggregate: Volts_Stats_Aggregate;\n};\n\n\nexport type Subscription_Root_TransactionArgs = {\n  distinct_on?: InputMaybe<Array<_Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Transaction_Order_By>>;\n  where?: InputMaybe<_Transaction_Bool_Exp>;\n};\n\n\nexport type Subscription_Root_Transaction_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<_Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Transaction_Order_By>>;\n  where?: InputMaybe<_Transaction_Bool_Exp>;\n};\n\n\nexport type Subscription_Root_Uptime_TempArgs = {\n  distinct_on?: InputMaybe<Array<_Uptime_Temp_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Uptime_Temp_Order_By>>;\n  where?: InputMaybe<_Uptime_Temp_Bool_Exp>;\n};\n\n\nexport type Subscription_Root_Uptime_Temp_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<_Uptime_Temp_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<_Uptime_Temp_Order_By>>;\n  where?: InputMaybe<_Uptime_Temp_Bool_Exp>;\n};\n\n\nexport type Subscription_RootAccountArgs = {\n  distinct_on?: InputMaybe<Array<Account_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Order_By>>;\n  where?: InputMaybe<Account_Bool_Exp>;\n};\n\n\nexport type Subscription_RootAccount_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Account_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Order_By>>;\n  where?: InputMaybe<Account_Bool_Exp>;\n};\n\n\nexport type Subscription_RootAccount_BalanceArgs = {\n  distinct_on?: InputMaybe<Array<Account_Balance_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Balance_Order_By>>;\n  where?: InputMaybe<Account_Balance_Bool_Exp>;\n};\n\n\nexport type Subscription_RootAccount_Balance_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Account_Balance_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Account_Balance_Order_By>>;\n  where?: InputMaybe<Account_Balance_Bool_Exp>;\n};\n\n\nexport type Subscription_RootAccount_Balance_By_PkArgs = {\n  address: Scalars['String']['input'];\n};\n\n\nexport type Subscription_RootAccount_By_PkArgs = {\n  address: Scalars['String']['input'];\n};\n\n\nexport type Subscription_RootBlockArgs = {\n  distinct_on?: InputMaybe<Array<Block_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Block_Order_By>>;\n  where?: InputMaybe<Block_Bool_Exp>;\n};\n\n\nexport type Subscription_RootBlock_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Block_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Block_Order_By>>;\n  where?: InputMaybe<Block_Bool_Exp>;\n};\n\n\nexport type Subscription_RootBlock_By_PkArgs = {\n  height: Scalars['bigint']['input'];\n};\n\n\nexport type Subscription_RootContractsArgs = {\n  distinct_on?: InputMaybe<Array<Contracts_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Contracts_Order_By>>;\n  where?: InputMaybe<Contracts_Bool_Exp>;\n};\n\n\nexport type Subscription_RootContracts_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Contracts_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Contracts_Order_By>>;\n  where?: InputMaybe<Contracts_Bool_Exp>;\n};\n\n\nexport type Subscription_RootContracts_By_PkArgs = {\n  address: Scalars['String']['input'];\n};\n\n\nexport type Subscription_RootCyb_CohortArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_Cohort_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyb_Cohort_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_Cohort_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyb_New_CohortArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_New_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_New_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_New_Cohort_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyb_New_Cohort_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyb_New_Cohort_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyb_New_Cohort_Order_By>>;\n  where?: InputMaybe<Cyb_New_Cohort_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyber_GiftArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyber_Gift_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyber_Gift_ProofsArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyber_Gift_Proofs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyber_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyber_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Cyber_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyberlinksArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyberlinks_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyberlinks_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Subscription_RootCyberlinks_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Stats_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootCyberlinks_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Stats_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootDaily_Amount_Of_Active_NeuronsArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Active_Neurons_Bool_Exp>;\n};\n\n\nexport type Subscription_RootDaily_Amount_Of_Active_Neurons_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Active_Neurons_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Active_Neurons_Bool_Exp>;\n};\n\n\nexport type Subscription_RootDaily_Amount_Of_Used_GasArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Used_Gas_Bool_Exp>;\n};\n\n\nexport type Subscription_RootDaily_Amount_Of_Used_Gas_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Amount_Of_Used_Gas_Order_By>>;\n  where?: InputMaybe<Daily_Amount_Of_Used_Gas_Bool_Exp>;\n};\n\n\nexport type Subscription_RootDaily_Number_Of_TransactionsArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Number_Of_Transactions_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Number_Of_Transactions_Order_By>>;\n  where?: InputMaybe<Daily_Number_Of_Transactions_Bool_Exp>;\n};\n\n\nexport type Subscription_RootDaily_Number_Of_Transactions_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Daily_Number_Of_Transactions_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Daily_Number_Of_Transactions_Order_By>>;\n  where?: InputMaybe<Daily_Number_Of_Transactions_Bool_Exp>;\n};\n\n\nexport type Subscription_RootFollow_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Follow_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Follow_Stats_Order_By>>;\n  where?: InputMaybe<Follow_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootFollow_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Follow_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Follow_Stats_Order_By>>;\n  where?: InputMaybe<Follow_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootGenesis_Neurons_ActivationArgs = {\n  distinct_on?: InputMaybe<Array<Genesis_Neurons_Activation_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Genesis_Neurons_Activation_Order_By>>;\n  where?: InputMaybe<Genesis_Neurons_Activation_Bool_Exp>;\n};\n\n\nexport type Subscription_RootGenesis_Neurons_Activation_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Genesis_Neurons_Activation_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Genesis_Neurons_Activation_Order_By>>;\n  where?: InputMaybe<Genesis_Neurons_Activation_Bool_Exp>;\n};\n\n\nexport type Subscription_RootInvestmintsArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\nexport type Subscription_RootInvestmints_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\nexport type Subscription_RootInvestmints_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Subscription_RootMessageArgs = {\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Subscription_RootMessage_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Subscription_RootMessages_By_AddressArgs = {\n  args: Messages_By_Address_Args;\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Subscription_RootMessages_By_Address_AggregateArgs = {\n  args: Messages_By_Address_Args;\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\nexport type Subscription_RootModulesArgs = {\n  distinct_on?: InputMaybe<Array<Modules_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Modules_Order_By>>;\n  where?: InputMaybe<Modules_Bool_Exp>;\n};\n\n\nexport type Subscription_RootModules_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Modules_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Modules_Order_By>>;\n  where?: InputMaybe<Modules_Bool_Exp>;\n};\n\n\nexport type Subscription_RootModules_By_PkArgs = {\n  module_name: Scalars['String']['input'];\n};\n\n\nexport type Subscription_RootNeuron_Activation_SourceArgs = {\n  distinct_on?: InputMaybe<Array<Neuron_Activation_Source_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Neuron_Activation_Source_Order_By>>;\n  where?: InputMaybe<Neuron_Activation_Source_Bool_Exp>;\n};\n\n\nexport type Subscription_RootNeuron_Activation_Source_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Neuron_Activation_Source_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Neuron_Activation_Source_Order_By>>;\n  where?: InputMaybe<Neuron_Activation_Source_Bool_Exp>;\n};\n\n\nexport type Subscription_RootNumber_Of_New_NeuronsArgs = {\n  distinct_on?: InputMaybe<Array<Number_Of_New_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Number_Of_New_Neurons_Order_By>>;\n  where?: InputMaybe<Number_Of_New_Neurons_Bool_Exp>;\n};\n\n\nexport type Subscription_RootNumber_Of_New_Neurons_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Number_Of_New_Neurons_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Number_Of_New_Neurons_Order_By>>;\n  where?: InputMaybe<Number_Of_New_Neurons_Bool_Exp>;\n};\n\n\nexport type Subscription_RootOld_PrecommitsArgs = {\n  distinct_on?: InputMaybe<Array<Old_Precommits_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Old_Precommits_Order_By>>;\n  where?: InputMaybe<Old_Precommits_Bool_Exp>;\n};\n\n\nexport type Subscription_RootOld_Precommits_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Old_Precommits_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Old_Precommits_Order_By>>;\n  where?: InputMaybe<Old_Precommits_Bool_Exp>;\n};\n\n\nexport type Subscription_RootOld_Precommits_By_PkArgs = {\n  consensus_address: Scalars['String']['input'];\n};\n\n\nexport type Subscription_RootParticlesArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\nexport type Subscription_RootParticles_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\nexport type Subscription_RootParticles_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Subscription_RootPre_CommitArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commit_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commit_Order_By>>;\n  where?: InputMaybe<Pre_Commit_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPre_Commit_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commit_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commit_Order_By>>;\n  where?: InputMaybe<Pre_Commit_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPre_Commits_Rewards_ViewArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Rewards_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Rewards_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Rewards_View_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPre_Commits_Rewards_View_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Rewards_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Rewards_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Rewards_View_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPre_Commits_TotalArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Total_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Total_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Total_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPre_Commits_Total_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_Total_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_Total_Order_By>>;\n  where?: InputMaybe<Pre_Commits_Total_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPre_Commits_ViewArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_View_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPre_Commits_View_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commits_View_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commits_View_Order_By>>;\n  where?: InputMaybe<Pre_Commits_View_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPruningArgs = {\n  distinct_on?: InputMaybe<Array<Pruning_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pruning_Order_By>>;\n  where?: InputMaybe<Pruning_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPruning_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pruning_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pruning_Order_By>>;\n  where?: InputMaybe<Pruning_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPussy_Gift_ProofsArgs = {\n  distinct_on?: InputMaybe<Array<Pussy_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pussy_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Pussy_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootPussy_Gift_Proofs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pussy_Gift_Proofs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pussy_Gift_Proofs_Order_By>>;\n  where?: InputMaybe<Pussy_Gift_Proofs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootRoutesArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\nexport type Subscription_RootRoutes_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\nexport type Subscription_RootRoutes_By_PkArgs = {\n  id: Scalars['Int']['input'];\n};\n\n\nexport type Subscription_RootSupplyArgs = {\n  distinct_on?: InputMaybe<Array<Supply_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Supply_Order_By>>;\n  where?: InputMaybe<Supply_Bool_Exp>;\n};\n\n\nexport type Subscription_RootSupply_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Supply_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Supply_Order_By>>;\n  where?: InputMaybe<Supply_Bool_Exp>;\n};\n\n\nexport type Subscription_RootSupply_By_PkArgs = {\n  one_row_id: Scalars['Boolean']['input'];\n};\n\n\nexport type Subscription_RootTest_GiftArgs = {\n  distinct_on?: InputMaybe<Array<Test_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Test_Gift_Order_By>>;\n  where?: InputMaybe<Test_Gift_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTest_Gift_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Test_Gift_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Test_Gift_Order_By>>;\n  where?: InputMaybe<Test_Gift_Bool_Exp>;\n};\n\n\nexport type Subscription_RootToday_Top_TxsArgs = {\n  distinct_on?: InputMaybe<Array<Today_Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Today_Top_Txs_Order_By>>;\n  where?: InputMaybe<Today_Top_Txs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootToday_Top_Txs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Today_Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Today_Top_Txs_Order_By>>;\n  where?: InputMaybe<Today_Top_Txs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTop_10_Of_Active_Neurons_WeekArgs = {\n  distinct_on?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Order_By>>;\n  where?: InputMaybe<Top_10_Of_Active_Neurons_Week_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTop_10_Of_Active_Neurons_Week_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Order_By>>;\n  where?: InputMaybe<Top_10_Of_Active_Neurons_Week_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTop_First_TxsArgs = {\n  distinct_on?: InputMaybe<Array<Top_First_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_First_Txs_Order_By>>;\n  where?: InputMaybe<Top_First_Txs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTop_First_Txs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Top_First_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_First_Txs_Order_By>>;\n  where?: InputMaybe<Top_First_Txs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTop_LeadersArgs = {\n  distinct_on?: InputMaybe<Array<Top_Leaders_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_Leaders_Order_By>>;\n  where?: InputMaybe<Top_Leaders_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTop_TxsArgs = {\n  distinct_on?: InputMaybe<Array<Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_Txs_Order_By>>;\n  where?: InputMaybe<Top_Txs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTop_Txs_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Top_Txs_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Top_Txs_Order_By>>;\n  where?: InputMaybe<Top_Txs_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTransactionArgs = {\n  distinct_on?: InputMaybe<Array<Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Transaction_Order_By>>;\n  where?: InputMaybe<Transaction_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTransaction_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Transaction_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Transaction_Order_By>>;\n  where?: InputMaybe<Transaction_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTransaction_By_PkArgs = {\n  hash: Scalars['String']['input'];\n};\n\n\nexport type Subscription_RootTweets_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Tweets_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Tweets_Stats_Order_By>>;\n  where?: InputMaybe<Tweets_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTweets_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Tweets_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Tweets_Stats_Order_By>>;\n  where?: InputMaybe<Tweets_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTxs_RankedArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Ranked_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Ranked_Order_By>>;\n  where?: InputMaybe<Txs_Ranked_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTxs_Ranked_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Ranked_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Ranked_Order_By>>;\n  where?: InputMaybe<Txs_Ranked_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTxs_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Stats_Order_By>>;\n  where?: InputMaybe<Txs_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootTxs_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Txs_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Txs_Stats_Order_By>>;\n  where?: InputMaybe<Txs_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootUptimeArgs = {\n  distinct_on?: InputMaybe<Array<Uptime_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Uptime_Order_By>>;\n  where?: InputMaybe<Uptime_Bool_Exp>;\n};\n\n\nexport type Subscription_RootUptime_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Uptime_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Uptime_Order_By>>;\n  where?: InputMaybe<Uptime_Bool_Exp>;\n};\n\n\nexport type Subscription_RootValidatorArgs = {\n  distinct_on?: InputMaybe<Array<Validator_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Validator_Order_By>>;\n  where?: InputMaybe<Validator_Bool_Exp>;\n};\n\n\nexport type Subscription_RootValidator_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Validator_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Validator_Order_By>>;\n  where?: InputMaybe<Validator_Bool_Exp>;\n};\n\n\nexport type Subscription_RootValidator_By_PkArgs = {\n  consensus_address: Scalars['String']['input'];\n};\n\n\nexport type Subscription_RootVolts_DemandArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Demand_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Demand_Order_By>>;\n  where?: InputMaybe<Volts_Demand_Bool_Exp>;\n};\n\n\nexport type Subscription_RootVolts_Demand_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Demand_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Demand_Order_By>>;\n  where?: InputMaybe<Volts_Demand_Bool_Exp>;\n};\n\n\nexport type Subscription_RootVolts_StatsArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Stats_Order_By>>;\n  where?: InputMaybe<Volts_Stats_Bool_Exp>;\n};\n\n\nexport type Subscription_RootVolts_Stats_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Volts_Stats_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Volts_Stats_Order_By>>;\n  where?: InputMaybe<Volts_Stats_Bool_Exp>;\n};\n\n/** columns and relationships of \"supply\" */\nexport type Supply = {\n  coins: Scalars['_coin']['output'];\n  height: Scalars['bigint']['output'];\n  one_row_id: Scalars['Boolean']['output'];\n};\n\n/** aggregated selection of \"supply\" */\nexport type Supply_Aggregate = {\n  aggregate?: Maybe<Supply_Aggregate_Fields>;\n  nodes: Array<Supply>;\n};\n\n/** aggregate fields of \"supply\" */\nexport type Supply_Aggregate_Fields = {\n  avg?: Maybe<Supply_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Supply_Max_Fields>;\n  min?: Maybe<Supply_Min_Fields>;\n  stddev?: Maybe<Supply_Stddev_Fields>;\n  stddev_pop?: Maybe<Supply_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Supply_Stddev_Samp_Fields>;\n  sum?: Maybe<Supply_Sum_Fields>;\n  var_pop?: Maybe<Supply_Var_Pop_Fields>;\n  var_samp?: Maybe<Supply_Var_Samp_Fields>;\n  variance?: Maybe<Supply_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"supply\" */\nexport type Supply_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Supply_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Supply_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"supply\". All fields are combined with a logical 'AND'. */\nexport type Supply_Bool_Exp = {\n  _and?: InputMaybe<Array<Supply_Bool_Exp>>;\n  _not?: InputMaybe<Supply_Bool_Exp>;\n  _or?: InputMaybe<Array<Supply_Bool_Exp>>;\n  coins?: InputMaybe<_Coin_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  one_row_id?: InputMaybe<Boolean_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Supply_Max_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Supply_Min_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** Ordering options when selecting data from \"supply\". */\nexport type Supply_Order_By = {\n  coins?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  one_row_id?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"supply\" */\nexport enum Supply_Select_Column {\n  /** column name */\n  Coins = 'coins',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  OneRowId = 'one_row_id'\n}\n\n/** aggregate stddev on columns */\nexport type Supply_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Supply_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Supply_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Supply_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Supply_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Supply_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Supply_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"test_gift\" */\nexport type Test_Gift = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  details?: Maybe<Scalars['json']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n\n/** columns and relationships of \"test_gift\" */\nexport type Test_GiftDetailsArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n/** aggregated selection of \"test_gift\" */\nexport type Test_Gift_Aggregate = {\n  aggregate?: Maybe<Test_Gift_Aggregate_Fields>;\n  nodes: Array<Test_Gift>;\n};\n\n/** aggregate fields of \"test_gift\" */\nexport type Test_Gift_Aggregate_Fields = {\n  avg?: Maybe<Test_Gift_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Test_Gift_Max_Fields>;\n  min?: Maybe<Test_Gift_Min_Fields>;\n  stddev?: Maybe<Test_Gift_Stddev_Fields>;\n  stddev_pop?: Maybe<Test_Gift_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Test_Gift_Stddev_Samp_Fields>;\n  sum?: Maybe<Test_Gift_Sum_Fields>;\n  var_pop?: Maybe<Test_Gift_Var_Pop_Fields>;\n  var_samp?: Maybe<Test_Gift_Var_Samp_Fields>;\n  variance?: Maybe<Test_Gift_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"test_gift\" */\nexport type Test_Gift_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Test_Gift_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Test_Gift_Avg_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"test_gift\". All fields are combined with a logical 'AND'. */\nexport type Test_Gift_Bool_Exp = {\n  _and?: InputMaybe<Array<Test_Gift_Bool_Exp>>;\n  _not?: InputMaybe<Test_Gift_Bool_Exp>;\n  _or?: InputMaybe<Array<Test_Gift_Bool_Exp>>;\n  address?: InputMaybe<String_Comparison_Exp>;\n  amount?: InputMaybe<Bigint_Comparison_Exp>;\n  details?: InputMaybe<Json_Comparison_Exp>;\n  proof?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Test_Gift_Max_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Test_Gift_Min_Fields = {\n  address?: Maybe<Scalars['String']['output']>;\n  amount?: Maybe<Scalars['bigint']['output']>;\n  proof?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"test_gift\". */\nexport type Test_Gift_Order_By = {\n  address?: InputMaybe<Order_By>;\n  amount?: InputMaybe<Order_By>;\n  details?: InputMaybe<Order_By>;\n  proof?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"test_gift\" */\nexport enum Test_Gift_Select_Column {\n  /** column name */\n  Address = 'address',\n  /** column name */\n  Amount = 'amount',\n  /** column name */\n  Details = 'details',\n  /** column name */\n  Proof = 'proof'\n}\n\n/** aggregate stddev on columns */\nexport type Test_Gift_Stddev_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Test_Gift_Stddev_Pop_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Test_Gift_Stddev_Samp_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Test_Gift_Sum_Fields = {\n  amount?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Test_Gift_Var_Pop_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Test_Gift_Var_Samp_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Test_Gift_Variance_Fields = {\n  amount?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to compare columns of type \"timestamp\". All fields are combined with logical 'AND'. */\nexport type Timestamp_Comparison_Exp = {\n  _eq?: InputMaybe<Scalars['timestamp']['input']>;\n  _gt?: InputMaybe<Scalars['timestamp']['input']>;\n  _gte?: InputMaybe<Scalars['timestamp']['input']>;\n  _in?: InputMaybe<Array<Scalars['timestamp']['input']>>;\n  _is_null?: InputMaybe<Scalars['Boolean']['input']>;\n  _lt?: InputMaybe<Scalars['timestamp']['input']>;\n  _lte?: InputMaybe<Scalars['timestamp']['input']>;\n  _neq?: InputMaybe<Scalars['timestamp']['input']>;\n  _nin?: InputMaybe<Array<Scalars['timestamp']['input']>>;\n};\n\n/** columns and relationships of \"today_top_txs\" */\nexport type Today_Top_Txs = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregated selection of \"today_top_txs\" */\nexport type Today_Top_Txs_Aggregate = {\n  aggregate?: Maybe<Today_Top_Txs_Aggregate_Fields>;\n  nodes: Array<Today_Top_Txs>;\n};\n\n/** aggregate fields of \"today_top_txs\" */\nexport type Today_Top_Txs_Aggregate_Fields = {\n  avg?: Maybe<Today_Top_Txs_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Today_Top_Txs_Max_Fields>;\n  min?: Maybe<Today_Top_Txs_Min_Fields>;\n  stddev?: Maybe<Today_Top_Txs_Stddev_Fields>;\n  stddev_pop?: Maybe<Today_Top_Txs_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Today_Top_Txs_Stddev_Samp_Fields>;\n  sum?: Maybe<Today_Top_Txs_Sum_Fields>;\n  var_pop?: Maybe<Today_Top_Txs_Var_Pop_Fields>;\n  var_samp?: Maybe<Today_Top_Txs_Var_Samp_Fields>;\n  variance?: Maybe<Today_Top_Txs_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"today_top_txs\" */\nexport type Today_Top_Txs_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Today_Top_Txs_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Today_Top_Txs_Avg_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"today_top_txs\". All fields are combined with a logical 'AND'. */\nexport type Today_Top_Txs_Bool_Exp = {\n  _and?: InputMaybe<Array<Today_Top_Txs_Bool_Exp>>;\n  _not?: InputMaybe<Today_Top_Txs_Bool_Exp>;\n  _or?: InputMaybe<Array<Today_Top_Txs_Bool_Exp>>;\n  count?: InputMaybe<Bigint_Comparison_Exp>;\n  type?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Today_Top_Txs_Max_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Today_Top_Txs_Min_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"today_top_txs\". */\nexport type Today_Top_Txs_Order_By = {\n  count?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"today_top_txs\" */\nexport enum Today_Top_Txs_Select_Column {\n  /** column name */\n  Count = 'count',\n  /** column name */\n  Type = 'type'\n}\n\n/** aggregate stddev on columns */\nexport type Today_Top_Txs_Stddev_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Today_Top_Txs_Stddev_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Today_Top_Txs_Stddev_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Today_Top_Txs_Sum_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Today_Top_Txs_Var_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Today_Top_Txs_Var_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Today_Top_Txs_Variance_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"top_10_of_active_neurons_week\" */\nexport type Top_10_Of_Active_Neurons_Week = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  pubkey?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregated selection of \"top_10_of_active_neurons_week\" */\nexport type Top_10_Of_Active_Neurons_Week_Aggregate = {\n  aggregate?: Maybe<Top_10_Of_Active_Neurons_Week_Aggregate_Fields>;\n  nodes: Array<Top_10_Of_Active_Neurons_Week>;\n};\n\n/** aggregate fields of \"top_10_of_active_neurons_week\" */\nexport type Top_10_Of_Active_Neurons_Week_Aggregate_Fields = {\n  avg?: Maybe<Top_10_Of_Active_Neurons_Week_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Top_10_Of_Active_Neurons_Week_Max_Fields>;\n  min?: Maybe<Top_10_Of_Active_Neurons_Week_Min_Fields>;\n  stddev?: Maybe<Top_10_Of_Active_Neurons_Week_Stddev_Fields>;\n  stddev_pop?: Maybe<Top_10_Of_Active_Neurons_Week_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Top_10_Of_Active_Neurons_Week_Stddev_Samp_Fields>;\n  sum?: Maybe<Top_10_Of_Active_Neurons_Week_Sum_Fields>;\n  var_pop?: Maybe<Top_10_Of_Active_Neurons_Week_Var_Pop_Fields>;\n  var_samp?: Maybe<Top_10_Of_Active_Neurons_Week_Var_Samp_Fields>;\n  variance?: Maybe<Top_10_Of_Active_Neurons_Week_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"top_10_of_active_neurons_week\" */\nexport type Top_10_Of_Active_Neurons_Week_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Top_10_Of_Active_Neurons_Week_Avg_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"top_10_of_active_neurons_week\". All fields are combined with a logical 'AND'. */\nexport type Top_10_Of_Active_Neurons_Week_Bool_Exp = {\n  _and?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Bool_Exp>>;\n  _not?: InputMaybe<Top_10_Of_Active_Neurons_Week_Bool_Exp>;\n  _or?: InputMaybe<Array<Top_10_Of_Active_Neurons_Week_Bool_Exp>>;\n  count?: InputMaybe<Bigint_Comparison_Exp>;\n  pubkey?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Top_10_Of_Active_Neurons_Week_Max_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  pubkey?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Top_10_Of_Active_Neurons_Week_Min_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  pubkey?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"top_10_of_active_neurons_week\". */\nexport type Top_10_Of_Active_Neurons_Week_Order_By = {\n  count?: InputMaybe<Order_By>;\n  pubkey?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"top_10_of_active_neurons_week\" */\nexport enum Top_10_Of_Active_Neurons_Week_Select_Column {\n  /** column name */\n  Count = 'count',\n  /** column name */\n  Pubkey = 'pubkey'\n}\n\n/** aggregate stddev on columns */\nexport type Top_10_Of_Active_Neurons_Week_Stddev_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Top_10_Of_Active_Neurons_Week_Stddev_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Top_10_Of_Active_Neurons_Week_Stddev_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Top_10_Of_Active_Neurons_Week_Sum_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Top_10_Of_Active_Neurons_Week_Var_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Top_10_Of_Active_Neurons_Week_Var_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Top_10_Of_Active_Neurons_Week_Variance_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"top_first_txs\" */\nexport type Top_First_Txs = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregated selection of \"top_first_txs\" */\nexport type Top_First_Txs_Aggregate = {\n  aggregate?: Maybe<Top_First_Txs_Aggregate_Fields>;\n  nodes: Array<Top_First_Txs>;\n};\n\n/** aggregate fields of \"top_first_txs\" */\nexport type Top_First_Txs_Aggregate_Fields = {\n  avg?: Maybe<Top_First_Txs_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Top_First_Txs_Max_Fields>;\n  min?: Maybe<Top_First_Txs_Min_Fields>;\n  stddev?: Maybe<Top_First_Txs_Stddev_Fields>;\n  stddev_pop?: Maybe<Top_First_Txs_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Top_First_Txs_Stddev_Samp_Fields>;\n  sum?: Maybe<Top_First_Txs_Sum_Fields>;\n  var_pop?: Maybe<Top_First_Txs_Var_Pop_Fields>;\n  var_samp?: Maybe<Top_First_Txs_Var_Samp_Fields>;\n  variance?: Maybe<Top_First_Txs_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"top_first_txs\" */\nexport type Top_First_Txs_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Top_First_Txs_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Top_First_Txs_Avg_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"top_first_txs\". All fields are combined with a logical 'AND'. */\nexport type Top_First_Txs_Bool_Exp = {\n  _and?: InputMaybe<Array<Top_First_Txs_Bool_Exp>>;\n  _not?: InputMaybe<Top_First_Txs_Bool_Exp>;\n  _or?: InputMaybe<Array<Top_First_Txs_Bool_Exp>>;\n  count?: InputMaybe<Bigint_Comparison_Exp>;\n  type?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Top_First_Txs_Max_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Top_First_Txs_Min_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"top_first_txs\". */\nexport type Top_First_Txs_Order_By = {\n  count?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"top_first_txs\" */\nexport enum Top_First_Txs_Select_Column {\n  /** column name */\n  Count = 'count',\n  /** column name */\n  Type = 'type'\n}\n\n/** aggregate stddev on columns */\nexport type Top_First_Txs_Stddev_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Top_First_Txs_Stddev_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Top_First_Txs_Stddev_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Top_First_Txs_Sum_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Top_First_Txs_Var_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Top_First_Txs_Var_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Top_First_Txs_Variance_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"top_leaders\" */\nexport type Top_Leaders = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"top_leaders\". All fields are combined with a logical 'AND'. */\nexport type Top_Leaders_Bool_Exp = {\n  _and?: InputMaybe<Array<Top_Leaders_Bool_Exp>>;\n  _not?: InputMaybe<Top_Leaders_Bool_Exp>;\n  _or?: InputMaybe<Array<Top_Leaders_Bool_Exp>>;\n  count?: InputMaybe<Bigint_Comparison_Exp>;\n  neuron?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** Ordering options when selecting data from \"top_leaders\". */\nexport type Top_Leaders_Order_By = {\n  count?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"top_leaders\" */\nexport enum Top_Leaders_Select_Column {\n  /** column name */\n  Count = 'count',\n  /** column name */\n  Neuron = 'neuron'\n}\n\n/** columns and relationships of \"top_txs\" */\nexport type Top_Txs = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregated selection of \"top_txs\" */\nexport type Top_Txs_Aggregate = {\n  aggregate?: Maybe<Top_Txs_Aggregate_Fields>;\n  nodes: Array<Top_Txs>;\n};\n\n/** aggregate fields of \"top_txs\" */\nexport type Top_Txs_Aggregate_Fields = {\n  avg?: Maybe<Top_Txs_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Top_Txs_Max_Fields>;\n  min?: Maybe<Top_Txs_Min_Fields>;\n  stddev?: Maybe<Top_Txs_Stddev_Fields>;\n  stddev_pop?: Maybe<Top_Txs_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Top_Txs_Stddev_Samp_Fields>;\n  sum?: Maybe<Top_Txs_Sum_Fields>;\n  var_pop?: Maybe<Top_Txs_Var_Pop_Fields>;\n  var_samp?: Maybe<Top_Txs_Var_Samp_Fields>;\n  variance?: Maybe<Top_Txs_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"top_txs\" */\nexport type Top_Txs_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Top_Txs_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Top_Txs_Avg_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"top_txs\". All fields are combined with a logical 'AND'. */\nexport type Top_Txs_Bool_Exp = {\n  _and?: InputMaybe<Array<Top_Txs_Bool_Exp>>;\n  _not?: InputMaybe<Top_Txs_Bool_Exp>;\n  _or?: InputMaybe<Array<Top_Txs_Bool_Exp>>;\n  count?: InputMaybe<Bigint_Comparison_Exp>;\n  type?: InputMaybe<String_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Top_Txs_Max_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Top_Txs_Min_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"top_txs\". */\nexport type Top_Txs_Order_By = {\n  count?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"top_txs\" */\nexport enum Top_Txs_Select_Column {\n  /** column name */\n  Count = 'count',\n  /** column name */\n  Type = 'type'\n}\n\n/** aggregate stddev on columns */\nexport type Top_Txs_Stddev_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Top_Txs_Stddev_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Top_Txs_Stddev_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Top_Txs_Sum_Fields = {\n  count?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Top_Txs_Var_Pop_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Top_Txs_Var_Samp_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Top_Txs_Variance_Fields = {\n  count?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"transaction\" */\nexport type Transaction = {\n  /** An object relationship */\n  block: Block;\n  /** fetch data from the table: \"cyberlinks\" */\n  cyberlinks: Array<Cyberlinks>;\n  /** An aggregate relationship */\n  cyberlinks_aggregate: Cyberlinks_Aggregate;\n  fee: Scalars['jsonb']['output'];\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  hash: Scalars['String']['output'];\n  height: Scalars['bigint']['output'];\n  /** An array relationship */\n  investmints: Array<Investmints>;\n  /** An aggregate relationship */\n  investmints_aggregate: Investmints_Aggregate;\n  logs?: Maybe<Scalars['jsonb']['output']>;\n  memo?: Maybe<Scalars['String']['output']>;\n  messages: Scalars['jsonb']['output'];\n  /** An array relationship */\n  messagesByTransactionHash: Array<Message>;\n  /** An aggregate relationship */\n  messagesByTransactionHash_aggregate: Message_Aggregate;\n  /** An array relationship */\n  particles: Array<Particles>;\n  /** An aggregate relationship */\n  particles_aggregate: Particles_Aggregate;\n  raw_log?: Maybe<Scalars['String']['output']>;\n  /** An array relationship */\n  routes: Array<Routes>;\n  /** An aggregate relationship */\n  routes_aggregate: Routes_Aggregate;\n  signatures: Scalars['_text']['output'];\n  signer_infos: Scalars['jsonb']['output'];\n  success: Scalars['Boolean']['output'];\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionCyberlinksArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionCyberlinks_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Cyberlinks_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Cyberlinks_Order_By>>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionFeeArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionInvestmintsArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionInvestmints_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Investmints_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Investmints_Order_By>>;\n  where?: InputMaybe<Investmints_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionLogsArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionMessagesArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionMessagesByTransactionHashArgs = {\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionMessagesByTransactionHash_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Message_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Message_Order_By>>;\n  where?: InputMaybe<Message_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionParticlesArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionParticles_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Particles_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Particles_Order_By>>;\n  where?: InputMaybe<Particles_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionRoutesArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionRoutes_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Routes_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Routes_Order_By>>;\n  where?: InputMaybe<Routes_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"transaction\" */\nexport type TransactionSigner_InfosArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n/** aggregated selection of \"transaction\" */\nexport type Transaction_Aggregate = {\n  aggregate?: Maybe<Transaction_Aggregate_Fields>;\n  nodes: Array<Transaction>;\n};\n\n/** aggregate fields of \"transaction\" */\nexport type Transaction_Aggregate_Fields = {\n  avg?: Maybe<Transaction_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Transaction_Max_Fields>;\n  min?: Maybe<Transaction_Min_Fields>;\n  stddev?: Maybe<Transaction_Stddev_Fields>;\n  stddev_pop?: Maybe<Transaction_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Transaction_Stddev_Samp_Fields>;\n  sum?: Maybe<Transaction_Sum_Fields>;\n  var_pop?: Maybe<Transaction_Var_Pop_Fields>;\n  var_samp?: Maybe<Transaction_Var_Samp_Fields>;\n  variance?: Maybe<Transaction_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"transaction\" */\nexport type Transaction_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Transaction_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** order by aggregate values of table \"transaction\" */\nexport type Transaction_Aggregate_Order_By = {\n  avg?: InputMaybe<Transaction_Avg_Order_By>;\n  count?: InputMaybe<Order_By>;\n  max?: InputMaybe<Transaction_Max_Order_By>;\n  min?: InputMaybe<Transaction_Min_Order_By>;\n  stddev?: InputMaybe<Transaction_Stddev_Order_By>;\n  stddev_pop?: InputMaybe<Transaction_Stddev_Pop_Order_By>;\n  stddev_samp?: InputMaybe<Transaction_Stddev_Samp_Order_By>;\n  sum?: InputMaybe<Transaction_Sum_Order_By>;\n  var_pop?: InputMaybe<Transaction_Var_Pop_Order_By>;\n  var_samp?: InputMaybe<Transaction_Var_Samp_Order_By>;\n  variance?: InputMaybe<Transaction_Variance_Order_By>;\n};\n\n/** aggregate avg on columns */\nexport type Transaction_Avg_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by avg() on columns of table \"transaction\" */\nexport type Transaction_Avg_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** Boolean expression to filter rows from the table \"transaction\". All fields are combined with a logical 'AND'. */\nexport type Transaction_Bool_Exp = {\n  _and?: InputMaybe<Array<Transaction_Bool_Exp>>;\n  _not?: InputMaybe<Transaction_Bool_Exp>;\n  _or?: InputMaybe<Array<Transaction_Bool_Exp>>;\n  block?: InputMaybe<Block_Bool_Exp>;\n  cyberlinks?: InputMaybe<Cyberlinks_Bool_Exp>;\n  fee?: InputMaybe<Jsonb_Comparison_Exp>;\n  gas_used?: InputMaybe<Bigint_Comparison_Exp>;\n  gas_wanted?: InputMaybe<Bigint_Comparison_Exp>;\n  hash?: InputMaybe<String_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  investmints?: InputMaybe<Investmints_Bool_Exp>;\n  logs?: InputMaybe<Jsonb_Comparison_Exp>;\n  memo?: InputMaybe<String_Comparison_Exp>;\n  messages?: InputMaybe<Jsonb_Comparison_Exp>;\n  messagesByTransactionHash?: InputMaybe<Message_Bool_Exp>;\n  particles?: InputMaybe<Particles_Bool_Exp>;\n  raw_log?: InputMaybe<String_Comparison_Exp>;\n  routes?: InputMaybe<Routes_Bool_Exp>;\n  signatures?: InputMaybe<_Text_Comparison_Exp>;\n  signer_infos?: InputMaybe<Jsonb_Comparison_Exp>;\n  success?: InputMaybe<Boolean_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Transaction_Max_Fields = {\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  hash?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  memo?: Maybe<Scalars['String']['output']>;\n  raw_log?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by max() on columns of table \"transaction\" */\nexport type Transaction_Max_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  hash?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  memo?: InputMaybe<Order_By>;\n  raw_log?: InputMaybe<Order_By>;\n};\n\n/** aggregate min on columns */\nexport type Transaction_Min_Fields = {\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  hash?: Maybe<Scalars['String']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  memo?: Maybe<Scalars['String']['output']>;\n  raw_log?: Maybe<Scalars['String']['output']>;\n};\n\n/** order by min() on columns of table \"transaction\" */\nexport type Transaction_Min_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  hash?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  memo?: InputMaybe<Order_By>;\n  raw_log?: InputMaybe<Order_By>;\n};\n\n/** Ordering options when selecting data from \"transaction\". */\nexport type Transaction_Order_By = {\n  block?: InputMaybe<Block_Order_By>;\n  cyberlinks_aggregate?: InputMaybe<Cyberlinks_Aggregate_Order_By>;\n  fee?: InputMaybe<Order_By>;\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  hash?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  investmints_aggregate?: InputMaybe<Investmints_Aggregate_Order_By>;\n  logs?: InputMaybe<Order_By>;\n  memo?: InputMaybe<Order_By>;\n  messages?: InputMaybe<Order_By>;\n  messagesByTransactionHash_aggregate?: InputMaybe<Message_Aggregate_Order_By>;\n  particles_aggregate?: InputMaybe<Particles_Aggregate_Order_By>;\n  raw_log?: InputMaybe<Order_By>;\n  routes_aggregate?: InputMaybe<Routes_Aggregate_Order_By>;\n  signatures?: InputMaybe<Order_By>;\n  signer_infos?: InputMaybe<Order_By>;\n  success?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"transaction\" */\nexport enum Transaction_Select_Column {\n  /** column name */\n  Fee = 'fee',\n  /** column name */\n  GasUsed = 'gas_used',\n  /** column name */\n  GasWanted = 'gas_wanted',\n  /** column name */\n  Hash = 'hash',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Logs = 'logs',\n  /** column name */\n  Memo = 'memo',\n  /** column name */\n  Messages = 'messages',\n  /** column name */\n  RawLog = 'raw_log',\n  /** column name */\n  Signatures = 'signatures',\n  /** column name */\n  SignerInfos = 'signer_infos',\n  /** column name */\n  Success = 'success'\n}\n\n/** aggregate stddev on columns */\nexport type Transaction_Stddev_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev() on columns of table \"transaction\" */\nexport type Transaction_Stddev_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Transaction_Stddev_Pop_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_pop() on columns of table \"transaction\" */\nexport type Transaction_Stddev_Pop_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Transaction_Stddev_Samp_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by stddev_samp() on columns of table \"transaction\" */\nexport type Transaction_Stddev_Samp_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** aggregate sum on columns */\nexport type Transaction_Sum_Fields = {\n  gas_used?: Maybe<Scalars['bigint']['output']>;\n  gas_wanted?: Maybe<Scalars['bigint']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** order by sum() on columns of table \"transaction\" */\nexport type Transaction_Sum_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_pop on columns */\nexport type Transaction_Var_Pop_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_pop() on columns of table \"transaction\" */\nexport type Transaction_Var_Pop_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** aggregate var_samp on columns */\nexport type Transaction_Var_Samp_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by var_samp() on columns of table \"transaction\" */\nexport type Transaction_Var_Samp_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** aggregate variance on columns */\nexport type Transaction_Variance_Fields = {\n  gas_used?: Maybe<Scalars['Float']['output']>;\n  gas_wanted?: Maybe<Scalars['Float']['output']>;\n  height?: Maybe<Scalars['Float']['output']>;\n};\n\n/** order by variance() on columns of table \"transaction\" */\nexport type Transaction_Variance_Order_By = {\n  gas_used?: InputMaybe<Order_By>;\n  gas_wanted?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n};\n\n/** columns and relationships of \"tweets_stats\" */\nexport type Tweets_Stats = {\n  date?: Maybe<Scalars['date']['output']>;\n  tweets?: Maybe<Scalars['numeric']['output']>;\n  tweets_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregated selection of \"tweets_stats\" */\nexport type Tweets_Stats_Aggregate = {\n  aggregate?: Maybe<Tweets_Stats_Aggregate_Fields>;\n  nodes: Array<Tweets_Stats>;\n};\n\n/** aggregate fields of \"tweets_stats\" */\nexport type Tweets_Stats_Aggregate_Fields = {\n  avg?: Maybe<Tweets_Stats_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Tweets_Stats_Max_Fields>;\n  min?: Maybe<Tweets_Stats_Min_Fields>;\n  stddev?: Maybe<Tweets_Stats_Stddev_Fields>;\n  stddev_pop?: Maybe<Tweets_Stats_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Tweets_Stats_Stddev_Samp_Fields>;\n  sum?: Maybe<Tweets_Stats_Sum_Fields>;\n  var_pop?: Maybe<Tweets_Stats_Var_Pop_Fields>;\n  var_samp?: Maybe<Tweets_Stats_Var_Samp_Fields>;\n  variance?: Maybe<Tweets_Stats_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"tweets_stats\" */\nexport type Tweets_Stats_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Tweets_Stats_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Tweets_Stats_Avg_Fields = {\n  tweets?: Maybe<Scalars['Float']['output']>;\n  tweets_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"tweets_stats\". All fields are combined with a logical 'AND'. */\nexport type Tweets_Stats_Bool_Exp = {\n  _and?: InputMaybe<Array<Tweets_Stats_Bool_Exp>>;\n  _not?: InputMaybe<Tweets_Stats_Bool_Exp>;\n  _or?: InputMaybe<Array<Tweets_Stats_Bool_Exp>>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  tweets?: InputMaybe<Numeric_Comparison_Exp>;\n  tweets_per_day?: InputMaybe<Bigint_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Tweets_Stats_Max_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  tweets?: Maybe<Scalars['numeric']['output']>;\n  tweets_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Tweets_Stats_Min_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  tweets?: Maybe<Scalars['numeric']['output']>;\n  tweets_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** Ordering options when selecting data from \"tweets_stats\". */\nexport type Tweets_Stats_Order_By = {\n  date?: InputMaybe<Order_By>;\n  tweets?: InputMaybe<Order_By>;\n  tweets_per_day?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"tweets_stats\" */\nexport enum Tweets_Stats_Select_Column {\n  /** column name */\n  Date = 'date',\n  /** column name */\n  Tweets = 'tweets',\n  /** column name */\n  TweetsPerDay = 'tweets_per_day'\n}\n\n/** aggregate stddev on columns */\nexport type Tweets_Stats_Stddev_Fields = {\n  tweets?: Maybe<Scalars['Float']['output']>;\n  tweets_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Tweets_Stats_Stddev_Pop_Fields = {\n  tweets?: Maybe<Scalars['Float']['output']>;\n  tweets_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Tweets_Stats_Stddev_Samp_Fields = {\n  tweets?: Maybe<Scalars['Float']['output']>;\n  tweets_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Tweets_Stats_Sum_Fields = {\n  tweets?: Maybe<Scalars['numeric']['output']>;\n  tweets_per_day?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Tweets_Stats_Var_Pop_Fields = {\n  tweets?: Maybe<Scalars['Float']['output']>;\n  tweets_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Tweets_Stats_Var_Samp_Fields = {\n  tweets?: Maybe<Scalars['Float']['output']>;\n  tweets_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Tweets_Stats_Variance_Fields = {\n  tweets?: Maybe<Scalars['Float']['output']>;\n  tweets_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"txs_ranked\" */\nexport type Txs_Ranked = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregated selection of \"txs_ranked\" */\nexport type Txs_Ranked_Aggregate = {\n  aggregate?: Maybe<Txs_Ranked_Aggregate_Fields>;\n  nodes: Array<Txs_Ranked>;\n};\n\n/** aggregate fields of \"txs_ranked\" */\nexport type Txs_Ranked_Aggregate_Fields = {\n  avg?: Maybe<Txs_Ranked_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Txs_Ranked_Max_Fields>;\n  min?: Maybe<Txs_Ranked_Min_Fields>;\n  stddev?: Maybe<Txs_Ranked_Stddev_Fields>;\n  stddev_pop?: Maybe<Txs_Ranked_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Txs_Ranked_Stddev_Samp_Fields>;\n  sum?: Maybe<Txs_Ranked_Sum_Fields>;\n  var_pop?: Maybe<Txs_Ranked_Var_Pop_Fields>;\n  var_samp?: Maybe<Txs_Ranked_Var_Samp_Fields>;\n  variance?: Maybe<Txs_Ranked_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"txs_ranked\" */\nexport type Txs_Ranked_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Txs_Ranked_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Txs_Ranked_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"txs_ranked\". All fields are combined with a logical 'AND'. */\nexport type Txs_Ranked_Bool_Exp = {\n  _and?: InputMaybe<Array<Txs_Ranked_Bool_Exp>>;\n  _not?: InputMaybe<Txs_Ranked_Bool_Exp>;\n  _or?: InputMaybe<Array<Txs_Ranked_Bool_Exp>>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  neuron?: InputMaybe<String_Comparison_Exp>;\n  rank?: InputMaybe<Bigint_Comparison_Exp>;\n  type?: InputMaybe<String_Comparison_Exp>;\n  week?: InputMaybe<Date_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Txs_Ranked_Max_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Txs_Ranked_Min_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  neuron?: Maybe<Scalars['String']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n  type?: Maybe<Scalars['String']['output']>;\n  week?: Maybe<Scalars['date']['output']>;\n};\n\n/** Ordering options when selecting data from \"txs_ranked\". */\nexport type Txs_Ranked_Order_By = {\n  height?: InputMaybe<Order_By>;\n  neuron?: InputMaybe<Order_By>;\n  rank?: InputMaybe<Order_By>;\n  type?: InputMaybe<Order_By>;\n  week?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"txs_ranked\" */\nexport enum Txs_Ranked_Select_Column {\n  /** column name */\n  Height = 'height',\n  /** column name */\n  Neuron = 'neuron',\n  /** column name */\n  Rank = 'rank',\n  /** column name */\n  Type = 'type',\n  /** column name */\n  Week = 'week'\n}\n\n/** aggregate stddev on columns */\nexport type Txs_Ranked_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Txs_Ranked_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Txs_Ranked_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Txs_Ranked_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Txs_Ranked_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Txs_Ranked_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Txs_Ranked_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"txs_stats\" */\nexport type Txs_Stats = {\n  date?: Maybe<Scalars['date']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  msg_type?: Maybe<Scalars['String']['output']>;\n  pubkey?: Maybe<Scalars['jsonb']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n};\n\n\n/** columns and relationships of \"txs_stats\" */\nexport type Txs_StatsPubkeyArgs = {\n  path?: InputMaybe<Scalars['String']['input']>;\n};\n\n/** aggregated selection of \"txs_stats\" */\nexport type Txs_Stats_Aggregate = {\n  aggregate?: Maybe<Txs_Stats_Aggregate_Fields>;\n  nodes: Array<Txs_Stats>;\n};\n\n/** aggregate fields of \"txs_stats\" */\nexport type Txs_Stats_Aggregate_Fields = {\n  avg?: Maybe<Txs_Stats_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Txs_Stats_Max_Fields>;\n  min?: Maybe<Txs_Stats_Min_Fields>;\n  stddev?: Maybe<Txs_Stats_Stddev_Fields>;\n  stddev_pop?: Maybe<Txs_Stats_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Txs_Stats_Stddev_Samp_Fields>;\n  sum?: Maybe<Txs_Stats_Sum_Fields>;\n  var_pop?: Maybe<Txs_Stats_Var_Pop_Fields>;\n  var_samp?: Maybe<Txs_Stats_Var_Samp_Fields>;\n  variance?: Maybe<Txs_Stats_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"txs_stats\" */\nexport type Txs_Stats_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Txs_Stats_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Txs_Stats_Avg_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"txs_stats\". All fields are combined with a logical 'AND'. */\nexport type Txs_Stats_Bool_Exp = {\n  _and?: InputMaybe<Array<Txs_Stats_Bool_Exp>>;\n  _not?: InputMaybe<Txs_Stats_Bool_Exp>;\n  _or?: InputMaybe<Array<Txs_Stats_Bool_Exp>>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  height?: InputMaybe<Bigint_Comparison_Exp>;\n  msg_type?: InputMaybe<String_Comparison_Exp>;\n  pubkey?: InputMaybe<Jsonb_Comparison_Exp>;\n  rank?: InputMaybe<Bigint_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Txs_Stats_Max_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  msg_type?: Maybe<Scalars['String']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Txs_Stats_Min_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  height?: Maybe<Scalars['bigint']['output']>;\n  msg_type?: Maybe<Scalars['String']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** Ordering options when selecting data from \"txs_stats\". */\nexport type Txs_Stats_Order_By = {\n  date?: InputMaybe<Order_By>;\n  height?: InputMaybe<Order_By>;\n  msg_type?: InputMaybe<Order_By>;\n  pubkey?: InputMaybe<Order_By>;\n  rank?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"txs_stats\" */\nexport enum Txs_Stats_Select_Column {\n  /** column name */\n  Date = 'date',\n  /** column name */\n  Height = 'height',\n  /** column name */\n  MsgType = 'msg_type',\n  /** column name */\n  Pubkey = 'pubkey',\n  /** column name */\n  Rank = 'rank'\n}\n\n/** aggregate stddev on columns */\nexport type Txs_Stats_Stddev_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Txs_Stats_Stddev_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Txs_Stats_Stddev_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Txs_Stats_Sum_Fields = {\n  height?: Maybe<Scalars['bigint']['output']>;\n  rank?: Maybe<Scalars['bigint']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Txs_Stats_Var_Pop_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Txs_Stats_Var_Samp_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Txs_Stats_Variance_Fields = {\n  height?: Maybe<Scalars['Float']['output']>;\n  rank?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"uptime\" */\nexport type Uptime = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n  uptime?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregated selection of \"uptime\" */\nexport type Uptime_Aggregate = {\n  aggregate?: Maybe<Uptime_Aggregate_Fields>;\n  nodes: Array<Uptime>;\n};\n\n/** aggregate fields of \"uptime\" */\nexport type Uptime_Aggregate_Fields = {\n  avg?: Maybe<Uptime_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Uptime_Max_Fields>;\n  min?: Maybe<Uptime_Min_Fields>;\n  stddev?: Maybe<Uptime_Stddev_Fields>;\n  stddev_pop?: Maybe<Uptime_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Uptime_Stddev_Samp_Fields>;\n  sum?: Maybe<Uptime_Sum_Fields>;\n  var_pop?: Maybe<Uptime_Var_Pop_Fields>;\n  var_samp?: Maybe<Uptime_Var_Samp_Fields>;\n  variance?: Maybe<Uptime_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"uptime\" */\nexport type Uptime_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Uptime_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Uptime_Avg_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n  uptime?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"uptime\". All fields are combined with a logical 'AND'. */\nexport type Uptime_Bool_Exp = {\n  _and?: InputMaybe<Array<Uptime_Bool_Exp>>;\n  _not?: InputMaybe<Uptime_Bool_Exp>;\n  _or?: InputMaybe<Array<Uptime_Bool_Exp>>;\n  consensus_address?: InputMaybe<String_Comparison_Exp>;\n  consensus_pubkey?: InputMaybe<String_Comparison_Exp>;\n  pre_commits?: InputMaybe<Bigint_Comparison_Exp>;\n  uptime?: InputMaybe<Numeric_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Uptime_Max_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n  uptime?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Uptime_Min_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n  uptime?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** Ordering options when selecting data from \"uptime\". */\nexport type Uptime_Order_By = {\n  consensus_address?: InputMaybe<Order_By>;\n  consensus_pubkey?: InputMaybe<Order_By>;\n  pre_commits?: InputMaybe<Order_By>;\n  uptime?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"uptime\" */\nexport enum Uptime_Select_Column {\n  /** column name */\n  ConsensusAddress = 'consensus_address',\n  /** column name */\n  ConsensusPubkey = 'consensus_pubkey',\n  /** column name */\n  PreCommits = 'pre_commits',\n  /** column name */\n  Uptime = 'uptime'\n}\n\n/** aggregate stddev on columns */\nexport type Uptime_Stddev_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n  uptime?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Uptime_Stddev_Pop_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n  uptime?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Uptime_Stddev_Samp_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n  uptime?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Uptime_Sum_Fields = {\n  pre_commits?: Maybe<Scalars['bigint']['output']>;\n  uptime?: Maybe<Scalars['numeric']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Uptime_Var_Pop_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n  uptime?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Uptime_Var_Samp_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n  uptime?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Uptime_Variance_Fields = {\n  pre_commits?: Maybe<Scalars['Float']['output']>;\n  uptime?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"validator\" */\nexport type Validator = {\n  /** An array relationship */\n  blocks: Array<Block>;\n  /** An aggregate relationship */\n  blocks_aggregate: Block_Aggregate;\n  consensus_address: Scalars['String']['output'];\n  consensus_pubkey: Scalars['String']['output'];\n  /** An array relationship */\n  pre_commits: Array<Pre_Commit>;\n  /** An aggregate relationship */\n  pre_commits_aggregate: Pre_Commit_Aggregate;\n};\n\n\n/** columns and relationships of \"validator\" */\nexport type ValidatorBlocksArgs = {\n  distinct_on?: InputMaybe<Array<Block_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Block_Order_By>>;\n  where?: InputMaybe<Block_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"validator\" */\nexport type ValidatorBlocks_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Block_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Block_Order_By>>;\n  where?: InputMaybe<Block_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"validator\" */\nexport type ValidatorPre_CommitsArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commit_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commit_Order_By>>;\n  where?: InputMaybe<Pre_Commit_Bool_Exp>;\n};\n\n\n/** columns and relationships of \"validator\" */\nexport type ValidatorPre_Commits_AggregateArgs = {\n  distinct_on?: InputMaybe<Array<Pre_Commit_Select_Column>>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  order_by?: InputMaybe<Array<Pre_Commit_Order_By>>;\n  where?: InputMaybe<Pre_Commit_Bool_Exp>;\n};\n\n/** aggregated selection of \"validator\" */\nexport type Validator_Aggregate = {\n  aggregate?: Maybe<Validator_Aggregate_Fields>;\n  nodes: Array<Validator>;\n};\n\n/** aggregate fields of \"validator\" */\nexport type Validator_Aggregate_Fields = {\n  count: Scalars['Int']['output'];\n  max?: Maybe<Validator_Max_Fields>;\n  min?: Maybe<Validator_Min_Fields>;\n};\n\n\n/** aggregate fields of \"validator\" */\nexport type Validator_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Validator_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** Boolean expression to filter rows from the table \"validator\". All fields are combined with a logical 'AND'. */\nexport type Validator_Bool_Exp = {\n  _and?: InputMaybe<Array<Validator_Bool_Exp>>;\n  _not?: InputMaybe<Validator_Bool_Exp>;\n  _or?: InputMaybe<Array<Validator_Bool_Exp>>;\n  blocks?: InputMaybe<Block_Bool_Exp>;\n  consensus_address?: InputMaybe<String_Comparison_Exp>;\n  consensus_pubkey?: InputMaybe<String_Comparison_Exp>;\n  pre_commits?: InputMaybe<Pre_Commit_Bool_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Validator_Max_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Validator_Min_Fields = {\n  consensus_address?: Maybe<Scalars['String']['output']>;\n  consensus_pubkey?: Maybe<Scalars['String']['output']>;\n};\n\n/** Ordering options when selecting data from \"validator\". */\nexport type Validator_Order_By = {\n  blocks_aggregate?: InputMaybe<Block_Aggregate_Order_By>;\n  consensus_address?: InputMaybe<Order_By>;\n  consensus_pubkey?: InputMaybe<Order_By>;\n  pre_commits_aggregate?: InputMaybe<Pre_Commit_Aggregate_Order_By>;\n};\n\n/** select columns of table \"validator\" */\nexport enum Validator_Select_Column {\n  /** column name */\n  ConsensusAddress = 'consensus_address',\n  /** column name */\n  ConsensusPubkey = 'consensus_pubkey'\n}\n\n/** columns and relationships of \"volts_demand\" */\nexport type Volts_Demand = {\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n  volts?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregated selection of \"volts_demand\" */\nexport type Volts_Demand_Aggregate = {\n  aggregate?: Maybe<Volts_Demand_Aggregate_Fields>;\n  nodes: Array<Volts_Demand>;\n};\n\n/** aggregate fields of \"volts_demand\" */\nexport type Volts_Demand_Aggregate_Fields = {\n  avg?: Maybe<Volts_Demand_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Volts_Demand_Max_Fields>;\n  min?: Maybe<Volts_Demand_Min_Fields>;\n  stddev?: Maybe<Volts_Demand_Stddev_Fields>;\n  stddev_pop?: Maybe<Volts_Demand_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Volts_Demand_Stddev_Samp_Fields>;\n  sum?: Maybe<Volts_Demand_Sum_Fields>;\n  var_pop?: Maybe<Volts_Demand_Var_Pop_Fields>;\n  var_samp?: Maybe<Volts_Demand_Var_Samp_Fields>;\n  variance?: Maybe<Volts_Demand_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"volts_demand\" */\nexport type Volts_Demand_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Volts_Demand_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Volts_Demand_Avg_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n  volts?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"volts_demand\". All fields are combined with a logical 'AND'. */\nexport type Volts_Demand_Bool_Exp = {\n  _and?: InputMaybe<Array<Volts_Demand_Bool_Exp>>;\n  _not?: InputMaybe<Volts_Demand_Bool_Exp>;\n  _or?: InputMaybe<Array<Volts_Demand_Bool_Exp>>;\n  cyberlinks_per_day?: InputMaybe<Bigint_Comparison_Exp>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  volts?: InputMaybe<Float8_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Volts_Demand_Max_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n  volts?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Volts_Demand_Min_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n  date?: Maybe<Scalars['date']['output']>;\n  volts?: Maybe<Scalars['float8']['output']>;\n};\n\n/** Ordering options when selecting data from \"volts_demand\". */\nexport type Volts_Demand_Order_By = {\n  cyberlinks_per_day?: InputMaybe<Order_By>;\n  date?: InputMaybe<Order_By>;\n  volts?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"volts_demand\" */\nexport enum Volts_Demand_Select_Column {\n  /** column name */\n  CyberlinksPerDay = 'cyberlinks_per_day',\n  /** column name */\n  Date = 'date',\n  /** column name */\n  Volts = 'volts'\n}\n\n/** aggregate stddev on columns */\nexport type Volts_Demand_Stddev_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n  volts?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Volts_Demand_Stddev_Pop_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n  volts?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Volts_Demand_Stddev_Samp_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n  volts?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Volts_Demand_Sum_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['bigint']['output']>;\n  volts?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Volts_Demand_Var_Pop_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n  volts?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Volts_Demand_Var_Samp_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n  volts?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Volts_Demand_Variance_Fields = {\n  cyberlinks_per_day?: Maybe<Scalars['Float']['output']>;\n  volts?: Maybe<Scalars['Float']['output']>;\n};\n\n/** columns and relationships of \"volts_stats\" */\nexport type Volts_Stats = {\n  date?: Maybe<Scalars['date']['output']>;\n  volts?: Maybe<Scalars['float8']['output']>;\n  volts_per_day?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregated selection of \"volts_stats\" */\nexport type Volts_Stats_Aggregate = {\n  aggregate?: Maybe<Volts_Stats_Aggregate_Fields>;\n  nodes: Array<Volts_Stats>;\n};\n\n/** aggregate fields of \"volts_stats\" */\nexport type Volts_Stats_Aggregate_Fields = {\n  avg?: Maybe<Volts_Stats_Avg_Fields>;\n  count: Scalars['Int']['output'];\n  max?: Maybe<Volts_Stats_Max_Fields>;\n  min?: Maybe<Volts_Stats_Min_Fields>;\n  stddev?: Maybe<Volts_Stats_Stddev_Fields>;\n  stddev_pop?: Maybe<Volts_Stats_Stddev_Pop_Fields>;\n  stddev_samp?: Maybe<Volts_Stats_Stddev_Samp_Fields>;\n  sum?: Maybe<Volts_Stats_Sum_Fields>;\n  var_pop?: Maybe<Volts_Stats_Var_Pop_Fields>;\n  var_samp?: Maybe<Volts_Stats_Var_Samp_Fields>;\n  variance?: Maybe<Volts_Stats_Variance_Fields>;\n};\n\n\n/** aggregate fields of \"volts_stats\" */\nexport type Volts_Stats_Aggregate_FieldsCountArgs = {\n  columns?: InputMaybe<Array<Volts_Stats_Select_Column>>;\n  distinct?: InputMaybe<Scalars['Boolean']['input']>;\n};\n\n/** aggregate avg on columns */\nexport type Volts_Stats_Avg_Fields = {\n  volts?: Maybe<Scalars['Float']['output']>;\n  volts_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** Boolean expression to filter rows from the table \"volts_stats\". All fields are combined with a logical 'AND'. */\nexport type Volts_Stats_Bool_Exp = {\n  _and?: InputMaybe<Array<Volts_Stats_Bool_Exp>>;\n  _not?: InputMaybe<Volts_Stats_Bool_Exp>;\n  _or?: InputMaybe<Array<Volts_Stats_Bool_Exp>>;\n  date?: InputMaybe<Date_Comparison_Exp>;\n  volts?: InputMaybe<Float8_Comparison_Exp>;\n  volts_per_day?: InputMaybe<Float8_Comparison_Exp>;\n};\n\n/** aggregate max on columns */\nexport type Volts_Stats_Max_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  volts?: Maybe<Scalars['float8']['output']>;\n  volts_per_day?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate min on columns */\nexport type Volts_Stats_Min_Fields = {\n  date?: Maybe<Scalars['date']['output']>;\n  volts?: Maybe<Scalars['float8']['output']>;\n  volts_per_day?: Maybe<Scalars['float8']['output']>;\n};\n\n/** Ordering options when selecting data from \"volts_stats\". */\nexport type Volts_Stats_Order_By = {\n  date?: InputMaybe<Order_By>;\n  volts?: InputMaybe<Order_By>;\n  volts_per_day?: InputMaybe<Order_By>;\n};\n\n/** select columns of table \"volts_stats\" */\nexport enum Volts_Stats_Select_Column {\n  /** column name */\n  Date = 'date',\n  /** column name */\n  Volts = 'volts',\n  /** column name */\n  VoltsPerDay = 'volts_per_day'\n}\n\n/** aggregate stddev on columns */\nexport type Volts_Stats_Stddev_Fields = {\n  volts?: Maybe<Scalars['Float']['output']>;\n  volts_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_pop on columns */\nexport type Volts_Stats_Stddev_Pop_Fields = {\n  volts?: Maybe<Scalars['Float']['output']>;\n  volts_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate stddev_samp on columns */\nexport type Volts_Stats_Stddev_Samp_Fields = {\n  volts?: Maybe<Scalars['Float']['output']>;\n  volts_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate sum on columns */\nexport type Volts_Stats_Sum_Fields = {\n  volts?: Maybe<Scalars['float8']['output']>;\n  volts_per_day?: Maybe<Scalars['float8']['output']>;\n};\n\n/** aggregate var_pop on columns */\nexport type Volts_Stats_Var_Pop_Fields = {\n  volts?: Maybe<Scalars['Float']['output']>;\n  volts_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate var_samp on columns */\nexport type Volts_Stats_Var_Samp_Fields = {\n  volts?: Maybe<Scalars['Float']['output']>;\n  volts_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\n/** aggregate variance on columns */\nexport type Volts_Stats_Variance_Fields = {\n  volts?: Maybe<Scalars['Float']['output']>;\n  volts_per_day?: Maybe<Scalars['Float']['output']>;\n};\n\nexport type TransactionsSubscriptionVariables = Exact<{ [key: string]: never; }>;\n\n\nexport type TransactionsSubscription = { transaction: Array<{ success: boolean, messages: any, height: any, hash: string }> };\n\nexport type AccountCountQueryVariables = Exact<{ [key: string]: never; }>;\n\n\nexport type AccountCountQuery = { account_aggregate: { aggregate?: { count: number } | null } };\n\nexport type BlockByHeightQueryVariables = Exact<{\n  blockId?: InputMaybe<Scalars['bigint']['input']>;\n}>;\n\n\nexport type BlockByHeightQuery = { block: Array<{ hash: string, height: any, proposer_address?: string | null, timestamp: any, transactions: Array<{ messages: any, hash: string, height: any, success: boolean }> }> };\n\nexport type BlocksQueryVariables = Exact<{\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  where?: InputMaybe<Block_Bool_Exp>;\n}>;\n\n\nexport type BlocksQuery = { block: Array<{ hash: string, height: any, proposer_address?: string | null, timestamp: any, transactions_aggregate: { aggregate?: { count: number } | null } }> };\n\nexport type ContractsCountQueryVariables = Exact<{ [key: string]: never; }>;\n\n\nexport type ContractsCountQuery = { contracts_aggregate: { aggregate?: { count: number } | null } };\n\nexport type CyberlinksByParticleQueryVariables = Exact<{\n  limit?: InputMaybe<Scalars['Int']['input']>;\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  orderBy?: InputMaybe<Array<Cyberlinks_Order_By> | Cyberlinks_Order_By>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n}>;\n\n\nexport type CyberlinksByParticleQuery = { cyberlinks: Array<{ timestamp: any, neuron: string, transaction_hash: string, from: string, to: string }> };\n\nexport type CyberlinksCountByNeuronQueryVariables = Exact<{\n  address?: InputMaybe<Scalars['String']['input']>;\n  particles_from?: InputMaybe<Array<Scalars['String']['input']> | Scalars['String']['input']>;\n  timestamp?: InputMaybe<Scalars['timestamp']['input']>;\n}>;\n\n\nexport type CyberlinksCountByNeuronQuery = { cyberlinks_aggregate: { aggregate?: { count: number } | null } };\n\nexport type CyberlinksCountByParticleQueryVariables = Exact<{\n  cid?: InputMaybe<Scalars['String']['input']>;\n  where?: InputMaybe<Cyberlinks_Bool_Exp>;\n}>;\n\n\nexport type CyberlinksCountByParticleQuery = { cyberlinks_aggregate: { aggregate?: { count: number } | null } };\n\nexport type MessagesByAddressCountQueryVariables = Exact<{\n  address?: InputMaybe<Scalars['_text']['input']>;\n  timestamp?: InputMaybe<Scalars['timestamp']['input']>;\n}>;\n\n\nexport type MessagesByAddressCountQuery = { messages_by_address_aggregate: { aggregate?: { count: number } | null } };\n\nexport type MessagesByAddressSenseQueryVariables = Exact<{\n  address?: InputMaybe<Scalars['_text']['input']>;\n  limit?: InputMaybe<Scalars['bigint']['input']>;\n  offset?: InputMaybe<Scalars['bigint']['input']>;\n  timestamp_from?: InputMaybe<Scalars['timestamp']['input']>;\n  types?: InputMaybe<Scalars['_text']['input']>;\n  order_direction?: InputMaybe<Order_By>;\n}>;\n\n\nexport type MessagesByAddressSenseQuery = { messages_by_address: Array<{ transaction_hash: string, index: any, value: any, type: string, transaction: { success: boolean, memo?: string | null, block: { timestamp: any, height: any } } }> };\n\nexport type MessagesByAddressSenseWsSubscriptionVariables = Exact<{\n  address?: InputMaybe<Scalars['_text']['input']>;\n  limit?: InputMaybe<Scalars['bigint']['input']>;\n  offset?: InputMaybe<Scalars['bigint']['input']>;\n  timestamp_from?: InputMaybe<Scalars['timestamp']['input']>;\n  types?: InputMaybe<Scalars['_text']['input']>;\n  order_direction?: InputMaybe<Order_By>;\n}>;\n\n\nexport type MessagesByAddressSenseWsSubscription = { messages_by_address: Array<{ transaction_hash: string, index: any, value: any, type: string, transaction: { success: boolean, memo?: string | null, block: { timestamp: any, height: any } } }> };\n\nexport type TransactionCountQueryVariables = Exact<{ [key: string]: never; }>;\n\n\nexport type TransactionCountQuery = { transaction_aggregate: { aggregate?: { count: number } | null } };\n\nexport type UptimeByAddressQueryVariables = Exact<{\n  address?: InputMaybe<Scalars['String']['input']>;\n}>;\n\n\nexport type UptimeByAddressQuery = { uptime: Array<{ uptime?: any | null }> };\n\nexport type WasmDashboardPageQueryVariables = Exact<{\n  offset?: InputMaybe<Scalars['Int']['input']>;\n  limit?: InputMaybe<Scalars['Int']['input']>;\n}>;\n\n\nexport type WasmDashboardPageQuery = { contracts: Array<{ address: string, admin: string, code_id: any, creator: string, fees: any, gas: any, label: string, tx: any }>, contracts_aggregate: { aggregate?: { count: number, sum?: { gas?: any | null, fees?: any | null, tx?: any | null } | null } | null } };\n\nexport type MessagesByAddressQueryVariables = Exact<{\n  address?: InputMaybe<Scalars['_text']['input']>;\n  limit?: InputMaybe<Scalars['bigint']['input']>;\n  offset?: InputMaybe<Scalars['bigint']['input']>;\n  types?: InputMaybe<Scalars['_text']['input']>;\n}>;\n\n\nexport type MessagesByAddressQuery = { messages_by_address: Array<{ transaction_hash: string, value: any, type: string, transaction: { success: boolean, height: any, logs?: any | null, memo?: string | null, block: { timestamp: any } } }> };\n\n\nexport const TransactionsDocument = gql`\n    subscription Transactions {\n  transaction(offset: 0, limit: 200, order_by: {height: desc}) {\n    success\n    messages\n    height\n    hash\n  }\n}\n    `;\n\n/**\n * __useTransactionsSubscription__\n *\n * To run a query within a React component, call `useTransactionsSubscription` and pass it any options that fit your needs.\n * When your component renders, `useTransactionsSubscription` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the subscription, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useTransactionsSubscription({\n *   variables: {\n *   },\n * });\n */\nexport function useTransactionsSubscription(baseOptions?: Apollo.SubscriptionHookOptions<TransactionsSubscription, TransactionsSubscriptionVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useSubscription<TransactionsSubscription, TransactionsSubscriptionVariables>(TransactionsDocument, options);\n      }\nexport type TransactionsSubscriptionHookResult = ReturnType<typeof useTransactionsSubscription>;\nexport type TransactionsSubscriptionResult = Apollo.SubscriptionResult<TransactionsSubscription>;\nexport const AccountCountDocument = gql`\n    query accountCount {\n  account_aggregate {\n    aggregate {\n      count(columns: address)\n    }\n  }\n}\n    `;\n\n/**\n * __useAccountCountQuery__\n *\n * To run a query within a React component, call `useAccountCountQuery` and pass it any options that fit your needs.\n * When your component renders, `useAccountCountQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useAccountCountQuery({\n *   variables: {\n *   },\n * });\n */\nexport function useAccountCountQuery(baseOptions?: Apollo.QueryHookOptions<AccountCountQuery, AccountCountQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<AccountCountQuery, AccountCountQueryVariables>(AccountCountDocument, options);\n      }\nexport function useAccountCountLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<AccountCountQuery, AccountCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<AccountCountQuery, AccountCountQueryVariables>(AccountCountDocument, options);\n        }\nexport function useAccountCountSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<AccountCountQuery, AccountCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<AccountCountQuery, AccountCountQueryVariables>(AccountCountDocument, options);\n        }\nexport type AccountCountQueryHookResult = ReturnType<typeof useAccountCountQuery>;\nexport type AccountCountLazyQueryHookResult = ReturnType<typeof useAccountCountLazyQuery>;\nexport type AccountCountSuspenseQueryHookResult = ReturnType<typeof useAccountCountSuspenseQuery>;\nexport type AccountCountQueryResult = Apollo.QueryResult<AccountCountQuery, AccountCountQueryVariables>;\nexport const BlockByHeightDocument = gql`\n    query blockByHeight($blockId: bigint) {\n  block(where: {height: {_eq: $blockId}}) {\n    hash\n    height\n    proposer_address\n    timestamp\n    transactions {\n      messages\n      hash\n      height\n      success\n    }\n  }\n}\n    `;\n\n/**\n * __useBlockByHeightQuery__\n *\n * To run a query within a React component, call `useBlockByHeightQuery` and pass it any options that fit your needs.\n * When your component renders, `useBlockByHeightQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useBlockByHeightQuery({\n *   variables: {\n *      blockId: // value for 'blockId'\n *   },\n * });\n */\nexport function useBlockByHeightQuery(baseOptions?: Apollo.QueryHookOptions<BlockByHeightQuery, BlockByHeightQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<BlockByHeightQuery, BlockByHeightQueryVariables>(BlockByHeightDocument, options);\n      }\nexport function useBlockByHeightLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<BlockByHeightQuery, BlockByHeightQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<BlockByHeightQuery, BlockByHeightQueryVariables>(BlockByHeightDocument, options);\n        }\nexport function useBlockByHeightSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<BlockByHeightQuery, BlockByHeightQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<BlockByHeightQuery, BlockByHeightQueryVariables>(BlockByHeightDocument, options);\n        }\nexport type BlockByHeightQueryHookResult = ReturnType<typeof useBlockByHeightQuery>;\nexport type BlockByHeightLazyQueryHookResult = ReturnType<typeof useBlockByHeightLazyQuery>;\nexport type BlockByHeightSuspenseQueryHookResult = ReturnType<typeof useBlockByHeightSuspenseQuery>;\nexport type BlockByHeightQueryResult = Apollo.QueryResult<BlockByHeightQuery, BlockByHeightQueryVariables>;\nexport const BlocksDocument = gql`\n    query blocks($limit: Int, $offset: Int, $where: block_bool_exp) {\n  block(where: $where, limit: $limit, offset: $offset, order_by: {height: desc}) {\n    hash\n    height\n    proposer_address\n    transactions_aggregate {\n      aggregate {\n        count\n      }\n    }\n    timestamp\n  }\n}\n    `;\n\n/**\n * __useBlocksQuery__\n *\n * To run a query within a React component, call `useBlocksQuery` and pass it any options that fit your needs.\n * When your component renders, `useBlocksQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useBlocksQuery({\n *   variables: {\n *      limit: // value for 'limit'\n *      offset: // value for 'offset'\n *      where: // value for 'where'\n *   },\n * });\n */\nexport function useBlocksQuery(baseOptions?: Apollo.QueryHookOptions<BlocksQuery, BlocksQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<BlocksQuery, BlocksQueryVariables>(BlocksDocument, options);\n      }\nexport function useBlocksLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<BlocksQuery, BlocksQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<BlocksQuery, BlocksQueryVariables>(BlocksDocument, options);\n        }\nexport function useBlocksSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<BlocksQuery, BlocksQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<BlocksQuery, BlocksQueryVariables>(BlocksDocument, options);\n        }\nexport type BlocksQueryHookResult = ReturnType<typeof useBlocksQuery>;\nexport type BlocksLazyQueryHookResult = ReturnType<typeof useBlocksLazyQuery>;\nexport type BlocksSuspenseQueryHookResult = ReturnType<typeof useBlocksSuspenseQuery>;\nexport type BlocksQueryResult = Apollo.QueryResult<BlocksQuery, BlocksQueryVariables>;\nexport const ContractsCountDocument = gql`\n    query contractsCount {\n  contracts_aggregate {\n    aggregate {\n      count\n    }\n  }\n}\n    `;\n\n/**\n * __useContractsCountQuery__\n *\n * To run a query within a React component, call `useContractsCountQuery` and pass it any options that fit your needs.\n * When your component renders, `useContractsCountQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useContractsCountQuery({\n *   variables: {\n *   },\n * });\n */\nexport function useContractsCountQuery(baseOptions?: Apollo.QueryHookOptions<ContractsCountQuery, ContractsCountQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<ContractsCountQuery, ContractsCountQueryVariables>(ContractsCountDocument, options);\n      }\nexport function useContractsCountLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<ContractsCountQuery, ContractsCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<ContractsCountQuery, ContractsCountQueryVariables>(ContractsCountDocument, options);\n        }\nexport function useContractsCountSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<ContractsCountQuery, ContractsCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<ContractsCountQuery, ContractsCountQueryVariables>(ContractsCountDocument, options);\n        }\nexport type ContractsCountQueryHookResult = ReturnType<typeof useContractsCountQuery>;\nexport type ContractsCountLazyQueryHookResult = ReturnType<typeof useContractsCountLazyQuery>;\nexport type ContractsCountSuspenseQueryHookResult = ReturnType<typeof useContractsCountSuspenseQuery>;\nexport type ContractsCountQueryResult = Apollo.QueryResult<ContractsCountQuery, ContractsCountQueryVariables>;\nexport const CyberlinksByParticleDocument = gql`\n    query CyberlinksByParticle($limit: Int, $offset: Int, $orderBy: [cyberlinks_order_by!], $where: cyberlinks_bool_exp) {\n  cyberlinks(limit: $limit, offset: $offset, order_by: $orderBy, where: $where) {\n    from: particle_from\n    to: particle_to\n    timestamp\n    neuron\n    transaction_hash\n  }\n}\n    `;\n\n/**\n * __useCyberlinksByParticleQuery__\n *\n * To run a query within a React component, call `useCyberlinksByParticleQuery` and pass it any options that fit your needs.\n * When your component renders, `useCyberlinksByParticleQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useCyberlinksByParticleQuery({\n *   variables: {\n *      limit: // value for 'limit'\n *      offset: // value for 'offset'\n *      orderBy: // value for 'orderBy'\n *      where: // value for 'where'\n *   },\n * });\n */\nexport function useCyberlinksByParticleQuery(baseOptions?: Apollo.QueryHookOptions<CyberlinksByParticleQuery, CyberlinksByParticleQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<CyberlinksByParticleQuery, CyberlinksByParticleQueryVariables>(CyberlinksByParticleDocument, options);\n      }\nexport function useCyberlinksByParticleLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<CyberlinksByParticleQuery, CyberlinksByParticleQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<CyberlinksByParticleQuery, CyberlinksByParticleQueryVariables>(CyberlinksByParticleDocument, options);\n        }\nexport function useCyberlinksByParticleSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<CyberlinksByParticleQuery, CyberlinksByParticleQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<CyberlinksByParticleQuery, CyberlinksByParticleQueryVariables>(CyberlinksByParticleDocument, options);\n        }\nexport type CyberlinksByParticleQueryHookResult = ReturnType<typeof useCyberlinksByParticleQuery>;\nexport type CyberlinksByParticleLazyQueryHookResult = ReturnType<typeof useCyberlinksByParticleLazyQuery>;\nexport type CyberlinksByParticleSuspenseQueryHookResult = ReturnType<typeof useCyberlinksByParticleSuspenseQuery>;\nexport type CyberlinksByParticleQueryResult = Apollo.QueryResult<CyberlinksByParticleQuery, CyberlinksByParticleQueryVariables>;\nexport const CyberlinksCountByNeuronDocument = gql`\n    query CyberlinksCountByNeuron($address: String, $particles_from: [String!], $timestamp: timestamp) {\n  cyberlinks_aggregate(\n    where: {_and: [{neuron: {_eq: $address}}, {particle_from: {_in: $particles_from}}, {timestamp: {_gt: $timestamp}}]}\n  ) {\n    aggregate {\n      count\n    }\n  }\n}\n    `;\n\n/**\n * __useCyberlinksCountByNeuronQuery__\n *\n * To run a query within a React component, call `useCyberlinksCountByNeuronQuery` and pass it any options that fit your needs.\n * When your component renders, `useCyberlinksCountByNeuronQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useCyberlinksCountByNeuronQuery({\n *   variables: {\n *      address: // value for 'address'\n *      particles_from: // value for 'particles_from'\n *      timestamp: // value for 'timestamp'\n *   },\n * });\n */\nexport function useCyberlinksCountByNeuronQuery(baseOptions?: Apollo.QueryHookOptions<CyberlinksCountByNeuronQuery, CyberlinksCountByNeuronQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<CyberlinksCountByNeuronQuery, CyberlinksCountByNeuronQueryVariables>(CyberlinksCountByNeuronDocument, options);\n      }\nexport function useCyberlinksCountByNeuronLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<CyberlinksCountByNeuronQuery, CyberlinksCountByNeuronQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<CyberlinksCountByNeuronQuery, CyberlinksCountByNeuronQueryVariables>(CyberlinksCountByNeuronDocument, options);\n        }\nexport function useCyberlinksCountByNeuronSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<CyberlinksCountByNeuronQuery, CyberlinksCountByNeuronQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<CyberlinksCountByNeuronQuery, CyberlinksCountByNeuronQueryVariables>(CyberlinksCountByNeuronDocument, options);\n        }\nexport type CyberlinksCountByNeuronQueryHookResult = ReturnType<typeof useCyberlinksCountByNeuronQuery>;\nexport type CyberlinksCountByNeuronLazyQueryHookResult = ReturnType<typeof useCyberlinksCountByNeuronLazyQuery>;\nexport type CyberlinksCountByNeuronSuspenseQueryHookResult = ReturnType<typeof useCyberlinksCountByNeuronSuspenseQuery>;\nexport type CyberlinksCountByNeuronQueryResult = Apollo.QueryResult<CyberlinksCountByNeuronQuery, CyberlinksCountByNeuronQueryVariables>;\nexport const CyberlinksCountByParticleDocument = gql`\n    query cyberlinksCountByParticle($cid: String, $where: cyberlinks_bool_exp) {\n  cyberlinks_aggregate(where: $where) {\n    aggregate {\n      count\n    }\n  }\n}\n    `;\n\n/**\n * __useCyberlinksCountByParticleQuery__\n *\n * To run a query within a React component, call `useCyberlinksCountByParticleQuery` and pass it any options that fit your needs.\n * When your component renders, `useCyberlinksCountByParticleQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useCyberlinksCountByParticleQuery({\n *   variables: {\n *      cid: // value for 'cid'\n *      where: // value for 'where'\n *   },\n * });\n */\nexport function useCyberlinksCountByParticleQuery(baseOptions?: Apollo.QueryHookOptions<CyberlinksCountByParticleQuery, CyberlinksCountByParticleQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<CyberlinksCountByParticleQuery, CyberlinksCountByParticleQueryVariables>(CyberlinksCountByParticleDocument, options);\n      }\nexport function useCyberlinksCountByParticleLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<CyberlinksCountByParticleQuery, CyberlinksCountByParticleQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<CyberlinksCountByParticleQuery, CyberlinksCountByParticleQueryVariables>(CyberlinksCountByParticleDocument, options);\n        }\nexport function useCyberlinksCountByParticleSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<CyberlinksCountByParticleQuery, CyberlinksCountByParticleQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<CyberlinksCountByParticleQuery, CyberlinksCountByParticleQueryVariables>(CyberlinksCountByParticleDocument, options);\n        }\nexport type CyberlinksCountByParticleQueryHookResult = ReturnType<typeof useCyberlinksCountByParticleQuery>;\nexport type CyberlinksCountByParticleLazyQueryHookResult = ReturnType<typeof useCyberlinksCountByParticleLazyQuery>;\nexport type CyberlinksCountByParticleSuspenseQueryHookResult = ReturnType<typeof useCyberlinksCountByParticleSuspenseQuery>;\nexport type CyberlinksCountByParticleQueryResult = Apollo.QueryResult<CyberlinksCountByParticleQuery, CyberlinksCountByParticleQueryVariables>;\nexport const MessagesByAddressCountDocument = gql`\n    query MessagesByAddressCount($address: _text, $timestamp: timestamp) {\n  messages_by_address_aggregate(\n    args: {addresses: $address, limit: \"100000000\", offset: \"0\", types: \"{}\"}\n    where: {transaction: {block: {timestamp: {_gt: $timestamp}}}}\n  ) {\n    aggregate {\n      count\n    }\n  }\n}\n    `;\n\n/**\n * __useMessagesByAddressCountQuery__\n *\n * To run a query within a React component, call `useMessagesByAddressCountQuery` and pass it any options that fit your needs.\n * When your component renders, `useMessagesByAddressCountQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useMessagesByAddressCountQuery({\n *   variables: {\n *      address: // value for 'address'\n *      timestamp: // value for 'timestamp'\n *   },\n * });\n */\nexport function useMessagesByAddressCountQuery(baseOptions?: Apollo.QueryHookOptions<MessagesByAddressCountQuery, MessagesByAddressCountQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<MessagesByAddressCountQuery, MessagesByAddressCountQueryVariables>(MessagesByAddressCountDocument, options);\n      }\nexport function useMessagesByAddressCountLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<MessagesByAddressCountQuery, MessagesByAddressCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<MessagesByAddressCountQuery, MessagesByAddressCountQueryVariables>(MessagesByAddressCountDocument, options);\n        }\nexport function useMessagesByAddressCountSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<MessagesByAddressCountQuery, MessagesByAddressCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<MessagesByAddressCountQuery, MessagesByAddressCountQueryVariables>(MessagesByAddressCountDocument, options);\n        }\nexport type MessagesByAddressCountQueryHookResult = ReturnType<typeof useMessagesByAddressCountQuery>;\nexport type MessagesByAddressCountLazyQueryHookResult = ReturnType<typeof useMessagesByAddressCountLazyQuery>;\nexport type MessagesByAddressCountSuspenseQueryHookResult = ReturnType<typeof useMessagesByAddressCountSuspenseQuery>;\nexport type MessagesByAddressCountQueryResult = Apollo.QueryResult<MessagesByAddressCountQuery, MessagesByAddressCountQueryVariables>;\nexport const MessagesByAddressSenseDocument = gql`\n    query MessagesByAddressSense($address: _text, $limit: bigint, $offset: bigint, $timestamp_from: timestamp, $types: _text, $order_direction: order_by) {\n  messages_by_address(\n    args: {addresses: $address, limit: $limit, offset: $offset, types: $types}\n    order_by: {transaction: {block: {timestamp: $order_direction}}}\n    where: {transaction: {block: {timestamp: {_gt: $timestamp_from}}}}\n  ) {\n    transaction_hash\n    index\n    value\n    transaction {\n      success\n      block {\n        timestamp\n        height\n      }\n      memo\n    }\n    type\n  }\n}\n    `;\n\n/**\n * __useMessagesByAddressSenseQuery__\n *\n * To run a query within a React component, call `useMessagesByAddressSenseQuery` and pass it any options that fit your needs.\n * When your component renders, `useMessagesByAddressSenseQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useMessagesByAddressSenseQuery({\n *   variables: {\n *      address: // value for 'address'\n *      limit: // value for 'limit'\n *      offset: // value for 'offset'\n *      timestamp_from: // value for 'timestamp_from'\n *      types: // value for 'types'\n *      order_direction: // value for 'order_direction'\n *   },\n * });\n */\nexport function useMessagesByAddressSenseQuery(baseOptions?: Apollo.QueryHookOptions<MessagesByAddressSenseQuery, MessagesByAddressSenseQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<MessagesByAddressSenseQuery, MessagesByAddressSenseQueryVariables>(MessagesByAddressSenseDocument, options);\n      }\nexport function useMessagesByAddressSenseLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<MessagesByAddressSenseQuery, MessagesByAddressSenseQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<MessagesByAddressSenseQuery, MessagesByAddressSenseQueryVariables>(MessagesByAddressSenseDocument, options);\n        }\nexport function useMessagesByAddressSenseSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<MessagesByAddressSenseQuery, MessagesByAddressSenseQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<MessagesByAddressSenseQuery, MessagesByAddressSenseQueryVariables>(MessagesByAddressSenseDocument, options);\n        }\nexport type MessagesByAddressSenseQueryHookResult = ReturnType<typeof useMessagesByAddressSenseQuery>;\nexport type MessagesByAddressSenseLazyQueryHookResult = ReturnType<typeof useMessagesByAddressSenseLazyQuery>;\nexport type MessagesByAddressSenseSuspenseQueryHookResult = ReturnType<typeof useMessagesByAddressSenseSuspenseQuery>;\nexport type MessagesByAddressSenseQueryResult = Apollo.QueryResult<MessagesByAddressSenseQuery, MessagesByAddressSenseQueryVariables>;\nexport const MessagesByAddressSenseWsDocument = gql`\n    subscription MessagesByAddressSenseWs($address: _text, $limit: bigint, $offset: bigint, $timestamp_from: timestamp, $types: _text, $order_direction: order_by) {\n  messages_by_address(\n    args: {addresses: $address, limit: $limit, offset: $offset, types: $types}\n    order_by: {transaction: {block: {timestamp: $order_direction}}}\n    where: {transaction: {block: {timestamp: {_gt: $timestamp_from}}}}\n  ) {\n    transaction_hash\n    index\n    value\n    transaction {\n      success\n      block {\n        timestamp\n        height\n      }\n      memo\n    }\n    type\n  }\n}\n    `;\n\n/**\n * __useMessagesByAddressSenseWsSubscription__\n *\n * To run a query within a React component, call `useMessagesByAddressSenseWsSubscription` and pass it any options that fit your needs.\n * When your component renders, `useMessagesByAddressSenseWsSubscription` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the subscription, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useMessagesByAddressSenseWsSubscription({\n *   variables: {\n *      address: // value for 'address'\n *      limit: // value for 'limit'\n *      offset: // value for 'offset'\n *      timestamp_from: // value for 'timestamp_from'\n *      types: // value for 'types'\n *      order_direction: // value for 'order_direction'\n *   },\n * });\n */\nexport function useMessagesByAddressSenseWsSubscription(baseOptions?: Apollo.SubscriptionHookOptions<MessagesByAddressSenseWsSubscription, MessagesByAddressSenseWsSubscriptionVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useSubscription<MessagesByAddressSenseWsSubscription, MessagesByAddressSenseWsSubscriptionVariables>(MessagesByAddressSenseWsDocument, options);\n      }\nexport type MessagesByAddressSenseWsSubscriptionHookResult = ReturnType<typeof useMessagesByAddressSenseWsSubscription>;\nexport type MessagesByAddressSenseWsSubscriptionResult = Apollo.SubscriptionResult<MessagesByAddressSenseWsSubscription>;\nexport const TransactionCountDocument = gql`\n    query transactionCount {\n  transaction_aggregate {\n    aggregate {\n      count(columns: hash)\n    }\n  }\n}\n    `;\n\n/**\n * __useTransactionCountQuery__\n *\n * To run a query within a React component, call `useTransactionCountQuery` and pass it any options that fit your needs.\n * When your component renders, `useTransactionCountQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useTransactionCountQuery({\n *   variables: {\n *   },\n * });\n */\nexport function useTransactionCountQuery(baseOptions?: Apollo.QueryHookOptions<TransactionCountQuery, TransactionCountQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<TransactionCountQuery, TransactionCountQueryVariables>(TransactionCountDocument, options);\n      }\nexport function useTransactionCountLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<TransactionCountQuery, TransactionCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<TransactionCountQuery, TransactionCountQueryVariables>(TransactionCountDocument, options);\n        }\nexport function useTransactionCountSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<TransactionCountQuery, TransactionCountQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<TransactionCountQuery, TransactionCountQueryVariables>(TransactionCountDocument, options);\n        }\nexport type TransactionCountQueryHookResult = ReturnType<typeof useTransactionCountQuery>;\nexport type TransactionCountLazyQueryHookResult = ReturnType<typeof useTransactionCountLazyQuery>;\nexport type TransactionCountSuspenseQueryHookResult = ReturnType<typeof useTransactionCountSuspenseQuery>;\nexport type TransactionCountQueryResult = Apollo.QueryResult<TransactionCountQuery, TransactionCountQueryVariables>;\nexport const UptimeByAddressDocument = gql`\n    query uptimeByAddress($address: String) {\n  uptime(where: {consensus_address: {_eq: $address}}) {\n    uptime\n  }\n}\n    `;\n\n/**\n * __useUptimeByAddressQuery__\n *\n * To run a query within a React component, call `useUptimeByAddressQuery` and pass it any options that fit your needs.\n * When your component renders, `useUptimeByAddressQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useUptimeByAddressQuery({\n *   variables: {\n *      address: // value for 'address'\n *   },\n * });\n */\nexport function useUptimeByAddressQuery(baseOptions?: Apollo.QueryHookOptions<UptimeByAddressQuery, UptimeByAddressQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<UptimeByAddressQuery, UptimeByAddressQueryVariables>(UptimeByAddressDocument, options);\n      }\nexport function useUptimeByAddressLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<UptimeByAddressQuery, UptimeByAddressQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<UptimeByAddressQuery, UptimeByAddressQueryVariables>(UptimeByAddressDocument, options);\n        }\nexport function useUptimeByAddressSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<UptimeByAddressQuery, UptimeByAddressQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<UptimeByAddressQuery, UptimeByAddressQueryVariables>(UptimeByAddressDocument, options);\n        }\nexport type UptimeByAddressQueryHookResult = ReturnType<typeof useUptimeByAddressQuery>;\nexport type UptimeByAddressLazyQueryHookResult = ReturnType<typeof useUptimeByAddressLazyQuery>;\nexport type UptimeByAddressSuspenseQueryHookResult = ReturnType<typeof useUptimeByAddressSuspenseQuery>;\nexport type UptimeByAddressQueryResult = Apollo.QueryResult<UptimeByAddressQuery, UptimeByAddressQueryVariables>;\nexport const WasmDashboardPageDocument = gql`\n    query wasmDashboardPage($offset: Int, $limit: Int) {\n  contracts(limit: $limit, offset: $offset, order_by: {tx: desc}) {\n    address\n    admin\n    code_id\n    creator\n    fees\n    gas\n    label\n    tx\n  }\n  contracts_aggregate {\n    aggregate {\n      sum {\n        gas\n        fees\n        tx\n      }\n      count(columns: address)\n    }\n  }\n}\n    `;\n\n/**\n * __useWasmDashboardPageQuery__\n *\n * To run a query within a React component, call `useWasmDashboardPageQuery` and pass it any options that fit your needs.\n * When your component renders, `useWasmDashboardPageQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useWasmDashboardPageQuery({\n *   variables: {\n *      offset: // value for 'offset'\n *      limit: // value for 'limit'\n *   },\n * });\n */\nexport function useWasmDashboardPageQuery(baseOptions?: Apollo.QueryHookOptions<WasmDashboardPageQuery, WasmDashboardPageQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<WasmDashboardPageQuery, WasmDashboardPageQueryVariables>(WasmDashboardPageDocument, options);\n      }\nexport function useWasmDashboardPageLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<WasmDashboardPageQuery, WasmDashboardPageQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<WasmDashboardPageQuery, WasmDashboardPageQueryVariables>(WasmDashboardPageDocument, options);\n        }\nexport function useWasmDashboardPageSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<WasmDashboardPageQuery, WasmDashboardPageQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<WasmDashboardPageQuery, WasmDashboardPageQueryVariables>(WasmDashboardPageDocument, options);\n        }\nexport type WasmDashboardPageQueryHookResult = ReturnType<typeof useWasmDashboardPageQuery>;\nexport type WasmDashboardPageLazyQueryHookResult = ReturnType<typeof useWasmDashboardPageLazyQuery>;\nexport type WasmDashboardPageSuspenseQueryHookResult = ReturnType<typeof useWasmDashboardPageSuspenseQuery>;\nexport type WasmDashboardPageQueryResult = Apollo.QueryResult<WasmDashboardPageQuery, WasmDashboardPageQueryVariables>;\nexport const MessagesByAddressDocument = gql`\n    query MessagesByAddress($address: _text, $limit: bigint, $offset: bigint, $types: _text) {\n  messages_by_address(\n    args: {addresses: $address, limit: $limit, offset: $offset, types: $types}\n    order_by: {transaction: {block: {height: desc}}}\n  ) {\n    transaction_hash\n    value\n    transaction {\n      success\n      height\n      logs\n      memo\n      block {\n        timestamp\n      }\n    }\n    type\n  }\n}\n    `;\n\n/**\n * __useMessagesByAddressQuery__\n *\n * To run a query within a React component, call `useMessagesByAddressQuery` and pass it any options that fit your needs.\n * When your component renders, `useMessagesByAddressQuery` returns an object from Apollo Client that contains loading, error, and data properties\n * you can use to render your UI.\n *\n * @param baseOptions options that will be passed into the query, supported options are listed on: https://www.apollographql.com/docs/react/api/react-hooks/#options;\n *\n * @example\n * const { data, loading, error } = useMessagesByAddressQuery({\n *   variables: {\n *      address: // value for 'address'\n *      limit: // value for 'limit'\n *      offset: // value for 'offset'\n *      types: // value for 'types'\n *   },\n * });\n */\nexport function useMessagesByAddressQuery(baseOptions?: Apollo.QueryHookOptions<MessagesByAddressQuery, MessagesByAddressQueryVariables>) {\n        const options = {...defaultOptions, ...baseOptions}\n        return Apollo.useQuery<MessagesByAddressQuery, MessagesByAddressQueryVariables>(MessagesByAddressDocument, options);\n      }\nexport function useMessagesByAddressLazyQuery(baseOptions?: Apollo.LazyQueryHookOptions<MessagesByAddressQuery, MessagesByAddressQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useLazyQuery<MessagesByAddressQuery, MessagesByAddressQueryVariables>(MessagesByAddressDocument, options);\n        }\nexport function useMessagesByAddressSuspenseQuery(baseOptions?: Apollo.SuspenseQueryHookOptions<MessagesByAddressQuery, MessagesByAddressQueryVariables>) {\n          const options = {...defaultOptions, ...baseOptions}\n          return Apollo.useSuspenseQuery<MessagesByAddressQuery, MessagesByAddressQueryVariables>(MessagesByAddressDocument, options);\n        }\nexport type MessagesByAddressQueryHookResult = ReturnType<typeof useMessagesByAddressQuery>;\nexport type MessagesByAddressLazyQueryHookResult = ReturnType<typeof useMessagesByAddressLazyQuery>;\nexport type MessagesByAddressSuspenseQueryHookResult = ReturnType<typeof useMessagesByAddressSuspenseQuery>;\nexport type MessagesByAddressQueryResult = Apollo.QueryResult<MessagesByAddressQuery, MessagesByAddressQueryVariables>;","import { Coin } from 'cosmjs-types/cosmos/base/v1beta1/coin';\nimport { CyberLinkSimple, NeuronAddress } from 'src/types/base';\n\ninterface GenericIndexerTransaction<T> {\n  value: T;\n  type: string;\n  transaction_hash: string;\n  index: number;\n  transaction: {\n    memo?: string;\n    success: boolean;\n    block: {\n      timestamp: string;\n    };\n  };\n}\nexport const MSG_SEND_TRANSACTION_TYPE = 'cosmos.bank.v1beta1.MsgSend';\n\nexport const MSG_MULTI_SEND_TRANSACTION_TYPE =\n  'cosmos.bank.v1beta1.MsgMultiSend';\n\nexport const CYBER_LINK_TRANSACTION_TYPE = 'cyber.graph.v1beta1.MsgCyberlink';\n\ninterface Input {\n  address: NeuronAddress;\n  coins: Coin[];\n}\n\ninterface Output {\n  address: NeuronAddress;\n  coins: Coin[];\n}\n\nexport interface MsgMultiSendValue {\n  inputs: Input[];\n  outputs: Output[];\n}\n\nexport interface MsgSendValue {\n  amount: Coin[];\n  from_address: NeuronAddress;\n  to_address: NeuronAddress;\n}\n\ninterface MsgDelegateValue {\n  amount: Coin;\n  delegator_address: NeuronAddress;\n  validator_address: NeuronAddress;\n}\n\nexport interface CyberLinkValue {\n  neuron: NeuronAddress;\n  links: CyberLinkSimple[];\n}\n\nexport interface CyberLinkTransaction\n  extends GenericIndexerTransaction<CyberLinkValue> {\n  type: typeof CYBER_LINK_TRANSACTION_TYPE;\n}\n\nexport interface MsgMultiSendTransaction\n  extends GenericIndexerTransaction<MsgMultiSendValue> {\n  type: typeof MSG_MULTI_SEND_TRANSACTION_TYPE;\n}\n\nexport interface MsgSendTransaction\n  extends GenericIndexerTransaction<MsgSendValue> {\n  type: typeof MSG_SEND_TRANSACTION_TYPE;\n}\n\nexport type Transaction =\n  // | DelegateTransaction\n  CyberLinkTransaction | MsgMultiSendTransaction | MsgSendTransaction;\n","import { Tx } from 'cosmjs-types/cosmos/tx/v1beta1/tx';\nimport { MsgSend, MsgMultiSend } from 'cosmjs-types/cosmos/bank/v1beta1/tx';\n\nimport { fromBase64 } from '@cosmjs/encoding';\nimport {\n  MSG_MULTI_SEND_TRANSACTION_TYPE,\n  MSG_SEND_TRANSACTION_TYPE,\n} from 'src/services/backend/services/indexer/types';\nimport { NeuronAddress } from 'src/types/base';\nimport { TransactionDto } from 'src/services/CozoDb/types/dto';\nimport { getNowUtcNumber } from 'src/utils/date';\n\n// eslint-disable-next-line import/no-unused-modules\nexport const extractTxData = (data: string) => {\n  const result = Tx.decode(fromBase64(data));\n  const memo = result.body?.memo;\n  const messages = result.body?.messages\n    .map((message) => {\n      const msgType = message.typeUrl.slice(1);\n      if (msgType === MSG_SEND_TRANSACTION_TYPE) {\n        return MsgSend.decode(message.value);\n      }\n\n      if (msgType === MSG_MULTI_SEND_TRANSACTION_TYPE) {\n        return MsgMultiSend.decode(message.value);\n      }\n      return undefined;\n    })\n    .filter((message) => message !== undefined);\n\n  return { memo, messages };\n};\n\n// eslint-disable-next-line import/no-unused-modules\nexport const mapWebsocketTxToTransactions = (\n  neuron: NeuronAddress,\n  result: any\n) => {\n  const { data, events } = result;\n\n  const hash = events['tx.hash'][0];\n  const transactionType = events['message.action'][0].slice(1);\n  const timestamp = getNowUtcNumber();\n  const blockHeight = events['tx.height'][0];\n\n  const { memo = '', messages } = extractTxData(data.value.TxResult.tx);\n\n  const transactions: TransactionDto[] = [];\n  messages!.forEach((message, index) => {\n    transactions.push({\n      hash,\n      index,\n      type: transactionType,\n      timestamp,\n      success: true,\n      value: message!,\n      memo,\n      neuron,\n      blockHeight,\n    });\n  });\n\n  return transactions;\n};\n","import { ApolloClient, DocumentNode, InMemoryCache } from '@apollo/client';\n\nimport { GraphQLWsLink } from '@apollo/client/link/subscriptions';\nimport { GraphQLClient } from 'graphql-request';\nimport { createClient } from 'graphql-ws';\nimport { Observable } from 'rxjs';\nimport { INDEX_WEBSOCKET, INDEX_HTTPS } from 'src/constants/config';\n\nconst cyberGraphQLWsLink = new GraphQLWsLink(\n  createClient({\n    url: INDEX_WEBSOCKET,\n    shouldRetry: (errOrCloseEvent: unknown) => true,\n    retryAttempts: 10,\n    retryWait: async (retries: number): Promise<void> => {\n      setTimeout(() => Promise.resolve(), Math.min(1000 * 2 ** retries, 10000));\n    },\n    // on: {\n    //   error: (err) => {\n    //     console.log('---ws errr', err);\n    //   },\n    //   message: (msg) => {\n    //     console.log('---ws message', msg);\n    //   },\n    //   // Handle connection opened event\n    //   opened: () => {\n    //     console.log('---ws opened');\n    //   },\n    //   // Handle connection closed event\n    //   closed: () => {\n    //     console.log('---ws closed');\n    //   },\n    // },\n  })\n);\n\nexport const createIndexerClient = (abortSignal: AbortSignal) =>\n  new GraphQLClient(INDEX_HTTPS, {\n    signal: abortSignal,\n  });\n\n// eslint-disable-next-line import/no-unused-modules\nexport function createIndexerWebsocket<T>(\n  query: DocumentNode,\n  variables: object\n): Observable<T> {\n  const client = new ApolloClient({\n    link: cyberGraphQLWsLink,\n    cache: new InMemoryCache(),\n  });\n\n  const apolloObservable = client.subscribe({ query, variables });\n  return new Observable((subscriber) => {\n    const subscription = apolloObservable.subscribe({\n      next(result) {\n        subscriber.next(result.data as T);\n      },\n      error(err) {\n        subscriber.error(err);\n      },\n      complete() {\n        subscriber.complete();\n      },\n    });\n\n    // Cleanup subscription on unsubscribe\n    return () => subscription.unsubscribe();\n  });\n}\n","/* eslint-disable import/no-unused-modules */\n\nimport { ParticleCid, NeuronAddress } from 'src/types/base';\nimport { numberToUtcDate } from 'src/utils/date';\n\nimport { CYBERLINKS_BATCH_LIMIT } from './consts';\nimport { createIndexerClient } from './utils/graphqlClient';\nimport { fetchIterableByOffset } from 'src/utils/async/iterable';\nimport {\n  CyberlinksByParticleDocument,\n  CyberlinksByParticleQuery,\n  CyberlinksByParticleQueryVariables,\n  CyberlinksCountByNeuronDocument,\n  CyberlinksCountByNeuronQuery,\n  CyberlinksCountByNeuronQueryVariables,\n  Order_By,\n} from 'src/generated/graphql';\n\nconst fetchCyberlinks = async ({\n  particleCid,\n  timestampFrom,\n  offset = 0,\n  abortSignal,\n}: {\n  particleCid: ParticleCid;\n  timestampFrom: number;\n  offset?: number;\n  abortSignal: AbortSignal;\n}) => {\n  const res = await createIndexerClient(abortSignal).request<\n    CyberlinksByParticleQuery,\n    CyberlinksByParticleQueryVariables\n  >(CyberlinksByParticleDocument, {\n    limit: CYBERLINKS_BATCH_LIMIT,\n    offset,\n    orderBy: [{ timestamp: Order_By.Asc }],\n    where: {\n      _or: [\n        { particle_to: { _eq: particleCid } },\n        { particle_from: { _eq: particleCid } },\n      ],\n      timestamp: { _gt: numberToUtcDate(timestampFrom) },\n    },\n  });\n\n  return res.cyberlinks;\n};\n\nconst fetchCyberlinksCount = async (\n  address: NeuronAddress,\n  particlesFrom: ParticleCid[],\n  timestampFrom: number,\n  abortSignal: AbortSignal\n) => {\n  const res = await createIndexerClient(abortSignal).request<\n    CyberlinksCountByNeuronQuery,\n    CyberlinksCountByNeuronQueryVariables\n  >(CyberlinksCountByNeuronDocument, {\n    address,\n    particles_from: particlesFrom,\n    timestamp: numberToUtcDate(timestampFrom),\n  });\n\n  return res.cyberlinks_aggregate.aggregate?.count;\n};\n\nconst fetchCyberlinksByNeroun = async ({\n  neuron,\n  particlesFrom,\n  timestampFrom,\n  batchSize,\n  offset = 0,\n  abortSignal,\n}: {\n  neuron: NeuronAddress;\n  particlesFrom: ParticleCid[];\n  timestampFrom: number;\n  batchSize: number;\n  offset: number;\n  abortSignal: AbortSignal;\n}) => {\n  const where = {\n    _and: [\n      {\n        timestamp: {\n          _gt: numberToUtcDate(timestampFrom),\n        },\n      },\n      {\n        neuron: {\n          _eq: neuron,\n        },\n      },\n      { particle_from: { _in: particlesFrom } },\n    ],\n  };\n\n  const res = await createIndexerClient(abortSignal).request<\n    CyberlinksByParticleQuery,\n    CyberlinksByParticleQueryVariables\n  >(CyberlinksByParticleDocument, {\n    limit: batchSize,\n    offset,\n    orderBy: [\n      {\n        timestamp: Order_By.Asc,\n      },\n    ],\n    where,\n  });\n\n  return res.cyberlinks;\n};\n\nexport const fetchCyberlinksByNerounIterable = async (\n  neuron: NeuronAddress,\n  particlesFrom: ParticleCid[],\n  timestampFrom: number,\n  batchSize: number,\n  abortSignal: AbortSignal\n) =>\n  fetchIterableByOffset(fetchCyberlinksByNeroun, {\n    neuron,\n    particlesFrom,\n    timestampFrom,\n    batchSize,\n    abortSignal,\n  });\n\nconst fetchCyberlinksIterable = (\n  particleCid: ParticleCid,\n  timestampFrom: number,\n  abortSignal: AbortSignal\n) =>\n  fetchIterableByOffset(fetchCyberlinks, {\n    particleCid,\n    timestampFrom,\n    abortSignal,\n  });\n\nexport { fetchCyberlinksIterable, fetchCyberlinksCount };\n","const TRANSACTIONS_BATCH_LIMIT = 500;\nconst CYBERLINKS_BATCH_LIMIT = 200;\n\nexport { TRANSACTIONS_BATCH_LIMIT, CYBERLINKS_BATCH_LIMIT };\n","import { CyberLinkSimple, CyberlinkTxHash, ParticleCid } from 'src/types/base';\nimport { QueuePriority } from 'src/services/QueueManager/types';\nimport { asyncIterableBatchProcessor } from 'src/utils/async/iterable';\nimport { CID_TWEET } from 'src/constants/app';\nimport { LinkDto, TransactionDto } from 'src/services/CozoDb/types/dto';\n\nimport { fetchCyberlinksIterable } from '../../../indexer/cyberlinks';\nimport ParticlesResolverQueue from '../ParticlesResolverQueue/ParticlesResolverQueue';\nimport { MAX_LINKS_RESOLVE_BATCH } from '../consts';\nimport {\n  CYBER_LINK_TRANSACTION_TYPE,\n  CyberLinkValue,\n} from '../../../indexer/types';\n\nconst getUniqueParticlesFromLinks = (links: CyberLinkSimple[]) =>\n  [\n    ...new Set([\n      ...links.map((link) => link.to),\n      ...links.map((link) => link.from),\n    ]),\n  ] as ParticleCid[];\n\n// eslint-disable-next-line import/no-unused-modules\nexport const fetchCyberlinksAndResolveParticles = async (\n  cid: ParticleCid,\n  timestampUpdate: number,\n  particlesResolver: ParticlesResolverQueue,\n  queuePriority: QueuePriority,\n  abortSignal: AbortSignal\n) => {\n  const cyberlinksIterable = fetchCyberlinksIterable(\n    cid,\n    timestampUpdate,\n    abortSignal\n  );\n  const links = [];\n  // eslint-disable-next-line no-restricted-syntax\n  for await (const batch of cyberlinksIterable) {\n    links.push(...batch);\n    const particles = getUniqueParticlesFromLinks(batch);\n    if (particles.length > 0) {\n      await asyncIterableBatchProcessor(\n        particles,\n        (cids: ParticleCid[]) =>\n          particlesResolver!.enqueueBatch(cids, queuePriority),\n        MAX_LINKS_RESOLVE_BATCH\n      );\n    }\n  }\n\n  return links;\n};\n\nexport function extractCybelinksFromTransaction(batch: TransactionDto[]) {\n  const cyberlinks = batch.filter(\n    (l) => l.type === CYBER_LINK_TRANSACTION_TYPE\n  );\n  const particlesFound = new Set<string>();\n  const links: LinkDto[] = [];\n  // Get links: only from TWEETS\n  const tweets: Record<ParticleCid, LinkDto> = cyberlinks.reduce<\n    Record<ParticleCid, LinkDto>\n  >((acc, { value, hash, timestamp }: TransactionDto) => {\n    (value as CyberLinkValue).links.forEach((link) => {\n      particlesFound.add(link.to);\n      particlesFound.add(link.from);\n      const txLink = {\n        ...link,\n        timestamp,\n        neuron: (value as CyberLinkValue).neuron,\n        transactionHash: hash,\n      };\n      links.push(txLink);\n\n      if (link.from === CID_TWEET) {\n        acc[txLink.to] = txLink;\n      }\n    });\n    return acc;\n  }, {});\n\n  return {\n    tweets,\n    particlesFound: [...particlesFound],\n    links,\n  };\n}\n","import { NeuronAddress } from 'src/types/base';\nimport { numberToUtcDate } from 'src/utils/date';\nimport { fetchIterableByOffset } from 'src/utils/async/iterable';\nimport {\n  MessagesByAddressCountDocument,\n  MessagesByAddressCountQuery,\n  MessagesByAddressCountQueryVariables,\n  MessagesByAddressSenseDocument,\n  MessagesByAddressSenseQuery,\n  MessagesByAddressSenseQueryVariables,\n} from 'src/generated/graphql';\n\nimport { createIndexerClient } from './utils/graphqlClient';\nimport { Transaction } from './types';\n\ntype OrderDirection = 'desc' | 'asc';\ntype Abortable = { abortSignal: AbortSignal };\n\nexport type MessagesByAddressVariables = {\n  neuron: NeuronAddress;\n  timestampFrom: number;\n  offset?: number;\n  types: Transaction['type'][];\n  orderDirection: OrderDirection;\n  limit: number;\n} & Abortable;\n\nexport const mapMessagesByAddressVariables = ({\n  neuron,\n  timestampFrom,\n  offset = 0,\n  types = [],\n  orderDirection = 'desc',\n  limit,\n}: MessagesByAddressVariables) => ({\n  address: `{${neuron}}`,\n  limit,\n  timestamp_from: numberToUtcDate(timestampFrom),\n  offset,\n  types: `{${types.map((t) => `\"${t}\"`).join(' ,')}}`,\n  order_direction: orderDirection,\n});\n\nconst fetchTransactions = async ({\n  neuron,\n  timestampFrom,\n  offset = 0,\n  types = [],\n  orderDirection = 'desc',\n  limit,\n  abortSignal,\n}: MessagesByAddressVariables) => {\n  const res = await createIndexerClient(abortSignal).request<\n    MessagesByAddressSenseQuery,\n    MessagesByAddressSenseQueryVariables\n  >(\n    MessagesByAddressSenseDocument,\n    mapMessagesByAddressVariables({\n      neuron,\n      timestampFrom,\n      offset,\n      types,\n      orderDirection,\n      limit,\n      abortSignal,\n    }) as MessagesByAddressSenseQueryVariables\n  );\n\n  return res?.messages_by_address as Transaction[];\n};\n\nexport const fetchTransactionMessagesCount = async (\n  address: NeuronAddress,\n  timestampFrom: number,\n  abortSignal: AbortSignal\n) => {\n  const res = await createIndexerClient(abortSignal).request<\n    MessagesByAddressCountQuery,\n    MessagesByAddressCountQueryVariables\n  >(MessagesByAddressCountDocument, {\n    address: `{${address}}`,\n    timestamp: numberToUtcDate(timestampFrom),\n  });\n\n  return res?.messages_by_address_aggregate.aggregate?.count;\n};\n\nexport const fetchTransactionsIterable = ({\n  neuron,\n  timestampFrom,\n  types,\n  orderDirection,\n  limit,\n  abortSignal,\n}: MessagesByAddressVariables) =>\n  fetchIterableByOffset(fetchTransactions, {\n    neuron,\n    timestampFrom,\n    types,\n    orderDirection,\n    limit,\n    abortSignal,\n  });\n","import { TransactionDto } from 'src/services/CozoDb/types/dto';\nimport { SenseChat } from 'src/services/backend/types/sense';\nimport { NeuronAddress } from 'src/types/base';\nimport { Coin } from 'cosmjs-types/cosmos/base/v1beta1/coin';\n\nimport {\n  MSG_SEND_TRANSACTION_TYPE,\n  MSG_MULTI_SEND_TRANSACTION_TYPE,\n  MsgSendTransaction,\n} from '../../../indexer/types';\n\nexport const extractSenseChats = (\n  myAddress: NeuronAddress,\n  transactions: TransactionDto[]\n) => {\n  const sendTransactions =\n    transactions!.filter(\n      (t) =>\n        t.type === MSG_SEND_TRANSACTION_TYPE ||\n        t.type === MSG_MULTI_SEND_TRANSACTION_TYPE\n    ) || [];\n\n  if (sendTransactions.length === 0) {\n    return [];\n  }\n  const chats = new Map<NeuronAddress, SenseChat>();\n  transactions.forEach((t) => {\n    let userAddress = '';\n    if (t.type === MSG_MULTI_SEND_TRANSACTION_TYPE) {\n      const { inputs, outputs } = t.value;\n      const isSender = inputs.find((i) => i.address === myAddress);\n      const userMessages = isSender ? outputs : inputs;\n      userMessages.forEach((msg) =>\n        updateSenseChat(chats, msg.address, t, msg.coins, isSender)\n      );\n    } else if (t.type === MSG_SEND_TRANSACTION_TYPE) {\n      const { fromAddress, toAddress, amount } =\n        t.value as MsgSendTransaction['value'];\n      const isSender = fromAddress === myAddress;\n      userAddress = isSender ? toAddress : fromAddress;\n      updateSenseChat(chats, userAddress, t, amount, isSender);\n    }\n  });\n\n  return chats;\n};\n\nconst updateSenseChat = (\n  chats: Map<NeuronAddress, SenseChat>,\n  addr: string,\n  t: TransactionDto,\n  amount: Coin[],\n  isSender: boolean\n): Map<string, SenseChat> => {\n  const chat = chats.get(addr);\n  const transactions = chat?.transactions || [];\n\n  transactions.push(t);\n  chats.set(addr, {\n    userAddress: addr,\n    lastSendTimestamp: isSender ? t.timestamp : chat?.lastSendTimestamp || 0,\n    last: { amount, memo: t.memo, direction: isSender ? 'to' : 'from' },\n    transactions,\n  });\n  return chats;\n};\n","import { EntryType } from 'src/services/CozoDb/types/entities';\nimport DbApiWrapper from 'src/services/backend/services/DbApi/DbApi';\nimport { NeuronAddress } from 'src/types/base';\nimport {\n  SenseListItem,\n  SenseTransactionMeta,\n} from 'src/services/backend/types/sense';\nimport { throwIfAborted } from 'src/utils/async/promise';\nimport { extractSenseChats } from '../../utils/sense';\n\n// eslint-disable-next-line import/prefer-default-export\nexport const syncMyChats = async (\n  db: DbApiWrapper,\n  myAddress: NeuronAddress,\n  timestampFrom: number,\n  signal: AbortSignal,\n  shouldUpdateTimestamp = true\n) => {\n  const syncItems = await db.findSyncStatus({\n    ownerId: myAddress,\n    entryType: EntryType.chat,\n  });\n\n  const syncItemsMap = new Map(syncItems?.map((i) => [i.id, i]));\n\n  const myTransactions = await db.getTransactions(myAddress, {\n    order: 'asc',\n    timestampFrom,\n  });\n\n  const myChats = extractSenseChats(myAddress, myTransactions!);\n\n  const results: SenseListItem[] = [];\n\n  // eslint-disable-next-line no-restricted-syntax\n  for (const chat of myChats.values()) {\n    const syncItem = syncItemsMap.get(chat.userAddress);\n    const lastTransaction = chat.transactions.at(-1)!;\n\n    const { timestamp: transactionTimestamp, hash, index } = lastTransaction;\n    const syncItemHeader = {\n      entryType: EntryType.chat,\n      ownerId: myAddress,\n      meta: {\n        transactionHash: hash,\n        index,\n      } as SenseTransactionMeta,\n    };\n\n    // if no sync item(first message/initial)\n    if (!syncItem) {\n      const unreadCount = chat.transactions.filter(\n        (t) => t.timestamp > chat.lastSendTimestamp\n      ).length; // uread count on top of my last send message\n\n      const newItem = {\n        ...syncItemHeader,\n        id: chat.userAddress,\n        unreadCount,\n        // if 'fast' then no shift update poiter till 'slow' reupdate\n        timestampUpdate: shouldUpdateTimestamp ? transactionTimestamp : 0,\n        timestampRead: chat.lastSendTimestamp,\n        disabled: false,\n      };\n\n      // eslint-disable-next-line no-await-in-loop\n      await throwIfAborted(db.putSyncStatus.bind(db), signal)(newItem);\n\n      results.push({ ...newItem, meta: lastTransaction });\n    } else {\n      const {\n        id,\n        timestampRead,\n        timestampUpdate,\n        meta,\n        unreadCount: prevUnreadCount,\n      } = syncItem;\n\n      const lastTimestampRead = Math.max(\n        timestampRead!,\n        chat.lastSendTimestamp\n      );\n      const { timestampUpdateContent = 0, timestampUpdateChat = 0 } = meta;\n      const timestampUnreadFrom = Math.max(\n        chat.lastSendTimestamp,\n        timestampUpdateChat\n      );\n      const unreadCount =\n        prevUnreadCount +\n        chat.transactions.filter((t) => t.timestamp > timestampUnreadFrom) // + new messages count\n          .length;\n\n      if (timestampUpdate < transactionTimestamp) {\n        // if message source is 'fast' then no update till 'slow' reupdate\n        const newTimestampUpdateChat = shouldUpdateTimestamp\n          ? transactionTimestamp\n          : timestampUpdateChat;\n\n        const syncStatusChanges = {\n          ...syncItemHeader,\n          id: id!,\n          unreadCount,\n          timestampRead: lastTimestampRead,\n          // show max timestamp to use in sorting, in sense list\n          // real timestamp shold be resynced with 'slow' data source by timestampUpdateChat\n          timestampUpdate: Math.max(\n            transactionTimestamp,\n            timestampUpdateContent,\n            newTimestampUpdateChat\n          ),\n\n          meta: {\n            ...syncItemHeader.meta,\n            timestampUpdateChat: newTimestampUpdateChat,\n            timestampUpdateContent,\n          },\n        };\n\n        // eslint-disable-next-line no-await-in-loop\n        await throwIfAborted(\n          db.updateSyncStatus.bind(db),\n          signal\n        )(syncStatusChanges);\n\n        results.push({\n          ...syncItem,\n          ...syncStatusChanges,\n          meta: lastTransaction,\n        } as SenseListItem);\n      }\n    }\n  }\n  return results;\n};\n","import { ProgressTracking } from 'src/services/backend/types/services';\n\nconst ROLLING_WINDOW = 10;\n\ntype onProgressUpdateFunc = (progress: ProgressTracking) => void;\n\ntype RequestRecord = {\n  timestamp: number;\n  itemCount: number;\n};\n\n// eslint-disable-next-line import/no-unused-modules, import/prefer-default-export\nexport class ProgressTracker {\n  private requestRecords: RequestRecord[] = [];\n\n  private totalRequests = 0;\n\n  private completedRequests = 0;\n\n  private estimatedTime = -1;\n\n  private batchSize = 1;\n\n  private onProgressUpdate?: onProgressUpdateFunc;\n\n  public get progress(): ProgressTracking {\n    return {\n      totalCount: this.totalRequests,\n      completeCount: this.completedRequests,\n      estimatedTime: this.estimatedTime,\n    };\n  }\n\n  constructor(onProgressUpdate?: onProgressUpdateFunc) {\n    this.onProgressUpdate = onProgressUpdate;\n  }\n\n  public start(totalRequests: number, batchSize = 1) {\n    this.totalRequests = totalRequests;\n    this.requestRecords = [];\n    this.completedRequests = 0;\n    this.estimatedTime = -1;\n    this.batchSize = batchSize;\n\n    return this.progress;\n  }\n\n  public add(extraRequests: number) {\n    this.totalRequests += extraRequests;\n\n    return this.progress;\n  }\n\n  public trackProgress(processedCount: number) {\n    this.addRequestRecord(processedCount);\n\n    if (this.requestRecords.length > ROLLING_WINDOW) {\n      this.requestRecords.shift();\n    }\n\n    if (this.requestRecords.length > 1) {\n      const averageTimePerItem = this.calculateAverageTimePerItem();\n      const remainingRequests = this.totalRequests - this.completedRequests;\n      const estimatedRemainingItems = remainingRequests * processedCount; // Assuming remaining requests will process the same number of items\n      const estimatedRemainingTime =\n        averageTimePerItem * estimatedRemainingItems;\n\n      this.completedRequests += processedCount;\n      this.estimatedTime = Math.round(estimatedRemainingTime); // Convert to seconds;\n      this.onProgressUpdate && this.onProgressUpdate(this.progress);\n    }\n\n    return this.progress;\n  }\n\n  private addRequestRecord(itemCount: number) {\n    this.requestRecords.push({ timestamp: Date.now(), itemCount });\n  }\n\n  private calculateAverageTimePerItem(): number {\n    let totalDiff = 0;\n    let totalItems = 0;\n\n    for (let i = 1; i < this.requestRecords.length; i++) {\n      const timeDiff =\n        this.requestRecords[i].timestamp - this.requestRecords[i - 1].timestamp;\n      const { itemCount } = this.requestRecords[i];\n\n      totalDiff += timeDiff * itemCount;\n      totalItems += itemCount;\n    }\n\n    return totalItems === 0 ? 0 : totalDiff / totalItems;\n  }\n}\n","import {\n  Observable,\n  filter,\n  distinctUntilChanged,\n  map,\n  switchMap,\n  take,\n  tap,\n} from 'rxjs';\n\nimport BroadcastChannelSender from 'src/services/backend/channels/BroadcastChannelSender';\nimport { broadcastStatus } from 'src/services/backend/channels/broadcastStatus';\nimport { SyncEntryName } from 'src/services/backend/types/services';\nimport { CyblogChannel, createCyblogChannel } from 'src/utils/logging/cyblog';\n\nimport DbApiWrapper from '../../../DbApi/DbApi';\nimport ParticlesResolverQueue from '../ParticlesResolverQueue/ParticlesResolverQueue';\nimport { ProgressTracker } from '../ProgressTracker/ProgressTracker';\nimport { ServiceDeps } from '../types';\nimport { SyncServiceParams } from '../../types';\n\nabstract class BaseSync {\n  protected name: string;\n\n  protected abortController: AbortController;\n\n  protected db: DbApiWrapper | undefined;\n\n  protected progressTracker = new ProgressTracker();\n\n  protected channelApi = new BroadcastChannelSender();\n\n  protected particlesResolver: ParticlesResolverQueue | undefined;\n\n  protected statusApi: ReturnType<typeof broadcastStatus>;\n\n  protected params: SyncServiceParams = {\n    myAddress: null,\n  };\n\n  protected readonly isInitialized$: Observable<boolean>;\n\n  protected cyblogCh: CyblogChannel;\n\n  constructor(\n    name: SyncEntryName,\n    deps: ServiceDeps,\n    particlesResolver: ParticlesResolverQueue\n  ) {\n    this.name = name;\n\n    this.abortController = new AbortController();\n\n    this.statusApi = broadcastStatus(name, this.channelApi);\n    this.particlesResolver = particlesResolver;\n    this.cyblogCh = createCyblogChannel({ thread: 'bckd', module: name });\n    if (!deps.params$) {\n      throw new Error('params$ is not defined');\n    }\n\n    deps.dbInstance$.subscribe((db) => {\n      this.db = db;\n    });\n\n    this.particlesResolver = particlesResolver;\n\n    this.isInitialized$ = this.createIsInitializedObserver(deps);\n\n    this.isInitialized$.subscribe((isInitialized) => {\n      this.cyblogCh.info(\n        `>>> ${this.name} - ${isInitialized ? 'initialized' : 'inactive'}`\n      );\n      this.statusApi.sendStatus(isInitialized ? 'initialized' : 'inactive');\n    });\n\n    this.isInitialized$\n      .pipe(switchMap(() => deps.params$!))\n      .subscribe((params) => {\n        this.params = params;\n        this.cyblogCh.info(`>>> ${this.name} - params updated`, {\n          data: params,\n        });\n      });\n\n    // Restart observer\n    this.isInitialized$\n      .pipe(\n        filter((isInitialized) => !!isInitialized),\n        switchMap(() => this.createRestartObserver(deps.params$!))\n      )\n      .subscribe(() => {\n        this.restart();\n      });\n  }\n\n  protected initAbortController() {\n    this.abortController = new AbortController();\n  }\n\n  protected abstract createIsInitializedObserver(\n    deps: ServiceDeps\n  ): Observable<boolean>;\n\n  // eslint-disable-next-line class-methods-use-this\n  protected createRestartObserver(params$: Observable<SyncServiceParams>) {\n    return params$.pipe(\n      map((params) => params.myAddress),\n      distinctUntilChanged((addrBefore, addrAfter) => addrBefore === addrAfter),\n      map((v) => !!v),\n      filter((v) => !!v)\n    );\n  }\n\n  public abstract restart(): void;\n\n  public abstract start(): void;\n}\n\nexport default BaseSync;\n","/* eslint-disable import/prefer-default-export */\nimport {\n  distinctUntilChanged,\n  filter,\n  Observable,\n  share,\n  switchMap,\n  tap,\n} from 'rxjs';\n\nexport const switchWhenInitialized = (\n  isInitialized$: Observable<boolean>,\n  actionObservable$: Observable<any>,\n  onChange?: (isInitialized: boolean) => void\n) =>\n  isInitialized$.pipe(\n    distinctUntilChanged(),\n    tap((isInitialized) => onChange?.(isInitialized)),\n    filter((initialized) => initialized),\n    switchMap(() => actionObservable$),\n    share()\n  );\n","import { Observable, Subject, from, startWith, switchMap, tap } from 'rxjs';\n\nimport { SyncEntryName } from 'src/services/backend/types/services';\n\nimport ParticlesResolverQueue from '../ParticlesResolverQueue/ParticlesResolverQueue';\nimport { ServiceDeps } from '../types';\nimport BaseSync from './BaseSync';\nimport { switchWhenInitialized } from '../utils/rxjs/withInitializer';\nimport { SyncServiceParams } from '../../types';\n\nabstract class BaseSyncClient extends BaseSync {\n  protected readonly source$: Observable<any>;\n\n  protected readonly reloadTrigger$ = new Subject<void>();\n\n  constructor(\n    name: SyncEntryName,\n    deps: ServiceDeps,\n    particlesResolver: ParticlesResolverQueue\n  ) {\n    super(name, deps, particlesResolver);\n\n    const source$ = switchWhenInitialized(\n      this.isInitialized$!,\n      this.reloadTrigger$.pipe(\n        startWith(null),\n        tap(() => {\n          // initialize abort conteoller for restart strategy\n          this.initAbortController();\n        }),\n        switchMap(() =>\n          this.createInitObservable().pipe(\n            switchMap((timestampFrom: number) =>\n              this.createClientObservable(timestampFrom).pipe(\n                tap(() => this.statusApi.sendStatus('listen')),\n                switchMap((data) => from(this.onUpdate(data, this.params)))\n              )\n            )\n          )\n        )\n      ),\n      (isInitialized) => {\n        console.log(`>>> ${name} isInitialized`, isInitialized);\n        this.statusApi.sendStatus(isInitialized ? 'initialized' : 'inactive');\n      }\n    );\n\n    source$.subscribe({\n      next: () => {\n        this.statusApi.sendStatus('listen');\n      },\n      error: (err) => {\n        this.statusApi.sendStatus('error', err);\n      },\n    });\n    this.source$ = source$;\n  }\n\n  protected abstract createClientObservable(\n    timestampFrom: number\n  ): Observable<any>;\n\n  protected abstract createInitObservable(): Observable<number>;\n\n  public restart() {\n    this.abortController?.abort();\n    this.reloadTrigger$.next();\n    console.log(`>>> ${this.name} client restart`);\n  }\n\n  protected abstract onUpdate(\n    data: any,\n    params: SyncServiceParams\n  ): Promise<void>;\n\n  public start() {\n    this.source$.subscribe(() => {\n      // dummy subscriber to keep pipeline running - don't remove\n    });\n    return this;\n  }\n}\n\nexport default BaseSyncClient;\n","/* eslint-disable camelcase */\nimport {\n  map,\n  combineLatest,\n  Observable,\n  from,\n  defer,\n  distinctUntilChanged,\n  merge,\n  filter,\n} from 'rxjs';\nimport { isEmpty } from 'lodash';\n\nimport { EntryType } from 'src/services/CozoDb/types/entities';\nimport { mapIndexerTransactionToEntity } from 'src/services/CozoDb/mapping';\nimport { numberToUtcDate } from 'src/utils/date';\nimport { NeuronAddress } from 'src/types/base';\nimport { QueuePriority } from 'src/services/QueueManager/types';\nimport { SyncStatusDto, TransactionDto } from 'src/services/CozoDb/types/dto';\nimport { asyncIterableBatchProcessor } from 'src/utils/async/iterable';\nimport { throwIfAborted } from 'src/utils/async/promise';\nimport {\n  createNodeWebsocketObservable,\n  getIncomingTransfersQuery,\n} from 'src/services/lcd/websocket';\nimport {\n  MessagesByAddressSenseQueryVariables,\n  MessagesByAddressSenseWsDocument,\n  MessagesByAddressSenseWsSubscription,\n} from 'src/generated/graphql';\n\nimport { mapWebsocketTxToTransactions } from 'src/services/lcd/utils/mapping';\n\nimport { ServiceDeps } from '../types';\nimport { extractCybelinksFromTransaction } from '../utils/links';\n\nimport {\n  fetchTransactionsIterable,\n  mapMessagesByAddressVariables,\n  fetchTransactionMessagesCount,\n} from '../../../indexer/transactions';\nimport { syncMyChats } from './services/chat';\nimport { TRANSACTIONS_BATCH_LIMIT } from '../../../indexer/consts';\nimport BaseSyncClient from '../BaseSyncLoop/BaseSyncClient';\nimport { createIndexerWebsocket } from '../../../indexer/utils/graphqlClient';\nimport { SyncServiceParams } from '../../types';\nimport { MAX_DATABASE_PUT_SIZE } from '../consts';\n\ntype DataStreamResult = {\n  source: 'indexer' | 'node';\n  transactions: TransactionDto[];\n};\n\nclass SyncTransactionsLoop extends BaseSyncClient {\n  protected createIsInitializedObserver(deps: ServiceDeps) {\n    const isInitialized$ = combineLatest([\n      deps.dbInstance$,\n      deps.params$!.pipe(\n        map((params) => params.myAddress),\n        distinctUntilChanged()\n      ),\n      this.particlesResolver!.isInitialized$,\n    ]).pipe(\n      map(\n        ([dbInstance, myAddress, syncQueueInitialized]) =>\n          !!dbInstance && !!syncQueueInitialized && !!myAddress\n      )\n    );\n\n    return isInitialized$;\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  protected createClientObservable(\n    timestampFrom: number\n  ): Observable<DataStreamResult> {\n    const { myAddress } = this.params;\n    this.cyblogCh.info(\n      `>>> ${this.name} subscribe ${myAddress} from ${numberToUtcDate(\n        timestampFrom\n      )}`\n    );\n\n    const variables = mapMessagesByAddressVariables({\n      neuron: myAddress!,\n      timestampFrom,\n      types: [],\n      orderDirection: 'desc',\n      limit: 100,\n    }) as MessagesByAddressSenseQueryVariables;\n\n    const indexerObservable$ =\n      createIndexerWebsocket<MessagesByAddressSenseWsSubscription>(\n        MessagesByAddressSenseWsDocument,\n        variables\n      ).pipe(\n        map((response: MessagesByAddressSenseWsSubscription) => {\n          return {\n            source: 'indexer',\n            transactions: response.messages_by_address.map((i) =>\n              mapIndexerTransactionToEntity(myAddress!, i)\n            ),\n          };\n        })\n      );\n\n    const nodeObservample$ = createNodeWebsocketObservable(\n      myAddress!,\n      getIncomingTransfersQuery(myAddress!),\n      (message, ctx) => this.cyblogCh.info(message, { unit: 'node-ws', ...ctx })\n    ).pipe(\n      filter((data) => !isEmpty(data)),\n      map((data) => {\n        return {\n          source: 'node',\n          transactions: mapWebsocketTxToTransactions(myAddress!, data),\n        };\n      })\n    );\n\n    return merge(\n      indexerObservable$,\n      nodeObservample$\n    ) as Observable<DataStreamResult>;\n  }\n\n  protected createInitObservable() {\n    return defer(() => from(this.initSync()));\n    // return from(this.initSync());\n  }\n\n  public async initSync() {\n    const { myAddress } = this.params;\n    const { signal } = this.abortController;\n    const syncItem = await this.db!.getSyncStatus(myAddress!, myAddress!);\n\n    const lastTransactionTimestamp = await this.syncTransactions(\n      myAddress!,\n      myAddress!,\n      syncItem\n    );\n\n    this.statusApi.sendStatus('in-progress', `sync my chats`);\n    const syncStatusItems = await syncMyChats(\n      this.db!,\n      myAddress!,\n      syncItem.timestampUpdate,\n      signal\n    );\n\n    this.channelApi.postSenseUpdate(syncStatusItems);\n    this.statusApi.sendStatus('active');\n\n    return lastTransactionTimestamp;\n  }\n\n  protected async onUpdate(\n    { source, transactions }: DataStreamResult,\n    params: SyncServiceParams\n  ) {\n    const { myAddress } = params;\n    const { signal } = this.abortController;\n    if (transactions.length === 0) {\n      this.cyblogCh.info(`>>> ${this.name} ${myAddress} recived 0 updates `);\n      return;\n    }\n    const syncItem = await this.db!.getSyncStatus(myAddress!, myAddress!);\n\n    await this.processBatchTransactions(\n      myAddress!,\n      myAddress!,\n      transactions,\n      syncItem,\n      source\n    );\n\n    this.statusApi.sendStatus('in-progress', `sync my chats`);\n    const syncStatusItems = await syncMyChats(\n      this.db!,\n      myAddress!,\n      syncItem.timestampUpdate,\n      signal,\n      source !== 'node'\n    );\n\n    this.channelApi.postSenseUpdate(syncStatusItems);\n    this.statusApi.sendStatus('listen');\n  }\n\n  public async processBatchTransactions(\n    myAddress: NeuronAddress,\n    address: NeuronAddress,\n    transactions: TransactionDto[],\n    { timestampRead, unreadCount, timestampUpdate }: SyncStatusDto,\n    source: DataStreamResult['source']\n  ) {\n    const { signal } = this.abortController;\n\n    // node transaction is limited by incoming messages,\n    // to prevent missing of other msg types let's avoid to change ts\n    const shouldUpdateTimestamp = source !== 'node';\n\n    this.cyblogCh.info(\n      `   syncTransactions - process ${address}[${source}],  count: ${\n        transactions.length\n      }, from: ${transactions.at(0)?.timestamp}, to: ${\n        transactions.at(-1)?.timestamp\n      }`\n    );\n\n    // save transaction\n    await throwIfAborted(this.db!.putTransactions, signal)(transactions);\n\n    // save links\n    this.syncLinks(transactions, signal);\n\n    const {\n      hash,\n      index,\n\n      timestamp,\n    } = transactions.at(-1)!;\n\n    const lastTimestampFrom = timestamp;\n\n    // Update transaction sync items\n    const newSyncItem = {\n      ownerId: myAddress,\n      entryType: EntryType.transactions,\n      id: address,\n      timestampUpdate: shouldUpdateTimestamp\n        ? lastTimestampFrom\n        : timestampUpdate!,\n      unreadCount: unreadCount! + transactions.length,\n      timestampRead: timestampRead || 0,\n      disabled: false,\n      meta: {\n        transactionHash: hash,\n        index,\n      },\n    };\n\n    await throwIfAborted(this.db!.putSyncStatus, signal)(newSyncItem);\n\n    return lastTimestampFrom;\n  }\n\n  public async syncTransactions(\n    myAddress: NeuronAddress,\n    address: NeuronAddress,\n    syncItem: SyncStatusDto\n  ) {\n    const { unreadCount, timestampUpdate } = syncItem;\n    const timestampFrom = timestampUpdate + 1; // ofsset + 1 to fix milliseconds precision bug\n\n    this.statusApi.sendStatus('estimating');\n\n    const totalMessageCount = await fetchTransactionMessagesCount(\n      address,\n      timestampFrom,\n      this.abortController!.signal\n    );\n\n    this.cyblogCh.info(\n      `>>> syncTransactions - start ${address},  count: ${totalMessageCount}, from: ${timestampFrom}`\n    );\n\n    if (totalMessageCount === 0) {\n      return timestampFrom;\n    }\n\n    this.statusApi.sendStatus(\n      'in-progress',\n      `sync ${address}...`,\n      this.progressTracker.start(\n        Math.ceil(totalMessageCount / TRANSACTIONS_BATCH_LIMIT)\n      )\n    );\n\n    const transactionsAsyncIterable = fetchTransactionsIterable({\n      neuron: address,\n      timestampFrom,\n      types: [], // SENSE_TRANSACTIONS,\n      orderDirection: 'asc',\n      limit: TRANSACTIONS_BATCH_LIMIT,\n      abortSignal: this.abortController?.signal,\n    });\n\n    let transactionCount = 0;\n    let lastTimestampFrom = timestampFrom;\n\n    // eslint-disable-next-line no-restricted-syntax\n    for await (const batch of transactionsAsyncIterable) {\n      this.statusApi.sendStatus(\n        'in-progress',\n        `sync ${address}...`,\n        this.progressTracker.trackProgress(1)\n      );\n\n      transactionCount += batch.length;\n\n      const transactions = batch.map((i) =>\n        mapIndexerTransactionToEntity(address, i)\n      );\n\n      lastTimestampFrom = await this.processBatchTransactions(\n        myAddress,\n        address,\n        transactions,\n        {\n          ...syncItem,\n          unreadCount: unreadCount + transactionCount,\n        },\n        'indexer'\n      );\n    }\n\n    return lastTimestampFrom;\n  }\n\n  private async syncLinks(batch: TransactionDto[], signal: AbortSignal) {\n    const { tweets, particlesFound, links } =\n      extractCybelinksFromTransaction(batch);\n    if (links.length > 0) {\n      await asyncIterableBatchProcessor(\n        links,\n        (links) => throwIfAborted(this.db!.putCyberlinks, signal)(links),\n        MAX_DATABASE_PUT_SIZE\n      );\n    }\n\n    const tweetParticles = Object.keys(tweets);\n\n    const nonTweetParticles = particlesFound.filter(\n      (cid) => !tweetParticles.includes(cid)\n    );\n\n    // pre-resolve 'tweets' particles\n    await this.particlesResolver!.enqueueBatch(\n      tweetParticles,\n      QueuePriority.HIGH\n    );\n\n    // pre-resolve all the rest particles\n    if (nonTweetParticles.length > 0) {\n      await this.particlesResolver!.enqueueBatch(\n        nonTweetParticles,\n        QueuePriority.LOW\n      );\n    }\n  }\n}\n\nexport default SyncTransactionsLoop;\n","import { Observable } from 'rxjs';\nimport { WEBSOCKET_URL } from 'src/constants/config';\nimport { NeuronAddress } from 'src/types/base';\nimport { LogFunc } from 'src/utils/logging/cyblog';\n\nexport const getIncomingTransfersQuery = (address: NeuronAddress) =>\n  `tm.event='Tx' AND transfer.recipient='${address}'`;\n\n// eslint-disable-next-line import/no-unused-modules\nexport function createNodeWebsocketObservable(\n  address: NeuronAddress,\n  query: string,\n  log: LogFunc\n) {\n  return new Observable((subscriber) => {\n    const ws = new WebSocket(WEBSOCKET_URL);\n\n    ws.onopen = () => {\n      log(`node ws connected to ${WEBSOCKET_URL} with ${query}`);\n      ws.send(\n        JSON.stringify({\n          jsonrpc: '2.0',\n          method: 'subscribe',\n          id: '0',\n          params: { query },\n        })\n      );\n    };\n\n    ws.onmessage = (event) => {\n      const message = JSON.parse(event.data);\n      log(`node ws ${address} onmessage`, message);\n      subscriber.next(message.result);\n    };\n\n    ws.onerror = (event) => {\n      log(`node ws ${address} error`, { error: event });\n      subscriber.error(event);\n    };\n\n    ws.onclose = () => {\n      log(`node ws ${address} closed`);\n      subscriber.complete();\n    };\n\n    return () => {\n      ws.close();\n    };\n  });\n}\n","import { EntityToDto, DtoToEntity } from 'src/types/dto';\n\nexport const snakeToCamel = (str: string) =>\n  str.replace(/([-_][a-z])/g, (group) =>\n    group.toUpperCase().replace('-', '').replace('_', '')\n  );\n\nexport const camelToSnake = (str: string) =>\n  str.replace(/[A-Z]/g, (letter) => `_${letter.toLowerCase()}`);\n// Function to transform a DB entity to a DTO\n\n// eslint-disable-next-line import/no-unused-modules\nexport function entityToDto<T extends Record<string, any>>(\n  dbEntity: T\n): EntityToDto<T> {\n  if (!dbEntity || typeof dbEntity !== 'object') {\n    return dbEntity;\n  }\n  const dto: Record<string, any> = {}; // Specify the type for dto\n  Object.keys(dbEntity).forEach((key) => {\n    if (Object.prototype.hasOwnProperty.call(dbEntity, key)) {\n      const camelCaseKey = snakeToCamel(key);\n      let value = dbEntity[key];\n      if (Array.isArray(dbEntity[key])) {\n        value = dbEntity[key].map((item) => entityToDto(item));\n      } else if (typeof dbEntity[key] === 'object') {\n        value = entityToDto(dbEntity[key]);\n      }\n      dto[camelCaseKey] = value;\n    }\n  });\n  return dto as EntityToDto<T>;\n}\n\n// eslint-disable-next-line import/no-unused-modules\nexport function dtoToEntity<T extends Record<string, any>>(\n  dto: T\n): DtoToEntity<T> {\n  // in case of recursive calls\n  if (!dto || typeof dto !== 'object') {\n    return dto;\n  }\n  const dbEntity: any = {};\n\n  Object.keys(dto).forEach((key) => {\n    if (Object.prototype.hasOwnProperty.call(dto, key)) {\n      const snakeCaseKey = camelToSnake(key);\n      let value = dto[key];\n      if (Array.isArray(dto[key])) {\n        value = dto[key].map((item) => dtoToEntity(item));\n      } else if (typeof dto[key] === 'object') {\n        value = dtoToEntity(dto[key]);\n      }\n      dbEntity[snakeCaseKey] = value;\n    }\n  });\n  return dbEntity as DtoToEntity<T>; // Replace T with the appropriate DB Entity type if known\n}\n\nexport function dtoListToEntity<T extends Record<string, any>>(\n  array: T[]\n): DtoToEntity<T>[] {\n  return array.map((dto) => dtoToEntity(dto));\n}\n\nexport function entityListToDto<T extends Record<string, any>>(\n  array: T[]\n): EntityToDto<T>[] {\n  return array.map((dto) => entityToDto(dto));\n}\n\nexport function removeUndefinedFields(entity: Record<string, any>) {\n  Object.keys(entity).forEach((key) => {\n    if (entity[key] === undefined) {\n      delete entity[key];\n    }\n  });\n  return entity;\n}\n","import { NeuronAddress } from 'src/types/base';\nimport { LinkDto, SyncStatusDto } from 'src/services/CozoDb/types/dto';\nimport { EntryType } from 'src/services/CozoDb/types/entities';\n\nimport { findLastIndex } from 'lodash';\nimport { entityToDto } from 'src/utils/dto';\n\nimport { SenseItemLinkMeta } from '../../types/sense';\nimport { SyncEntryName } from '../../types/services';\n\nexport function getLastReadInfo(\n  links: LinkDto[],\n  ownerId: NeuronAddress,\n  prevTimestampRead = 0,\n  prevUnreadCount = 0\n) {\n  const lastUnreadLinks = links.filter(\n    (link) => link.timestamp > prevTimestampRead\n  );\n  const lastMyLinkIndex = findLastIndex(\n    lastUnreadLinks,\n    (link) => link.neuron === ownerId\n  );\n\n  const unreadCount =\n    lastMyLinkIndex < 0\n      ? prevUnreadCount + lastUnreadLinks.length\n      : lastUnreadLinks.length - lastMyLinkIndex - 1;\n\n  const timestampRead =\n    lastMyLinkIndex < 0 ? prevTimestampRead : links[lastMyLinkIndex].timestamp;\n\n  return {\n    timestampRead,\n    unreadCount,\n  };\n}\n\nexport function changeParticleSyncStatus(\n  syncStatus: Partial<SyncStatusDto>,\n  links: LinkDto[],\n  ownerId: NeuronAddress,\n  shouldUpdateTimestamp = true\n) {\n  const { timestampRead, unreadCount } = getLastReadInfo(\n    links,\n    ownerId,\n    syncStatus.timestampRead,\n    syncStatus.unreadCount\n  );\n\n  const lastLink = entityToDto(links[links.length - 1]);\n  const timestampUpdate = lastLink.timestamp;\n  return {\n    ...syncStatus,\n    ownerId,\n    entryType: EntryType.particle,\n    disabled: false,\n    unreadCount,\n    meta: {\n      ...lastLink,\n      timestamp: timestampUpdate,\n    } as SenseItemLinkMeta,\n    timestampRead,\n    timestampUpdate: shouldUpdateTimestamp\n      ? timestampUpdate\n      : syncStatus.timestampUpdate,\n  } as SyncStatusDto;\n}\n\nconst mapSyncEntryReadable: Record<SyncEntryName, string> = {\n  'my-friends': \"friend's logs\",\n  particles: 'log cyberlinks',\n  resolver: 'particles',\n  transactions: 'transactions',\n  pin: 'ipfs pins',\n};\n\nexport const syncEntryNameToReadable = (name: SyncEntryName) =>\n  mapSyncEntryReadable[name] || name;\n","export const isAbortException = (e: Error) =>\n  e instanceof DOMException && e.name === 'AbortError';\n","import { Observable, defer, filter, from, tap } from 'rxjs';\n\nimport { SyncEntryName } from 'src/services/backend/types/services';\nimport { isAbortException } from 'src/utils/exceptions/helpers';\nimport { clone } from 'ramda';\n\nimport ParticlesResolverQueue from '../ParticlesResolverQueue/ParticlesResolverQueue';\nimport { ServiceDeps } from '../types';\nimport { createLoopObservable } from '../utils/rxjs/loop';\nimport BaseSync from './BaseSync';\nimport { SyncServiceParams } from '../../types';\n\nabstract class BaseSyncLoop extends BaseSync {\n  private restartLoop: (() => void) | undefined;\n\n  public readonly loop$: Observable<boolean>;\n\n  constructor(\n    name: SyncEntryName,\n    intervalMs: number,\n    deps: ServiceDeps,\n    particlesResolver: ParticlesResolverQueue,\n    {\n      warmupMs,\n    }: {\n      warmupMs: number;\n    } = { warmupMs: 0 }\n  ) {\n    super(name, deps, particlesResolver);\n\n    const { loop$, restartLoop } = createLoopObservable(\n      this.isInitialized$,\n      // defer(() => from(this.sync())),\n      defer(() => from(this.doSync())),\n      {\n        intervalMs,\n        warmupMs,\n        // onStartInterval: () => this.initAbortController(),\n        onError: (error) => {\n          this.cyblogCh.info(`>>> ${name} error`, error.toString());\n          this.statusApi.sendStatus('error', error.toString());\n        },\n        onChange: (isInitialized) => {\n          this.cyblogCh.info(`>>> ${name} initialized: ${isInitialized}`);\n          this.statusApi.sendStatus(isInitialized ? 'initialized' : 'inactive');\n        },\n      }\n    );\n\n    this.loop$ = loop$;\n    this.restartLoop = restartLoop;\n  }\n\n  public restart() {\n    this.abortController?.abort();\n    this.restartLoop?.();\n    this.cyblogCh.info(`>>> ${this.name} loop restart`);\n  }\n\n  public start() {\n    this.loop$.subscribe(() => this.statusApi.sendStatus('active'));\n    return this;\n  }\n\n  private async doSync() {\n    const params = clone(this.params);\n    this.initAbortController();\n    try {\n      await this.sync(params);\n    } catch (e) {\n      const isAborted = isAbortException(e);\n      this.cyblogCh.info(\n        `>>> ${this.name} ${params.myAddress} sync error [abrt:${isAborted}]:`,\n        {\n          error: e,\n        }\n      );\n\n      if (!isAborted) {\n        throw e;\n      }\n    }\n  }\n\n  protected abstract sync(params: SyncServiceParams): Promise<void>;\n}\n\nexport default BaseSyncLoop;\n","/* eslint-disable import/prefer-default-export */\nimport {\n  Observable,\n  switchMap,\n  interval,\n  startWith,\n  tap,\n  retry,\n  delay,\n  exhaustMap,\n  Subject,\n} from 'rxjs';\nimport { switchWhenInitialized } from './withInitializer';\n\ntype LoopObservableOptions = {\n  warmupMs?: number;\n  retryDelayMs?: number;\n  onStartInterval?: () => void;\n  onError?: (error: any) => void;\n  onChange?: (isInitialized: boolean) => void;\n  intervalMs?: number;\n};\n\nexport const createLoopObservable = (\n  isInitialized$: Observable<boolean>,\n  actionObservable$: Observable<any>,\n  options: LoopObservableOptions = {}\n) => {\n  const {\n    intervalMs,\n    warmupMs = 0,\n    onStartInterval,\n    onError,\n    retryDelayMs = 0,\n    onChange,\n  } = options;\n\n  const restartTrigger$ = new Subject<void>();\n\n  const intervalOrRestart$ = restartTrigger$.pipe(\n    startWith(null),\n    switchMap(() => interval(intervalMs).pipe(startWith(0), delay(warmupMs)))\n  );\n\n  const source$ = switchWhenInitialized(\n    isInitialized$,\n    intervalOrRestart$.pipe(\n      tap(() => onStartInterval && onStartInterval()),\n      exhaustMap(() =>\n        actionObservable$.pipe(\n          retry({\n            delay: (error) => {\n              console.log('retry', error);\n              onError && onError(error);\n              return interval(retryDelayMs);\n            },\n          })\n        )\n      )\n    ),\n    (isInitialized) => onChange?.(isInitialized)\n  );\n\n  return {\n    loop$: source$,\n    restartLoop: () => {\n      // console.log('>>> createLoopObservable restart');\n      // Trigger a restart by emitting a new value\n      restartTrigger$.next();\n    },\n  };\n};\n","import { map, combineLatest, distinctUntilChanged } from 'rxjs';\nimport { EntryType } from 'src/services/CozoDb/types/entities';\nimport { SyncStatusDto } from 'src/services/CozoDb/types/dto';\nimport { QueuePriority } from 'src/services/QueueManager/types';\nimport { NeuronAddress } from 'src/types/base';\n\nimport { mapLinkFromIndexerToDto } from 'src/services/CozoDb/mapping';\nimport { CID_TWEET } from 'src/constants/app';\nimport { dateToUtcNumber } from 'src/utils/date';\nimport { SenseListItem } from 'src/services/backend/types/sense';\nimport { asyncIterableBatchProcessor } from 'src/utils/async/iterable';\nimport { throwIfAborted } from 'src/utils/async/promise';\nimport { entityToDto } from 'src/utils/dto';\n\nimport { ServiceDeps } from '../types';\nimport { fetchCyberlinksAndResolveParticles } from '../utils/links';\n\nimport { changeParticleSyncStatus } from '../../utils';\nimport {\n  fetchCyberlinksByNerounIterable,\n  fetchCyberlinksCount,\n} from '../../../indexer/cyberlinks';\nimport { CYBERLINKS_BATCH_LIMIT } from '../../../indexer/consts';\nimport BaseSyncLoop from '../BaseSyncLoop/BaseSyncLoop';\nimport { MAX_DATABASE_PUT_SIZE } from '../consts';\nimport { SyncServiceParams } from '../../types';\n\nclass SyncParticlesLoop extends BaseSyncLoop {\n  protected createIsInitializedObserver(deps: ServiceDeps) {\n    const isInitialized$ = combineLatest([\n      deps.dbInstance$,\n      deps.ipfsInstance$,\n      deps.params$!.pipe(\n        map((params) => params.myAddress),\n        distinctUntilChanged()\n      ),\n      this.particlesResolver!.isInitialized$,\n    ]).pipe(\n      map(\n        ([dbInstance, ipfsInstance, myAddress, particleResolverInitialized]) =>\n          !!ipfsInstance &&\n          !!dbInstance &&\n          !!particleResolverInitialized &&\n          !!myAddress\n      )\n    );\n\n    return isInitialized$;\n  }\n\n  protected async sync(params: SyncServiceParams): Promise<void> {\n    const { myAddress } = params;\n    const { signal } = this.abortController;\n    this.statusApi.sendStatus('estimating');\n\n    const syncItemParticles = await this.db!.findSyncStatus({\n      ownerId: myAddress!,\n      entryType: EntryType.particle,\n    });\n\n    const timestampUpdate = syncItemParticles.at(0)?.timestampUpdate || 0;\n\n    // Get count of new links after last update\n    const newLinkCount = await fetchCyberlinksCount(\n      myAddress!,\n      [CID_TWEET],\n      timestampUpdate,\n      signal\n    );\n\n    this.cyblogCh.info(\n      `>>> syncMyParticles ${myAddress} count ${newLinkCount}`\n    );\n    this.progressTracker.start(newLinkCount + syncItemParticles.length);\n    this.statusApi.sendStatus(\n      'in-progress',\n      'preparing...',\n      this.progressTracker.progress\n    );\n\n    if (newLinkCount > 0) {\n      // fetch and save new particles\n      const newSyncItemParticles = await this.fetchNewTweets(\n        myAddress!,\n        timestampUpdate,\n        signal\n      );\n\n      // add to fetch-sync linked particles\n      syncItemParticles.push(...newSyncItemParticles);\n    }\n    await this.syncParticles(myAddress!, syncItemParticles, signal);\n  }\n\n  private async fetchNewTweets(\n    myAddress: NeuronAddress,\n    timestampUpdate: number,\n    signal: AbortSignal\n  ) {\n    const tweetsAsyncIterable = await fetchCyberlinksByNerounIterable(\n      myAddress,\n      [CID_TWEET],\n      timestampUpdate,\n      CYBERLINKS_BATCH_LIMIT,\n      this.abortController?.signal\n    );\n\n    const newTweets: SyncStatusDto[] = [];\n    const existingParticles = await this.db!.findSyncStatus({\n      ownerId: myAddress,\n      entryType: EntryType.particle,\n    });\n    const existingParticlesMap = new Map(\n      existingParticles.map((i) => [i.id, i])\n    );\n    // eslint-disable-next-line no-await-in-loop, no-restricted-syntax\n    for await (const tweetsBatch of tweetsAsyncIterable) {\n      this.statusApi.sendStatus(\n        'in-progress',\n        `fetching new tweets...`,\n        this.progressTracker.trackProgress(1)\n      );\n      const syncStatusEntities = tweetsBatch.map(entityToDto).map((item) => {\n        const { timestamp, to } = item;\n        const timestampUpdate = dateToUtcNumber(timestamp);\n\n        // In case my tweet already linked from other neuron, resync from beginning\n        const timestampSyncFrom = existingParticlesMap.get(to)\n          ? dateToUtcNumber(timestamp)\n          : 0;\n\n        // Initial state\n        return {\n          ownerId: myAddress,\n          id: to,\n          entryType: EntryType.particle,\n          timestampUpdate: timestampSyncFrom,\n          timestampRead: timestampUpdate,\n          unreadCount: 0,\n          disabled: false,\n          meta: { ...item, timestamp: timestampUpdate },\n        } as SyncStatusDto;\n      });\n\n      if (syncStatusEntities.length > 0) {\n        await throwIfAborted(\n          this.db!.putSyncStatus,\n          signal\n        )(syncStatusEntities);\n        newTweets.push(...syncStatusEntities);\n      }\n    }\n\n    return newTweets;\n  }\n\n  private async syncParticles(\n    myAddress: NeuronAddress,\n    syncItems: SyncStatusDto[],\n    signal: AbortSignal\n  ) {\n    const updatedSyncItems: SyncStatusDto[] = [];\n\n    // eslint-disable-next-line no-restricted-syntax\n    for (const syncItem of syncItems) {\n      const { id, timestampUpdate } = syncItem;\n\n      this.statusApi.sendStatus(\n        'in-progress',\n        `fetching tweet updates...`,\n        this.progressTracker.trackProgress(1)\n      );\n      // eslint-disable-next-line no-await-in-loop\n      const linksIndexer = await fetchCyberlinksAndResolveParticles(\n        id,\n        timestampUpdate,\n        this.particlesResolver!,\n        QueuePriority.MEDIUM,\n        this.abortController?.signal\n      );\n\n      if (linksIndexer.length > 0) {\n        const links = linksIndexer.map(mapLinkFromIndexerToDto);\n\n        // save links\n        // eslint-disable-next-line no-await-in-loop\n        await asyncIterableBatchProcessor(\n          links,\n          (links) => throwIfAborted(this.db!.putCyberlinks, signal)(links),\n          MAX_DATABASE_PUT_SIZE\n        );\n\n        const newItem = changeParticleSyncStatus(syncItem, links, myAddress);\n\n        updatedSyncItems.push(newItem);\n      }\n    }\n\n    if (updatedSyncItems.length > 0) {\n      await throwIfAborted(this.db!.putSyncStatus, signal)(updatedSyncItems);\n    }\n    this.channelApi.postSenseUpdate(updatedSyncItems as SenseListItem[]);\n  }\n}\n\nexport default SyncParticlesLoop;\n","/* eslint-disable camelcase */\nimport {\n  map,\n  combineLatest,\n  distinctUntilChanged,\n  BehaviorSubject,\n} from 'rxjs';\n\nimport { EntryType } from 'src/services/CozoDb/types/entities';\n\nimport { NeuronAddress } from 'src/types/base';\nimport { QueuePriority } from 'src/services/QueueManager/types';\nimport { isAbortException } from 'src/utils/exceptions/helpers';\n\nimport { mapLinkFromIndexerToDto } from 'src/services/CozoDb/mapping';\nimport { throwIfAborted } from 'src/utils/async/promise';\n\nimport { SyncEntryName } from 'src/services/backend/types/services';\nimport { SenseItemLinkMeta } from 'src/services/backend/types/sense';\nimport { entityToDto } from 'src/utils/dto';\nimport { ServiceDeps } from '../types';\n\nimport { fetchCyberlinksByNerounIterable } from '../../../indexer/cyberlinks';\nimport { CYBERLINKS_BATCH_LIMIT } from '../../../indexer/consts';\nimport BaseSyncLoop from '../BaseSyncLoop/BaseSyncLoop';\nimport { SyncServiceParams } from '../../types';\nimport { getLastReadInfo } from '../../utils';\n\nimport ParticlesResolverQueue from '../ParticlesResolverQueue/ParticlesResolverQueue';\nimport { SENSE_FRIEND_PARTICLES } from '../consts';\n\nclass SyncMyFriendsLoop extends BaseSyncLoop {\n  protected followings: NeuronAddress[] = [];\n\n  constructor(\n    name: SyncEntryName,\n    intervalMs: number,\n    deps: ServiceDeps,\n    particlesResolver: ParticlesResolverQueue,\n    { warmupMs }: { warmupMs: number } = { warmupMs: 0 }\n  ) {\n    if (!deps.followings$) {\n      throw new Error('followings$ is required');\n    }\n\n    super(name, intervalMs, deps, particlesResolver, {\n      warmupMs,\n    });\n  }\n\n  protected createIsInitializedObserver(deps: ServiceDeps) {\n    const followingsInitialized$ = new BehaviorSubject<boolean>(false);\n    deps.params$\n      ?.pipe(\n        map((params) => params.myAddress),\n        distinctUntilChanged()\n      )\n      .subscribe(() => {\n        followingsInitialized$.next(false);\n      });\n\n    deps.followings$!.subscribe((followings) => {\n      this.followings = followings;\n      followingsInitialized$.next(true);\n\n      this.restart();\n    });\n\n    const isInitialized$ = combineLatest([\n      deps.dbInstance$,\n      deps.params$!,\n      this.particlesResolver!.isInitialized$,\n      followingsInitialized$!,\n    ]).pipe(\n      map(\n        ([dbInstance, params, syncQueueInitialized, followingsInitialized]) =>\n          !!dbInstance &&\n          !!params.myAddress &&\n          !!syncQueueInitialized &&\n          followingsInitialized\n      )\n    );\n\n    return isInitialized$;\n  }\n\n  protected async sync(params: SyncServiceParams) {\n    const { signal } = this.abortController;\n\n    this.statusApi.sendStatus('in-progress', 'preparing...');\n    const { myAddress } = params;\n\n    const { followings } = this;\n\n    this.statusApi.sendStatus('estimating');\n\n    this.cyblogCh.info(\n      `>>> syncMyFriends ${myAddress} count ${followings.length}`,\n      {\n        unit: 'friends-sync',\n        data: followings,\n      }\n    );\n\n    this.progressTracker.start(followings.length);\n    this.statusApi.sendStatus(\n      'in-progress',\n      `sync...`,\n      this.progressTracker.progress\n    );\n\n    // eslint-disable-next-line no-restricted-syntax\n    for (const addr of followings) {\n      // eslint-disable-next-line no-await-in-loop\n      await this.syncLinks(myAddress!, addr, signal);\n    }\n  }\n\n  public async syncLinks(\n    myAddress: NeuronAddress,\n    address: NeuronAddress,\n    signal: AbortSignal\n  ) {\n    let syncUpdates = [];\n    try {\n      this.statusApi.sendStatus(\n        'in-progress',\n        `starting sync ${address}...`,\n        this.progressTracker.progress\n      );\n      const { timestampRead, unreadCount, meta } = await this.db!.getSyncStatus(\n        myAddress,\n        address\n      );\n\n      const { timestampUpdateChat = 0, timestampUpdateContent = 0 } =\n        meta || {};\n\n      const timestampFrom = timestampUpdateContent + 1; // ofsset + 1 to fix milliseconds precision bug\n\n      const linksAsyncIterable = await fetchCyberlinksByNerounIterable(\n        address,\n        SENSE_FRIEND_PARTICLES,\n        timestampFrom,\n        CYBERLINKS_BATCH_LIMIT,\n        signal\n      );\n\n      // eslint-disable-next-line no-restricted-syntax\n      for await (const linksBatch of linksAsyncIterable) {\n        this.statusApi.sendStatus(\n          'in-progress',\n          `sync ${address}...`,\n          this.progressTracker.trackProgress(1)\n        );\n\n        const links = linksBatch.map(mapLinkFromIndexerToDto);\n\n        const { timestampRead: newTimestampRead, unreadCount: newUnreadCount } =\n          getLastReadInfo(links, myAddress, timestampRead, unreadCount);\n\n        // const unreadItemsCount = unreadCount + links.length;\n\n        if (links.length > 0) {\n          const lastLink = entityToDto(links.at(-1)!);\n          const newTimestampUpdateContent = lastLink!.timestamp;\n\n          await throwIfAborted(this.db!.putCyberlinks, signal)(links);\n\n          const particles = links.map((t) => t.to);\n          await this.particlesResolver!.enqueueBatch(\n            particles,\n            QueuePriority.HIGH\n          );\n\n          const newSyncItem = {\n            ownerId: myAddress,\n            entryType: EntryType.chat,\n            id: address,\n            timestampUpdate: Math.max(\n              newTimestampUpdateContent,\n              timestampUpdateChat\n            ),\n            unreadCount: newUnreadCount,\n            timestampRead: newTimestampRead,\n            disabled: false,\n            meta: {\n              ...lastLink!,\n              timestampUpdateContent: newTimestampUpdateContent,\n              timestampUpdateChat,\n            } as SenseItemLinkMeta,\n          };\n          // Update transaction\n          await throwIfAborted(this.db!.putSyncStatus, signal)(newSyncItem);\n\n          syncUpdates.push(newSyncItem);\n        }\n      }\n    } catch (err) {\n      this.cyblogCh.error(`>>> SyncMyFriends ${address} error`, {\n        error: err,\n      });\n      if (!isAbortException(err)) {\n        this.statusApi.sendStatus('error', err.toString());\n      } else {\n        syncUpdates = [];\n        throw err;\n      }\n    } finally {\n      // console.log('-----syncUpdates with redux', syncUpdates);\n      this.channelApi.postSenseUpdate(syncUpdates);\n    }\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  // protected createRestartObserver(\n  //   params$: Observable<SyncServiceParams>\n  // ): Observable<boolean> {\n  //   return super\n  //     .createRestartObserver(params$)\n  //     .pipe(switchMap((addressChanged) => this.isInitialized$));\n  // }\n}\n\nexport default SyncMyFriendsLoop;\n","import Unixfs from 'ipfs-unixfs';\nimport { DAGNode, util as DAGUtil } from 'ipld-dag-pb';\nimport { isString } from 'lodash';\nimport { IpfsApi } from 'src/services/backend/workers/background/worker';\nimport { ParticleCid } from 'src/types/base';\nimport { PATTERN_IPFS_HASH } from 'src/constants/patterns';\n\n// eslint-disable-next-line import/prefer-default-export\nexport const getIpfsHash = (string: string): Promise<ParticleCid> =>\n  new Promise((resolve, reject) => {\n    const unixFsFile = new Unixfs('file', Buffer.from(string));\n\n    const buffer = unixFsFile.marshal();\n    DAGNode.create(buffer, (err, dagNode) => {\n      if (err) {\n        reject(new Error('Cannot create ipfs DAGNode'));\n      }\n\n      DAGUtil.cid(dagNode, (error, cid) => {\n        resolve(cid.toBaseEncodedString());\n      });\n    });\n  });\nexport const addIfpsMessageOrCid = async (\n  message: string | ParticleCid | File,\n  { ipfsApi }: { ipfsApi: IpfsApi | null }\n) => {\n  if (!ipfsApi) {\n    throw Error('IpfsApi is not initialized');\n  }\n\n  return (\n    isString(message) && message.match(PATTERN_IPFS_HASH)\n      ? message\n      : ((await ipfsApi!.addContent(message)) as string)\n  ) as ParticleCid;\n};\n","import { NeuronAddress, ParticleCid } from 'src/types/base';\nimport { getIpfsHash } from 'src/utils/ipfs/helpers';\nimport { PATTERN_CYBER } from 'src/constants/patterns';\nimport { Subject, Observable } from 'rxjs';\n\nimport DbApiWrapper from '../backend/services/DbApi/DbApi';\nimport { getFollowsAsCid, getFollowers } from './lcd';\nimport { FetchParticleAsync, QueuePriority } from '../QueueManager/types';\nimport { CommunityDto } from '../CozoDb/types/dto';\nimport { FetchIpfsFunc } from '../backend/services/sync/types';\nimport { createCyblogChannel } from 'src/utils/logging/cyblog';\n\nexport type SyncCommunityResult = {\n  action: 'reset' | 'add' | 'complete';\n  items: CommunityDto[];\n};\n\nconst cyblogCh = createCyblogChannel({\n  thread: 'bckd',\n  unit: 'fetchStoredSyncCommunity',\n});\n\n// eslint-disable-next-line import/prefer-default-export, import/no-unused-modules\nexport const fetchStoredSyncCommunity$ = (\n  dbApi: DbApiWrapper,\n  address: NeuronAddress,\n  fetchParticleAsync?: FetchIpfsFunc,\n  signal?: AbortSignal\n): Observable<SyncCommunityResult> => {\n  return new Observable<SyncCommunityResult>((subscriber) => {\n    subscriber.next({ action: 'reset', items: [] });\n\n    (async () => {\n      const storedCommunity = await dbApi.getCommunity(address);\n\n      subscriber.next({ action: 'add', items: storedCommunity });\n\n      const communityUpdatesMap = new Map<ParticleCid, CommunityDto>(\n        storedCommunity.map((c) => [c.particle, c])\n      );\n\n      const getExistingOrDefault = (cid: ParticleCid): Partial<CommunityDto> =>\n        communityUpdatesMap.get(cid) || {\n          ownerId: address,\n          name: '',\n          following: false,\n          follower: false,\n        };\n\n      const followsCids = await getFollowsAsCid(address, signal);\n      const followers = await getFollowers(address, signal);\n\n      const newFollowerCids = followsCids.filter(\n        (cid) => !storedCommunity.some((i) => i.particle === cid && i.following)\n      );\n\n      const newFollowingNeurons = followers.filter(\n        (addr) => !storedCommunity.some((i) => i.neuron === addr && i.follower)\n      );\n\n      cyblogCh.info(\n        `>>>$ sync community ${address} processing, stored ${storedCommunity.length} new followers: ${newFollowerCids.length} new following: ${newFollowingNeurons.length}`\n      );\n\n      const followersCommunity = await Promise.all(\n        newFollowingNeurons.map(async (neuron) => {\n          const cid = await getIpfsHash(neuron);\n\n          const communityItem = {\n            ...getExistingOrDefault(cid),\n            particle: cid,\n            neuron,\n            follower: true,\n          } as CommunityDto;\n\n          await dbApi.putCommunity(communityItem);\n          communityUpdatesMap.set(cid, communityItem);\n          return communityItem;\n        })\n      );\n\n      subscriber.next({ action: 'add', items: followersCommunity });\n\n      await Promise.all(\n        newFollowerCids.map(async (cid: ParticleCid) => {\n          const neuron = (await fetchParticleAsync!(cid, QueuePriority.URGENT))\n            ?.result?.textPreview;\n          if (neuron && neuron.match(PATTERN_CYBER)) {\n            const communityItem = {\n              ...getExistingOrDefault(cid),\n              neuron,\n              particle: cid,\n              following: true,\n            } as CommunityDto;\n\n            await dbApi.putCommunity(communityItem);\n            communityUpdatesMap.set(cid, communityItem);\n            subscriber.next({ action: 'add', items: [communityItem] });\n          }\n        })\n      );\n\n      cyblogCh.info(`>>>$ sync community ${address}, done`);\n      // const communityUpdates = [...communityUpdatesMap.values()];\n\n      // if (communityUpdates.length > 0) {\n      //   subscriber.next(communityUpdates);\n      // }\n      subscriber.next({ action: 'complete', items: [] });\n\n      subscriber.complete();\n    })().catch((err) => {\n      cyblogCh.error(`>>>$ sync community ${address}, error`, { error: err });\n      subscriber.error(err);\n    });\n  });\n};\n\n// eslint-disable-next-line import/no-unused-modules\nexport const fetchCommunity = async (\n  address: NeuronAddress,\n  fetchParticleAsync?: FetchParticleAsync,\n  onResolve?: (community: CommunityDto[]) => void,\n  signal?: AbortSignal\n) => {\n  const communityUpdatesMap = new Map<ParticleCid, CommunityDto>();\n\n  const getExistingOrDefault = (cid: ParticleCid): Partial<CommunityDto> =>\n    communityUpdatesMap.get(cid) || {\n      ownerId: address,\n      name: '',\n      following: false,\n      follower: false,\n    };\n\n  const followsCids = await getFollowsAsCid(address, signal);\n  const followers = await getFollowers(address, signal);\n\n  console.log(`>>> sync community ${address} processing without store`);\n\n  const followsPromise = Promise.all(\n    followsCids.map(async (cid) => {\n      const neuron = (await fetchParticleAsync!(cid))?.result?.textPreview;\n      if (neuron && neuron.match(PATTERN_CYBER)) {\n        const communityItem = {\n          ...getExistingOrDefault(cid),\n          neuron,\n          particle: cid,\n          following: true,\n        } as CommunityDto;\n        communityUpdatesMap.set(cid, communityItem);\n        onResolve && !signal?.aborted && onResolve([communityItem]);\n      }\n    })\n  );\n\n  const followersPromise = Promise.all(\n    followers.map(async (neuron) => {\n      const cid = await getIpfsHash(neuron);\n\n      const communityItem = {\n        ...getExistingOrDefault(cid),\n        particle: cid,\n        neuron,\n        follower: true,\n      } as CommunityDto;\n\n      communityUpdatesMap.set(cid, communityItem);\n      onResolve && !signal?.aborted && onResolve([communityItem]);\n    })\n  );\n\n  await Promise.all([followersPromise, followsPromise]);\n};\n","import axios from 'axios';\nimport { NeuronAddress, ParticleCid } from 'src/types/base';\nimport { CID_FOLLOW } from 'src/constants/app';\nimport { getIpfsHash } from 'src/utils/ipfs/helpers';\nimport { LCD_URL } from 'src/constants/config';\n// import { Api } from 'src/generated/lcd';\n\n// const lcdApi = new Api({ baseURL: LCD_URL });\n\nexport const getFollowsAsCid = async (\n  address: NeuronAddress,\n  signal?: AbortSignal\n): Promise<ParticleCid[]> => {\n  // const response = await lcdApi.cosmos.getTxsEvent(\n  //   {\n  //     events: [\n  //       `cyberlink.neuron=${address}`,\n  //       `cyberlink.particleFrom=${CID_FOLLOW}`,\n  //     ],\n  //     paginationLimit: '1000000000',\n  //   },\n  //   { signal }\n  // );\n\n  const response = await axios({\n    method: 'get',\n    url: `${LCD_URL}/txs?cyberlink.neuron=${address}&cyberlink.particleFrom=${CID_FOLLOW}&limit=1000000000`,\n    signal,\n  });\n\n  if (!response.data.txs) {\n    return [];\n  }\n  return response.data.txs.map(\n    (item) => item.tx.value.msg[0].value.links[0].to\n  );\n};\n\nexport const getFollowers = async (\n  address: NeuronAddress,\n  signal?: AbortSignal\n): Promise<NeuronAddress[]> => {\n  const addressHash = await getIpfsHash(address);\n\n  const response = await axios({\n    method: 'get',\n    url: `${LCD_URL}/txs?cyberlink.particleFrom=${CID_FOLLOW}&cyberlink.particleTo=${addressHash}&limit=1000000000`,\n    signal,\n  });\n\n  if (!response.data.txs) {\n    return [];\n  }\n  return response.data.txs.map((item) => item.tx.value.msg[0].value.neuron);\n};\n","/* eslint-disable no-restricted-syntax */\nimport { Observable, combineLatest } from 'rxjs';\nimport { map } from 'rxjs/operators';\n\nimport BroadcastChannelSender from '../../channels/BroadcastChannelSender';\n\nimport ParticlesResolverQueue from './services/ParticlesResolverQueue/ParticlesResolverQueue';\n\n// import SyncIpfsLoop from './services/SyncIpfsLoop/SyncIpfsLoop';\nimport SyncTransactionsLoop from './services/SyncTransactionsLoop/SyncTransactionsLoop';\nimport SyncParticlesLoop from './services/SyncParticlesLoop/SyncParticlesLoop';\n\nimport { ServiceDeps } from './services/types';\nimport {\n  MY_FRIENDS_SYNC_INTERVAL,\n  MY_PARTICLES_SYNC_INTERVAL,\n} from './services/consts';\nimport SyncMyFriendsLoop from './services/SyncMyFriendsLoop/SyncMyFriendsLoop';\nimport { SyncEntryName } from '../../types/services';\nimport BaseSyncLoop from './services/BaseSyncLoop/BaseSyncLoop';\nimport createCommunitySync$ from './services/CommunitySync/CommunitySync';\nimport { createCyblogChannel } from 'src/utils/logging/cyblog';\n\nconst cyblogCh = createCyblogChannel({ thread: 'bckd' });\n\n// eslint-disable-next-line import/prefer-default-export\nexport class SyncService {\n  private isInitialized$: Observable<boolean>;\n\n  private channelApi = new BroadcastChannelSender();\n\n  private loops: Partial<Record<SyncEntryName, BaseSyncLoop>> = {};\n\n  constructor(deps: ServiceDeps) {\n    const { dbInstance$, ipfsInstance$ } = deps;\n    this.isInitialized$ = combineLatest([dbInstance$, ipfsInstance$]).pipe(\n      map(([dbInstance, ipfsInstance]) => !!dbInstance && !!ipfsInstance)\n    );\n    // subscribe when started\n    this.isInitialized$.subscribe({\n      next: (result) => {\n        return result && this.channelApi.postServiceStatus('sync', 'started');\n      },\n      error: (err) => this.channelApi.postServiceStatus('sync', 'error', err),\n    });\n\n    const particlesResolver = new ParticlesResolverQueue(deps).start();\n\n    const communitySync$ = createCommunitySync$(deps);\n    communitySync$.subscribe((community) => {\n      cyblogCh.info('--> community fetched', {\n        unit: 'community',\n        data: community,\n      });\n    });\n\n    const followings$ = communitySync$.pipe(\n      map((c) => c.filter((i) => i.following)),\n      map((c) => c.map((i) => i.neuron))\n    );\n\n    // new SyncIpfsLoop(deps, particlesResolver).start();\n\n    new SyncTransactionsLoop('transactions', deps, particlesResolver).start();\n\n    new SyncParticlesLoop(\n      'particles',\n      MY_PARTICLES_SYNC_INTERVAL,\n      deps,\n      particlesResolver\n    ).start();\n\n    new SyncMyFriendsLoop(\n      'my-friends',\n      MY_FRIENDS_SYNC_INTERVAL,\n      { ...deps, followings$ },\n      particlesResolver\n      // { warmupMs: 1000 }\n    ).start();\n  }\n\n  public restart(name: SyncEntryName) {\n    this.loops[name]?.restart();\n  }\n}\n","import {\n  Observable,\n  combineLatest,\n  defer,\n  distinctUntilChanged,\n  filter,\n  map,\n  switchMap,\n} from 'rxjs';\n\nimport {\n  SyncCommunityResult,\n  fetchStoredSyncCommunity$,\n} from 'src/services/community/community';\nimport BroadcastChannelSender from 'src/services/backend/channels/BroadcastChannelSender';\nimport { CommunityDto } from 'src/services/CozoDb/types/dto';\nimport { ServiceDeps } from '../types';\n\n// eslint-disable-next-line import/no-unused-modules\nexport default function createCommunitySync$(\n  deps: ServiceDeps\n): Observable<CommunityDto[]> {\n  const { dbInstance$, ipfsInstance$, params$ } = deps;\n  const channel = new BroadcastChannelSender();\n\n  return combineLatest([\n    dbInstance$,\n    params$!.pipe(\n      map((params) => params.myAddress),\n      distinctUntilChanged()\n    ),\n    ipfsInstance$,\n  ]).pipe(\n    filter(\n      ([dbInstance, myAddress, ipfsInstance]) =>\n        !!dbInstance && !!ipfsInstance && !!myAddress\n    ),\n    switchMap(([dbApi, myAddress, ipfsInstance]) => {\n      const { waitForParticleResolve } = deps;\n      let community: CommunityDto[] = []; // Fix: Add type declaration for community array\n      return new Observable<CommunityDto[]>((observer) => {\n        observer.next([]);\n\n        fetchStoredSyncCommunity$(\n          dbApi!,\n          myAddress!,\n          waitForParticleResolve!\n        ).subscribe(({ action, items }: SyncCommunityResult) => {\n          channel.post({ type: 'load_community', value: { action, items } });\n\n          if (action === 'reset') {\n            community = [];\n          } else if (['add', 'complete'].some((s) => s === action)) {\n            community.push(...items);\n          }\n\n          if (action === 'complete') {\n            observer.next(community);\n            observer.complete();\n          }\n        });\n      });\n    })\n  );\n}\n","import {\n  BehaviorSubject,\n  defer,\n  Observable,\n  filter,\n  from,\n  mergeMap,\n  tap,\n} from 'rxjs';\nimport { IDeferredDbSaver } from 'src/services/QueueManager/types';\nimport { IPFSContent, IPFSContentMaybe } from 'src/services/ipfs/types';\n\nimport { v4 as uuidv4 } from 'uuid';\nimport { ParticleCid } from 'src/types/base';\nimport { mapParticleToEntity } from 'src/services/CozoDb/mapping';\nimport DbApi from '../DbApi/DbApi';\nimport { LinkDto } from 'src/services/CozoDb/types/dto';\n\ntype QueueItem = {\n  content?: IPFSContent;\n  links?: LinkDto[];\n};\n\ntype QueueMap = Map<ParticleCid | typeof uuidv4, QueueItem>;\n\nclass DeferredDbSaver implements IDeferredDbSaver {\n  private queue$ = new BehaviorSubject<QueueMap>(new Map());\n\n  private dbApi: DbApi | undefined;\n\n  public get queue(): QueueMap {\n    return this.queue$.getValue();\n  }\n\n  constructor(dbInstance$: Observable<DbApi | undefined>) {\n    dbInstance$.subscribe((db) => {\n      this.dbApi = db;\n    });\n\n    dbInstance$\n      .pipe(\n        filter((dbInstance) => !!dbInstance),\n        tap(() => cyblog.info('DeferredDbSaver - initialized')),\n        mergeMap(() => this.queue$), // Merge the queue$ stream here.\n        filter((queue) => queue.size > 0),\n        mergeMap((queue) => defer(() => from(this.processQueue(queue))))\n      )\n      .subscribe({\n        // next: () => console.log('Queue processed'),\n        error: (err) => console.error('Error processing IPFS queue', err),\n      });\n  }\n\n  public enqueueIpfsContent(content: IPFSContentMaybe) {\n    if (!content) {\n      return;\n    }\n    const { cid } = content;\n\n    this.queue$.next(new Map(this.queue$.value).set(cid, { content }));\n  }\n\n  public enqueueLinks(links: LinkDto[]) {\n    if (!links || !links.length) {\n      return;\n    }\n    const id = uuidv4();\n    this.queue$.next(new Map(this.queue$.value).set(id, { links }));\n  }\n\n  private async processQueue(queue: QueueMap) {\n    // const processingQueue = new Map(this.queue$.value); // Snapshot of the current queue\n    this.queue$.next(new Map());\n    // eslint-disable-next-line no-restricted-syntax\n    for (const [cid, item] of queue) {\n      // eslint-disable-next-line no-await-in-loop\n      await this.processQueueItem(item);\n      // console.log(' deffered DB done ', cid, item);\n\n      queue.delete(cid);\n    }\n    // this.queue$.next(queue);\n  }\n\n  private async processQueueItem(queueItem: QueueItem) {\n    const { content, links } = queueItem;\n    // console.log(`PostProcessing queue item: ${cid}`, item);\n    if (content) {\n      // eslint-disable-next-line no-await-in-loop\n      const entity = mapParticleToEntity(content);\n      await this.dbApi!.putParticles(entity);\n    }\n\n    if (links && links.length > 0) {\n      // eslint-disable-next-line no-await-in-loop\n      await this.dbApi!.putCyberlinks(links);\n    }\n  }\n}\n\nexport default DeferredDbSaver;\n","import { ProxyMarked, Remote, proxy } from 'comlink';\n\nimport { initIpfsNode } from 'src/services/ipfs/node/factory';\n\nimport {\n  CybIpfsNode,\n  IpfsContentType,\n  IpfsOptsType,\n} from 'src/services/ipfs/types';\n\nimport QueueManager from 'src/services/QueueManager/QueueManager';\n\n// import { CozoDbWorkerApi } from 'src/services/backend/workers/db/worker';\n\nimport {\n  QueueItemCallback,\n  QueueItemOptions,\n  QueuePriority,\n} from 'src/services/QueueManager/types';\nimport { ParticleCid } from 'src/types/base';\nimport { LinkDto } from 'src/services/CozoDb/types/dto';\nimport { BehaviorSubject, Subject } from 'rxjs';\n\nimport { exposeWorkerApi } from '../factoryMethods';\n\nimport { SyncService } from '../../services/sync/sync';\nimport { SyncServiceParams } from '../../services/sync/types';\n\nimport DbApi from '../../services/DbApi/DbApi';\n\nimport BroadcastChannelSender from '../../channels/BroadcastChannelSender';\nimport DeferredDbSaver from '../../services/DeferredDbSaver/DeferredDbSaver';\nimport { SyncEntryName } from '../../types/services';\n\nconst createBackgroundWorkerApi = () => {\n  const dbInstance$ = new Subject<DbApi | undefined>();\n\n  const ipfsInstance$ = new BehaviorSubject<CybIpfsNode | undefined>(undefined);\n\n  const params$ = new BehaviorSubject<SyncServiceParams>({\n    myAddress: null,\n  });\n\n  let ipfsNode: CybIpfsNode | undefined;\n  const defferedDbSaver = new DeferredDbSaver(dbInstance$);\n\n  const ipfsQueue = new QueueManager(ipfsInstance$, {\n    defferedDbSaver,\n  });\n  const broadcastApi = new BroadcastChannelSender();\n\n  // service to sync updates about cyberlinks, transactions, swarm etc.\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  const syncService = new SyncService({\n    waitForParticleResolve: async (\n      cid: ParticleCid,\n      priority: QueuePriority = QueuePriority.MEDIUM\n    ) => ipfsQueue.enqueueAndWait(cid, { postProcessing: true, priority }),\n    dbInstance$,\n    ipfsInstance$,\n    params$,\n  });\n\n  const init = async (dbApiProxy: DbApi & ProxyMarked) => {\n    dbInstance$.next(dbApiProxy);\n  };\n\n  const stopIpfs = async () => {\n    if (ipfsNode) {\n      await ipfsNode.stop();\n    }\n    ipfsInstance$.next(undefined);\n    broadcastApi.postServiceStatus('ipfs', 'inactive');\n  };\n\n  const startIpfs = async (ipfsOpts: IpfsOptsType) => {\n    try {\n      if (ipfsNode) {\n        console.log('Ipfs node already started!');\n        await ipfsNode.stop();\n      }\n      broadcastApi.postServiceStatus('ipfs', 'starting');\n      ipfsNode = await initIpfsNode(ipfsOpts);\n\n      ipfsInstance$.next(ipfsNode);\n\n      setTimeout(() => broadcastApi.postServiceStatus('ipfs', 'started'), 0);\n      return true;\n    } catch (err) {\n      console.log('----ipfs node init error ', err);\n      const msg = err instanceof Error ? err.message : (err as string);\n      broadcastApi.postServiceStatus('ipfs', 'error', msg);\n      throw Error(msg);\n    }\n  };\n\n  const defferedDbApi = {\n    importCyberlinks: (links: LinkDto[]) => {\n      defferedDbSaver.enqueueLinks(links);\n    },\n  };\n\n  const ipfsApi = {\n    start: startIpfs,\n    stop: stopIpfs,\n    getIpfsNode: async () => ipfsNode && proxy(ipfsNode),\n    config: async () => ipfsNode?.config,\n    info: async () => ipfsNode?.info(),\n    fetchWithDetails: async (cid: string, parseAs?: IpfsContentType) =>\n      ipfsNode?.fetchWithDetails(cid, parseAs),\n    enqueue: async (\n      cid: string,\n      callback: QueueItemCallback,\n      options: QueueItemOptions\n    ) => ipfsQueue!.enqueue(cid, callback, options),\n    enqueueAndWait: async (cid: string, options?: QueueItemOptions) =>\n      ipfsQueue!.enqueueAndWait(cid, options),\n    dequeue: async (cid: string) => ipfsQueue.cancel(cid),\n    dequeueByParent: async (parent: string) => ipfsQueue.cancelByParent(parent),\n    clearQueue: async () => ipfsQueue.clear(),\n    addContent: async (content: string | File) => ipfsNode?.addContent(content),\n  };\n\n  return {\n    init,\n    isInitialized: () => !!ipfsInstance$.value,\n    // syncDrive,\n    ipfsApi: proxy(ipfsApi),\n    defferedDbApi: proxy(defferedDbApi),\n    ipfsQueue: proxy(ipfsQueue),\n    restartSync: (name: SyncEntryName) => syncService.restart(name),\n    setParams: (params: Partial<SyncServiceParams>) =>\n      params$.next({ ...params$.value, ...params }),\n  };\n};\n\nconst backgroundWorker = createBackgroundWorkerApi();\nexport type IpfsApi = Remote<typeof backgroundWorker.ipfsApi>;\nexport type BackgroundWorker = typeof backgroundWorker;\n\n// Expose the API to the main thread as shared/regular worker\nexposeWorkerApi(self, backgroundWorker);\n","export const CYBLOG_LOG_SHOW = 'cyblog_show';\n\nexport const CYBLOG_BROADCAST_CHANNEL_NAME = 'CYBLOG_BROADCST_CHANNEL';\n\nexport const CYBLOG_CONSOLE_PARAMS_DEFAULT = {\n  thread: 'all',\n  unit: 'all',\n  module: 'all',\n};\n","import _, { isEmpty } from 'lodash';\nimport { ConsoleLogParams, LogContext, LogItem, LogLevel } from './types';\nimport { CYBLOG_BROADCAST_CHANNEL_NAME } from './constants';\n\nconst logList: LogItem[] = [];\n\nfunction createCybLog<T>(defaultContext: Partial<LogContext<T>> = {}) {\n  function appendLog(logItem: LogItem, truncate = true) {\n    logList.push(logItem);\n\n    while (truncate && logList.length > 1000) {\n      logList.shift(); // Remove the first element to keep the list size <= 1000\n    }\n  }\n  let consoleLogParams = {} as ConsoleLogParams;\n\n  const channel = new BroadcastChannel(CYBLOG_BROADCAST_CHANNEL_NAME);\n\n  channel.onmessage = (event) => {\n    if (event.data.type === 'params') {\n      consoleLogParams = { ...consoleLogParams, ...event.data.value };\n    }\n  };\n\n  const getConsoleLogParams = () => consoleLogParams;\n\n  function consoleLog<T>(\n    level: LogLevel,\n    message: T,\n    context: Partial<LogContext<T>>\n  ) {\n    const ctx = _.omit(context, [\n      'formatter',\n      'thread',\n      'module',\n      'unit',\n      'data',\n    ]);\n    const { thread = '', module = '', unit = '', data = '' } = context;\n    const ctxItem = isEmpty(ctx) ? '' : ctx;\n\n    if (Array.isArray(message)) {\n      console[level](...message, ctxItem);\n      return;\n    }\n\n    if (context?.formatter) {\n      console[level](context?.formatter(message), ctxItem);\n      return;\n    }\n\n    console[level](`[${thread}:${module}:${unit}] ${message}`, data, ctxItem);\n  }\n\n  // eslint-disable-next-line import/no-unused-modules\n  function log<T>(\n    level: LogLevel,\n    message: string | T,\n    context: LogContext<any> = defaultContext\n  ) {\n    try {\n      const formattedMessage = context?.formatter\n        ? context?.formatter(message)\n        : message;\n\n      const logEntry = {\n        timestamp: new Date(),\n        level,\n        message: formattedMessage,\n        stacktrace: context?.stacktrace,\n        context: _.omit(context, ['formatter', 'stacktrace']),\n      };\n\n      appendLog(logEntry);\n      // !!localStorage.getItem(LOCAL_STORAGE_USE_CONSOLE_LOG_KEY) &&\n      const showConsoleLog = Object.keys(consoleLogParams).reduce(\n        (acc: boolean, key: string) => {\n          const params = consoleLogParams[key];\n          const contextItem = context[key];\n          if (params && contextItem) {\n            return (\n              acc ||\n              params === 'all' ||\n              params.length === 0 ||\n              params.some((p) => p === contextItem)\n            );\n          }\n          return acc;\n        },\n        false\n      );\n\n      if (showConsoleLog) {\n        consoleLog(level, message, context);\n      }\n    } catch (error) {\n      console.log('cyblog error', error);\n    }\n  }\n\n  function info<T>(message: T, context?: LogContext<string | T>) {\n    return log('info', message, context);\n  }\n\n  function error<T>(message: T, context?: LogContext<string | T>) {\n    return log('error', message, context);\n  }\n\n  function warn<T>(message: T, context?: LogContext<string | T>) {\n    return log('warn', message, context);\n  }\n\n  function trace<T>(message: T, context?: LogContext<string | T>) {\n    return log('warn', message, context);\n  }\n\n  function normalizeLog() {\n    return logList.map((logItem) => {\n      const { context, ...rest } = logItem;\n      const {\n        unit = '',\n        module = '',\n        thread = '',\n        data = '',\n        error = '',\n        stacktrace = '',\n      } = context || {};\n      return {\n        ...rest,\n        unit,\n        module,\n        thread,\n        data, //: JSON.stringify(data),\n        error,\n        stacktrace,\n      };\n    });\n  }\n\n  return {\n    log,\n    info,\n    error,\n    warn,\n    trace,\n    logList,\n    getLogs: () => normalizeLog(),\n    clear: () => logList.splice(0, logList.length),\n    getConsoleLogParams,\n  };\n}\n\nexport const createCyblogChannel = (\n  defaultContext: Partial<LogContext<T>> = {}\n) => {\n  const channel = new BroadcastChannel(CYBLOG_BROADCAST_CHANNEL_NAME);\n\n  function postLogToChannel<T>(\n    level: LogLevel,\n    message: T,\n    context?: LogContext<string | T>\n  ) {\n    const ctx = { ...defaultContext, ...context };\n    if (context?.error) {\n      ctx.error = JSON.stringify(context.error);\n    }\n    channel.postMessage({\n      type: 'log',\n      value: { level, message, context: ctx },\n    });\n  }\n\n  function info<T>(message: T, context?: LogContext<string | T>) {\n    return postLogToChannel('info', message, context);\n  }\n\n  function error<T>(message: T, context?: LogContext<string | T>) {\n    return postLogToChannel('error', message, context);\n  }\n\n  function warn<T>(message: T, context?: LogContext<string | T>) {\n    return postLogToChannel('warn', message, context);\n  }\n\n  function trace<T>(message: T, context?: LogContext<string | T>) {\n    return postLogToChannel('warn', message, context);\n  }\n\n  return { info, error, warn, trace };\n};\n\nconst cyblog = createCybLog({ thread: 'main' });\n\nexport type LogFunc = (message: T, context?: LogContext<string | T>) => void;\n\nexport type CyblogChannel = ReturnType<typeof createCyblogChannel>;\n\nexport default cyblog;\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\tid: moduleId,\n\t\tloaded: false,\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Flag the module as loaded\n\tmodule.loaded = true;\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n// the startup function\n__webpack_require__.x = function() {\n\t// Load entry module and return exports\n\t// This entry module depends on other loaded chunks and execution need to be delayed\n\tvar __webpack_exports__ = __webpack_require__.O(undefined, [385,775,746,356,975], function() { return __webpack_require__(28379); })\n\t__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n\treturn __webpack_exports__;\n};\n\n","__webpack_require__.amdO = {};","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = function(chunkId) {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce(function(promises, key) {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks and sibling chunks for the entrypoint\n__webpack_require__.u = function(chunkId) {\n\t// return url for filenames not based on template\n\tif (chunkId === 385) return \"385.613cfe5b.js\";\n\t// return url for filenames based on template\n\treturn \"\" + chunkId + \".\" + {\"356\":\"cf28752a\",\"746\":\"35674002\",\"775\":\"8cd4fdf0\",\"827\":\"89ce62da\",\"975\":\"353b60ef\"}[chunkId] + \".chunk.js\";\n};","// This function allow to reference async chunks and sibling chunks for the entrypoint\n__webpack_require__.miniCssF = function(chunkId) {\n\t// return url for filenames based on template\n\treturn undefined;\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.nmd = function(module) {\n\tmodule.paths = [];\n\tif (!module.children) module.children = [];\n\treturn module;\n};","__webpack_require__.p = \"/\";","// no baseURI\n\n// object to store loaded chunks\n// \"1\" means \"already loaded\"\nvar installedChunks = {\n\t312: 1\n};\n\n// importScripts chunk loading\nvar installChunk = function(data) {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\tfor(var moduleId in moreModules) {\n\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\twhile(chunkIds.length)\n\t\tinstalledChunks[chunkIds.pop()] = 1;\n\tparentChunkLoadingFunction(data);\n};\n__webpack_require__.f.i = function(chunkId, promises) {\n\t// \"1\" is the signal for \"already loaded\"\n\tif(!installedChunks[chunkId]) {\n\t\tif(true) { // all chunks have JS\n\t\t\timportScripts(__webpack_require__.p + __webpack_require__.u(chunkId));\n\t\t}\n\t}\n};\n\nvar chunkLoadingGlobal = self[\"webpackChunkcyb\"] = self[\"webpackChunkcyb\"] || [];\nvar parentChunkLoadingFunction = chunkLoadingGlobal.push.bind(chunkLoadingGlobal);\nchunkLoadingGlobal.push = installChunk;\n\n// no HMR\n\n// no HMR manifest","// run startup\nvar __webpack_exports__ = __webpack_require__.x();\n"],"names":["deferred","leafPrototypes","getProto","next","stringToCid","s","stringToIpfsPath","CYBER_NODE_SWARM_PEER_ID","CYBERNODE_SWARM_ADDR_WSS","CYBERNODE_SWARM_ADDR_TCP","CYBER_GATEWAY_URL","nodeType","_config","_isStarted","config","this","isStarted","response","node","get","gatewayUrl","address","nodeAddress","port","async","options","initConfig","window","toCid","console","log","swarm","localAddrs","map","a","toString","cid","files","stat","withLocal","size","then","result","type","sizeLocal","local","blocks","cat","content","add","pin","peers","c","peer","addr","bootstrap","connect","ls","repoSize","stats","repo","responseId","id","agentVersion","addOptionsV0","cidVersion","rawLeaves","blockstore","open","datastore","libp2p","bootstrapList","transports","rtcConfiguration","iceServers","urls","credential","username","discoverRelays","connectionEncryption","streamMuxers","connectionGater","denyDialMultiaddr","peerDiscovery","list","services","identify","libp2pFactory","fs","addEventListener","evt","peerId","detail","conn","getConnections","transportsByAddr","Object","fromEntries","remoteAddr","protoCodes","v","name","debug","getMultiaddrs","fileSize","localFileSize","dagSize","mtime","optionsV0","File","fileName","arrayBuffer","data","Uint8Array","addFile","path","TextEncoder","encode","addBytes","cid_","pins","isPinned","remotePeer","stop","start","dial","iterable","item","metadata","toV0","mapToLsResult","host","relay","enabled","hop","preload","API","HTTPHeaders","Addresses","Gateway","Swarm","Delegates","Discovery","MDNS","Enabled","Interval","webRTCStar","Bootstrap","Pubsub","ConnMgr","HighWater","LowWater","DisableNatPortMap","Routing","Type","filter","filters","nat","EXPERIMENTAL","ipnsPubsub","Number","Networks","bostrom","CHAIN_ID","BOSTROM","BASE_DENOM","DENOM_LIQUID","RPC_URL","LCD_URL","WEBSOCKET_URL","INDEX_HTTPS","INDEX_WEBSOCKET","BECH32_PREFIX","MEMO_KEPLR","SPACE_PUSSY","DEFAULT_CHAIN_ID","BECH32_PREFIX_VAL","BECH32_PREFIX_VALOPER","RegExp","PATTERN_HTTP","getMimeFromUint8Array","raw","fileType","mime","createImgData","rawData","basic","parseArrayLikeToDetails","onProgress","meta","link","gateway","initialType","includes","detectContentType","indexOf","bytesDownloaded","byteLength","chunks","ReadableStream","reader","getReader","readStream","done","value","push","read","Symbol","asyncIterator","chunk","error","getResponseResult","Buffer","from","dataBase64","length","match","string","newString","trim","slice","test","isHtml","text","shortenString","blob","Blob","URL","createObjectURL","e","createTextPreview","array","previewLength","db","version","stores","following","ipfsContentAddtToInddexdDB","dbValue","cluster","file","dataFile","status","loadIPFSContentFromDb","textPreview","source","emptyMeta","fetchIPFSContentMeta","signal","fetchIPFSContentFromNode","controller","controllerLegacy","AbortController","timer","setTimeout","abort","startTime","Date","now","statsDoneTime","statsTime","allowedSize","clearTimeout","availableDownload","firstChunk","offset","fullyDownloaded","stream","catTime","pinTime","fetchIPFSContentFromGateway","headers","isExternalNode","contentUrl","fetch","method","body","flushResults","Promise","resolve","flush","firstChunkStream","fullStream","tee","firstReader","restReader","asyncIterable","toAsyncIterableWithMime","getIPFSContent","callBackFuncStatus","dataRsponseDb","addContenToIpfs","contentToUint8Array","nodeClassMap","helia","embedded","external","initIpfsNode","ipfsNodeType","restOptions","EnhancedClass","Base","parseAs","details","super","getPeers","find","swarmPeerId","lastConnectedTimestamp","isConnectedToSwarm","connectPeer","swarmPeerAddress","catch","err","message","withCybFeatures","instance","init","url","urlOpts","reconnectToSwarm","QueueStrategy","constructor","settings","order","getNextSource","index","isParticle","Boolean","EntryType","SyncQueueStatus","initialState","isLoading","chats","summary","unreadCount","total","particles","neurons","formatApiData","entryType","chat","to","particle","formatted","timestamp","toISOString","transactionHash","hash","transaction_hash","memo","senseChatId","transactions","ownerId","fromAddress","inputs","assign","neuron","fromLog","getSenseList","senseApi","getList","getSenseChat","getLinks","getFriendItems","markAsRead","newChatStructure","checkIfMessageExists","newMessage","some","msg","reducers","updateSenseList","reducer","state","action","payload","forEach","concat","caseReducers","orderSenseList","prepare","addSenseItem","newList","unshift","updateSenseItem","chatId","txHash","isSuccess","sorted","keys","reduce","acc","lastMsg","sort","b","parse","i","reset","extraReducers","builder","addCase","pending","fulfilled","rejected","arg","sense","unreadCountParticle","unreadCountNeuron","values","actions","POCKET","POCKET_ACCOUNT","actionBar","tweet","defaultAccount","account","accounts","saveToLocalStorage","localStorage","setItem","JSON","stringify","setDefaultAccount","setAccounts","setStageTweetActionBar","deleteAddress","accountKey","networkKey","bech32","cyber","entryCyber","entries","channel","BroadcastChannel","postServiceStatus","postMessage","postSyncEntryProgress","entry","postSenseUpdate","senseList","postSetDefaultAccount","post","QueueItemTimeoutError","Error","timeoutMs","setPrototypeOf","prototype","CustomHeaders","XCybSourceValues","getQueueItemTotalPriority","priority","viewPortPriority","strategies","timeout","maxConcurrentExecutions","ipfsInstance$","strategy","queueDebounceMs","defferedDbSaver","queue$","BehaviorSubject","Map","lastNodeCallTime","executing","Set","subscribe","setNode","interval","pipe","debounceTime","queue","cancelDeprioritizedItems","mergeMap","workItems","getItemBySourceAndPriority","merge","fetchData$","E","callbacks","callback","delete","removeAndNext","nextSource","switchSourceAndNext","postSummary","switchStrategy","customStrategy","pendingItems","pendingBySource","itemsToExecute","queueSource","items","executeCount","itemsByPriority","queueItem","set","executionTime","promiseFactory","res","fetchIpfsContent","sharedWorker","enqueueIpfsContent","Observable","observer","complete","each","with","throwError","catchError","of","mutateQueueItem","changes","Array","releaseExecution","key","enqueue","existingItem","initialSource","postProcessing","enqueueAndWait","updateViewPortPriority","cancel","cancelByParent","parent","clear","getQueueMap","getQueueList","getStats","fn","QueuePriority","createAsyncIterable","promise","onmessage","event","IPFSContentTransferHandler","canHandle","obj","serialize","rest","port1","port2","MessageChannel","close","deserialize","serializedObj","SharedWorker","process","env","IS_DEV","installTransferHandlers","overrideLogging","worker","consoleLogMap","original","warn","replaceConsoleLog","args","apply","serializableArgs","String","safeStringify","broadcastStatus","channelApi","sendStatus","progress","asyncIterableBatchProcessor","batchProcess","batchSize","batch","fetchIterableByOffset","fetchFunction","params","CID_TWEET","CID_FOLLOW","SENSE_FRIEND_PARTICLES","deps","statusApi","_syncQueue$","waitForParticleResolve","dbInstance$","loadSyncQueue","isInitialized$","combineLatest","dbInstance","ipfsInstance","getValue","loop$","_loop$","all","MEDIUM","updateSyncQueue","removeSyncQueue","source$","tap","q","isInitialized","processSyncQueue","share","URGENT","cids","putSyncQueue","getSyncQueue","statuses","numberToUtcDate","dateToUtcNumber","isoString","endsWith","mapIndexerTransactionToEntity","tx","transaction","block","height","success","blockHeight","mapLinkFromIndexerToDto","throwIfAborted","func","aborted","DOMException","Order_By","CyberlinksByParticleDocument","CyberlinksCountByNeuronDocument","MessagesByAddressCountDocument","MessagesByAddressSenseDocument","MessagesByAddressSenseWsDocument","MSG_SEND_TRANSACTION_TYPE","MSG_MULTI_SEND_TRANSACTION_TYPE","mapWebsocketTxToTransactions","events","transactionType","messages","Tx","msgType","typeUrl","MsgSend","MsgMultiSend","extractTxData","TxResult","cyberGraphQLWsLink","shouldRetry","errOrCloseEvent","retryAttempts","retryWait","retries","Math","min","createIndexerClient","abortSignal","fetchCyberlinks","particleCid","timestampFrom","request","limit","orderBy","Asc","where","_or","particle_to","_eq","particle_from","_gt","cyberlinks","fetchCyberlinksByNeroun","particlesFrom","_and","_in","fetchCyberlinksByNerounIterable","getUniqueParticlesFromLinks","links","fetchCyberlinksAndResolveParticles","timestampUpdate","particlesResolver","queuePriority","cyberlinksIterable","fetchCyberlinksIterable","enqueueBatch","mapMessagesByAddressVariables","types","orderDirection","timestamp_from","t","join","order_direction","fetchTransactions","messages_by_address","updateSenseChat","amount","isSender","userAddress","lastSendTimestamp","last","direction","syncMyChats","myAddress","shouldUpdateTimestamp","syncItems","findSyncStatus","syncItemsMap","myChats","outputs","coins","toAddress","extractSenseChats","getTransactions","results","syncItem","lastTransaction","at","transactionTimestamp","syncItemHeader","timestampRead","prevUnreadCount","lastTimestampRead","max","timestampUpdateContent","timestampUpdateChat","timestampUnreadFrom","newTimestampUpdateChat","syncStatusChanges","updateSyncStatus","bind","newItem","disabled","putSyncStatus","ProgressTracker","onProgressUpdate","requestRecords","totalRequests","completedRequests","estimatedTime","totalCount","completeCount","extraRequests","trackProgress","processedCount","addRequestRecord","shift","estimatedRemainingTime","calculateAverageTimePerItem","round","itemCount","totalDiff","totalItems","timeDiff","progressTracker","abortController","cyblogCh","thread","module","params$","createIsInitializedObserver","info","switchMap","createRestartObserver","restart","initAbortController","distinctUntilChanged","addrBefore","addrAfter","switchWhenInitialized","actionObservable$","onChange","initialized","reloadTrigger$","Subject","startWith","createInitObservable","createClientObservable","onUpdate","syncQueueInitialized","variables","indexerObservable$","query","apolloObservable","ApolloClient","cache","subscriber","subscription","unsubscribe","createIndexerWebsocket","nodeObservample$","ws","WebSocket","onopen","send","jsonrpc","onerror","onclose","createNodeWebsocketObservable","ctx","unit","isEmpty","defer","initSync","getSyncStatus","lastTransactionTimestamp","syncTransactions","syncStatusItems","processBatchTransactions","putTransactions","syncLinks","lastTimestampFrom","newSyncItem","totalMessageCount","messages_by_address_aggregate","aggregate","count","fetchTransactionMessagesCount","ceil","transactionsAsyncIterable","fetchTransactionsIterable","transactionCount","tweets","particlesFound","l","txLink","extractCybelinksFromTransaction","putCyberlinks","tweetParticles","nonTweetParticles","HIGH","LOW","snakeToCamel","str","replace","group","toUpperCase","entityToDto","dbEntity","dto","hasOwnProperty","call","camelCaseKey","isArray","getLastReadInfo","prevTimestampRead","lastUnreadLinks","lastMyLinkIndex","findLastIndex","changeParticleSyncStatus","syncStatus","lastLink","isAbortException","intervalMs","warmupMs","restartLoop","onStartInterval","onError","retryDelayMs","restartTrigger$","intervalOrRestart$","delay","exhaustMap","retry","createLoopObservable","doSync","sync","isAborted","particleResolverInitialized","syncItemParticles","newLinkCount","particles_from","cyberlinks_aggregate","fetchCyberlinksCount","newSyncItemParticles","fetchNewTweets","syncParticles","tweetsAsyncIterable","newTweets","existingParticles","existingParticlesMap","tweetsBatch","syncStatusEntities","timestampSyncFrom","updatedSyncItems","linksIndexer","followings$","followings","followingsInitialized$","followingsInitialized","syncUpdates","linksAsyncIterable","linksBatch","newTimestampRead","newUnreadCount","newTimestampUpdateContent","reject","buffer","marshal","DAGNode","dagNode","toBaseEncodedString","fetchStoredSyncCommunity$","dbApi","fetchParticleAsync","storedCommunity","getCommunity","communityUpdatesMap","getExistingOrDefault","follower","followsCids","axios","txs","followers","addressHash","newFollowerCids","newFollowingNeurons","followersCommunity","communityItem","putCommunity","SyncService","loops","communitySync$","community","createCommunitySync$","processQueue","enqueueLinks","processQueueItem","entity","size_local","mapParticleToEntity","putParticles","backgroundWorker","ipfsNode","ipfsQueue","broadcastApi","syncService","defferedDbApi","importCyberlinks","ipfsApi","ipfsOpts","getIpfsNode","fetchWithDetails","dequeue","dequeueByParent","clearQueue","addContent","dbApiProxy","restartSync","setParams","createBackgroundWorkerApi","api","self","onconnect","ports","CYBLOG_BROADCAST_CHANNEL_NAME","logList","createCyblogChannel","defaultContext","postLogToChannel","level","context","trace","cyblog","consoleLogParams","formattedMessage","formatter","logItem","truncate","appendLog","stacktrace","contextItem","p","ctxItem","consoleLog","getLogs","splice","getConsoleLogParams","createCybLog","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","undefined","exports","loaded","__webpack_modules__","m","x","__webpack_exports__","O","amdO","chunkIds","notFulfilled","Infinity","j","every","r","n","getter","__esModule","d","getPrototypeOf","__proto__","mode","ns","create","def","current","getOwnPropertyNames","definition","o","defineProperty","enumerable","f","chunkId","promises","u","miniCssF","g","globalThis","Function","prop","toStringTag","nmd","paths","children","installedChunks","importScripts","chunkLoadingGlobal","parentChunkLoadingFunction","moreModules","runtime","pop"],"sourceRoot":""}